{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a54b4474",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import scipy.io as sio\n",
    "from os import listdir\n",
    "from skimage import io\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets.mnist import MNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "from tqdm import tqdm, trange\n",
    "import math   \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec25b150",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import scipy.io as sio\n",
    "from os import listdir\n",
    "from skimage import io\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets.mnist import MNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "from tqdm import tqdm, trange\n",
    "import math   \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6887194",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import scipy.io as sio\n",
    "from os import listdir\n",
    "from skimage import io\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets.mnist import MNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "from tqdm import tqdm, trange\n",
    "import math   \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Install Data as it is saved from MATLAB\n",
    "\n",
    "NumPerElement=79999+1\n",
    "\n",
    "im=torch.zeros(NumPerElement,1,2,3600)\n",
    "#im=torch.zeros(NumPerElement,1,128,40)\n",
    "label=torch.zeros(NumPerElement)\n",
    "\n",
    "count1=0\n",
    "count=-1\n",
    "folder_dir ='/Users/anuraagthakur/Desktop/RawData/FSK2'\n",
    "for images in os.listdir(folder_dir):\n",
    "    if images != '.DS_Store':\n",
    "        AA=sio.loadmat(folder_dir+'/'+images)\n",
    "        if(count1<NumPerElement):\n",
    "            count1=count1+1\n",
    "            count=count+1\n",
    "            for key, value in AA.items():\n",
    "                #im[count,0:1,0:128,0:40] = torch.from_numpy(value)\n",
    "                im[count,0:1,0:1,0:3600] = torch.from_numpy(value.real[0:1,0:3600])\n",
    "                im[count,0:1,1:2,0:3600] = torch.from_numpy(value.imag[0:1,0:3600].copy())\n",
    "            label[count]=0\n",
    "\n",
    "            \n",
    "folder_dir ='/Users/anuraagthakur/Desktop/RawData/FSK4'\n",
    "count2=0\n",
    "for images in os.listdir(folder_dir):\n",
    "    if images != '.DS_Store':\n",
    "        AA=sio.loadmat(folder_dir+'/'+images)\n",
    "        if(count2<NumPerElement):\n",
    "            count2=count2+1\n",
    "            count=count+1\n",
    "            for key, value in AA.items():\n",
    "                #im[count,0:1,0:128,0:40] = torch.from_numpy(value)\n",
    "                im[count,0:1,0:1,0:3600] = torch.from_numpy(value.real[0:1,0:3600])\n",
    "                im[count,0:1,1:2,0:3600] = torch.from_numpy(value.imag[0:1,0:3600].copy())\n",
    "            label[count]=1\n",
    "\n",
    "        \n",
    "folder_dir ='/Users/anuraagthakur/Desktop/RawData/FSK8'\n",
    "count3=0\n",
    "for images in os.listdir(folder_dir):\n",
    "    if images != '.DS_Store':\n",
    "        AA=sio.loadmat(folder_dir+'/'+images)\n",
    "        if(count3<NumPerElement):\n",
    "            count3=count3+1\n",
    "            count=count+1\n",
    "            for key, value in AA.items():\n",
    "                #im[count,0:1,0:128,0:40] = torch.from_numpy(value)\n",
    "                im[count,0:1,0:1,0:3600] = torch.from_numpy(value.real[0:1,0:3600])\n",
    "                im[count,0:1,1:2,0:3600] = torch.from_numpy(value.imag[0:1,0:3600].copy())\n",
    "            label[count]=2\n",
    "\n",
    " \n",
    "folder_dir ='/Users/anuraagthakur/Desktop/RawData/FSK16'\n",
    "count4=0\n",
    "for images in os.listdir(folder_dir):   \n",
    "    if images != '.DS_Store':\n",
    "        AA=sio.loadmat(folder_dir+'/'+images)\n",
    "        if(count4<NumPerElement):\n",
    "            count4=count4+1\n",
    "            count=count+1\n",
    "            for key, value in AA.items():\n",
    "                #im[count,0:1,0:128,0:40] = torch.from_numpy(value)\n",
    "                im[count,0:1,0:1,0:3600] = torch.from_numpy(value.real[0:1,0:3600])\n",
    "                im[count,0:1,1:2,0:3600] = torch.from_numpy(value.imag[0:1,0:3600].copy())\n",
    "            label[count]=3\n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ab7d290-9203-465b-b20d-9194f0ade487",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/kz/23c67y1112113d31_lhlx3_h0000gn/T/ipykernel_21137/1633648109.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mimages\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'.DS_Store'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0mAA\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadmat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder_dir\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount4\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0mNumPerElement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0mcount4\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcount4\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/scipy/io/matlab/_mio.py\u001b[0m in \u001b[0;36mloadmat\u001b[0;34m(file_name, mdict, appendmat, **kwargs)\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0mvariable_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'variable_names'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m         \u001b[0mMR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmat_reader_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m         \u001b[0mmatfile_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/scipy/io/matlab/_mio.py\u001b[0m in \u001b[0;36mmat_reader_factory\u001b[0;34m(file_name, appendmat, **kwargs)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \"\"\"\n\u001b[1;32m     73\u001b[0m     \u001b[0mbyte_stream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_opened\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m     \u001b[0mmjv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmnv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_matfile_version\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbyte_stream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmjv\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mMatFile4Reader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbyte_stream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_opened\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/scipy/io/matlab/_miobase.py\u001b[0m in \u001b[0;36m_get_matfile_version\u001b[0;34m(fileobj)\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[0mmopt_ints\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmopt_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmopt_ints\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m         \u001b[0mfileobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m     \u001b[0;31m# For 5 format or 7.3 format we need to read an integer in the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import scipy.io as sio\n",
    "from os import listdir\n",
    "from skimage import io\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets.mnist import MNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "from tqdm import tqdm, trange\n",
    "import math   \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Install Data as it is saved from MATLAB\n",
    "\n",
    "NumPerElement=79999+1\n",
    "\n",
    "im=torch.zeros(NumPerElement,1,2,3600)\n",
    "#im=torch.zeros(NumPerElement,1,128,40)\n",
    "label=torch.zeros(NumPerElement)\n",
    "\n",
    "count1=0\n",
    "count=-1\n",
    "folder_dir ='/Users/anuraagthakur/Desktop/RawData/2CW'\n",
    "for images in os.listdir(folder_dir):\n",
    "    if images != '.DS_Store':\n",
    "        AA=sio.loadmat(folder_dir+'/'+images)\n",
    "        if(count1<NumPerElement):\n",
    "            count1=count1+1\n",
    "            count=count+1\n",
    "            for key, value in AA.items():\n",
    "                #im[count,0:1,0:128,0:40] = torch.from_numpy(value)\n",
    "                im[count,0:1,0:1,0:3600] = torch.from_numpy(value.real[0:1,0:3600])\n",
    "                im[count,0:1,1:2,0:3600] = torch.from_numpy(value.imag[0:1,0:3600].copy())\n",
    "            label[count]=0\n",
    "\n",
    "            \n",
    "folder_dir ='/Users/anuraagthakur/Desktop/RawData/4CW'\n",
    "count2=0\n",
    "for images in os.listdir(folder_dir):\n",
    "    if images != '.DS_Store':\n",
    "        AA=sio.loadmat(folder_dir+'/'+images)\n",
    "        if(count2<NumPerElement):\n",
    "            count2=count2+1\n",
    "            count=count+1\n",
    "            for key, value in AA.items():\n",
    "                #im[count,0:1,0:128,0:40] = torch.from_numpy(value)\n",
    "                im[count,0:1,0:1,0:3600] = torch.from_numpy(value.real[0:1,0:3600])\n",
    "                im[count,0:1,1:2,0:3600] = torch.from_numpy(value.imag[0:1,0:3600].copy())\n",
    "            label[count]=1\n",
    "\n",
    "        \n",
    "folder_dir ='/Users/anuraagthakur/Desktop/RawData/6CW'\n",
    "count3=0\n",
    "for images in os.listdir(folder_dir):\n",
    "    if images != '.DS_Store':\n",
    "        AA=sio.loadmat(folder_dir+'/'+images)\n",
    "        if(count3<NumPerElement):\n",
    "            count3=count3+1\n",
    "            count=count+1\n",
    "            for key, value in AA.items():\n",
    "                #im[count,0:1,0:128,0:40] = torch.from_numpy(value)\n",
    "                im[count,0:1,0:1,0:3600] = torch.from_numpy(value.real[0:1,0:3600])\n",
    "                im[count,0:1,1:2,0:3600] = torch.from_numpy(value.imag[0:1,0:3600].copy())\n",
    "            label[count]=2\n",
    "\n",
    " \n",
    "folder_dir ='/Users/anuraagthakur/Desktop/RawData/8CW'\n",
    "count4=0\n",
    "for images in os.listdir(folder_dir):   \n",
    "    if images != '.DS_Store':\n",
    "        AA=sio.loadmat(folder_dir+'/'+images)\n",
    "        if(count4<NumPerElement):\n",
    "            count4=count4+1\n",
    "            count=count+1\n",
    "            for key, value in AA.items():\n",
    "                #im[count,0:1,0:128,0:40] = torch.from_numpy(value)\n",
    "                im[count,0:1,0:1,0:3600] = torch.from_numpy(value.real[0:1,0:3600])\n",
    "                im[count,0:1,1:2,0:3600] = torch.from_numpy(value.imag[0:1,0:3600].copy())\n",
    "            label[count]=3\n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee69fa55-7e30-457f-9f5e-184dd2b17479",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f0717d-d3dd-48b8-a8f6-f737b89b23f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import scipy.io as sio\n",
    "from os import listdir\n",
    "from skimage import io\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets.mnist import MNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "from tqdm import tqdm, trange\n",
    "import math   \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Install Data as it is saved from MATLAB\n",
    "\n",
    "NumPerElement=79999+1\n",
    "\n",
    "im=torch.zeros(NumPerElement,1,2,3600)\n",
    "#im=torch.zeros(NumPerElement,1,128,40)\n",
    "label=torch.zeros(NumPerElement)\n",
    "\n",
    "count1=0\n",
    "count=-1\n",
    "folder_dir ='/Users/anuraagthakur/Desktop/RawData/2CW'\n",
    "for images in os.listdir(folder_dir):\n",
    "    if images != '.DS_Store':\n",
    "        AA=sio.loadmat(folder_dir+'/'+images)\n",
    "        if(count1<NumPerElement):\n",
    "            count1=count1+1\n",
    "            count=count+1\n",
    "            for key, value in AA.items():\n",
    "                #im[count,0:1,0:128,0:40] = torch.from_numpy(value)\n",
    "                im[count,0:1,0:1,0:3600] = torch.from_numpy(value.real[0:1,0:3600])\n",
    "                im[count,0:1,1:2,0:3600] = torch.from_numpy(value.imag[0:1,0:3600].copy())\n",
    "            label[count]=0\n",
    "\n",
    "            \n",
    "folder_dir ='/Users/anuraagthakur/Desktop/RawData/4CW'\n",
    "count2=0\n",
    "for images in os.listdir(folder_dir):\n",
    "    if images != '.DS_Store':\n",
    "        AA=sio.loadmat(folder_dir+'/'+images)\n",
    "        if(count2<NumPerElement):\n",
    "            count2=count2+1\n",
    "            count=count+1\n",
    "            for key, value in AA.items():\n",
    "                #im[count,0:1,0:128,0:40] = torch.from_numpy(value)\n",
    "                im[count,0:1,0:1,0:3600] = torch.from_numpy(value.real[0:1,0:3600])\n",
    "                im[count,0:1,1:2,0:3600] = torch.from_numpy(value.imag[0:1,0:3600].copy())\n",
    "            label[count]=1\n",
    "\n",
    "        \n",
    "folder_dir ='/Users/anuraagthakur/Desktop/RawData/6CW'\n",
    "count3=0\n",
    "for images in os.listdir(folder_dir):\n",
    "    if images != '.DS_Store':\n",
    "        AA=sio.loadmat(folder_dir+'/'+images)\n",
    "        if(count3<NumPerElement):\n",
    "            count3=count3+1\n",
    "            count=count+1\n",
    "            for key, value in AA.items():\n",
    "                #im[count,0:1,0:128,0:40] = torch.from_numpy(value)\n",
    "                im[count,0:1,0:1,0:3600] = torch.from_numpy(value.real[0:1,0:3600])\n",
    "                im[count,0:1,1:2,0:3600] = torch.from_numpy(value.imag[0:1,0:3600].copy())\n",
    "            label[count]=2\n",
    "\n",
    " \n",
    "folder_dir ='/Users/anuraagthakur/Desktop/RawData/8CW'\n",
    "count4=0\n",
    "for images in os.listdir(folder_dir):   \n",
    "    if images != '.DS_Store':\n",
    "        AA=sio.loadmat(folder_dir+'/'+images)\n",
    "        if(count4<NumPerElement):\n",
    "            count4=count4+1\n",
    "            count=count+1\n",
    "            for key, value in AA.items():\n",
    "                #im[count,0:1,0:128,0:40] = torch.from_numpy(value)\n",
    "                im[count,0:1,0:1,0:3600] = torch.from_numpy(value.real[0:1,0:3600])\n",
    "                im[count,0:1,1:2,0:3600] = torch.from_numpy(value.imag[0:1,0:3600].copy())\n",
    "            label[count]=3\n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac44232-bef8-4145-8f82-1b716c0acccc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7899093-b978-4a3e-84ae-10a930057fcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55c5ee4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79999\n"
     ]
    }
   ],
   "source": [
    "print(count)\n",
    "from sklearn.utils import shuffle\n",
    "im, label = shuffle(im, label, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2e885a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "doneing environment: \\ \n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 23.9.0\n",
      "  latest version: 25.3.1\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "Or to minimize the number of packages updated during conda update use\n",
      "\n",
      "     conda install conda=25.3.1\n",
      "\n",
      "\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install -c pytorch pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04c108bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "doneing environment: - \n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 23.9.0\n",
      "  latest version: 25.3.1\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "Or to minimize the number of packages updated during conda update use\n",
      "\n",
      "     conda install conda=25.3.1\n",
      "\n",
      "\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install pytorch torchvision -c pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b35d22fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some parts borrowed from:https://medium.com/@brianpulfer/vision-transformers-from-scratch-pytorch-a-step-by-step-guide-96c3313c2e0c\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets.mnist import MNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "from tqdm import tqdm, trange\n",
    "from sklearn.utils import shuffle\n",
    "import math   \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4ec714b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MultiHeadSelfAttention(nn.Module):\n",
    "# Uses the Dot Product to determine the correlation and this determines the level of similarity\n",
    "    def __init__(self, d, NumberHeadsGiven):\n",
    "        super(MultiHeadSelfAttention, self).__init__()\n",
    "        self.d = d\n",
    "        self.NumberHeadsGivenLocal = NumberHeadsGiven\n",
    "\n",
    "        d_head = int(d / NumberHeadsGiven)\n",
    "        # mapping for query key and value is here from the open source transformer code I mentioned in the paper itself\n",
    "        self.q_mappingSelf = nn.ModuleList(\n",
    "            [nn.Linear(d_head, d_head) for _ in range(self.NumberHeadsGivenLocal)]\n",
    "        )\n",
    "        self.k_mappingSelf = nn.ModuleList(\n",
    "            [nn.Linear(d_head, d_head) for _ in range(self.NumberHeadsGivenLocal)]\n",
    "        )\n",
    "        self.v_mappingsSelf = nn.ModuleList(\n",
    "            [nn.Linear(d_head, d_head) for _ in range(self.NumberHeadsGivenLocal)]\n",
    "        )\n",
    "        self.d_head = d_head\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward (self, GivenSequence):\n",
    "        ResultofAttentionandValue = []\n",
    "        for sequence in GivenSequence: # Each head gets different part of the token \n",
    "            seq_ResultofAttentionandValue = []\n",
    "            for head in range(self.NumberHeadsGivenLocal):\n",
    "                q_mapping = self.q_mappingSelf[head]\n",
    "                k_mapping = self.k_mappingSelf[head]\n",
    "                v_mapping = self.v_mappingsSelf[head]\n",
    "\n",
    "                seq = sequence[:, head * self.d_head : (head + 1) * self.d_head] # Different from the original paper but used in newer designs\n",
    "                q, k, v = q_mapping(seq), k_mapping(seq), v_mapping(seq)\n",
    "\n",
    "                attention = self.softmax(q @ k.T / (self.d_head**0.5)) # Attention Dot product\n",
    "                seq_ResultofAttentionandValue.append(attention @ v) # Attention times value\n",
    "            ResultofAttentionandValue.append(torch.hstack(seq_ResultofAttentionandValue))\n",
    "        return torch.cat([torch.unsqueeze(r, dim=0) for r in ResultofAttentionandValue])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0afe84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VisionTransformer(nn.Module):\n",
    "    def __init__(self, Hidden_DGiven, NumberHeadsGiven, HiddenMLPMultiplier=4): # Changed Ratio to 2 to experiment in some runs,not too much of a change\n",
    "        super(VisionTransformer, self).__init__()\n",
    "        self.Hidden_DGivenLocal= Hidden_DGiven\n",
    "        self.NumberHeadsGivenLocal = NumberHeadsGiven\n",
    "\n",
    "        self.normComp1 = nn.LayerNorm(Hidden_DGiven)\n",
    "        self.mhsa = MultiHeadSelfAttention(Hidden_DGiven, NumberHeadsGiven)\n",
    "        self.normComp2 = nn.LayerNorm(Hidden_DGiven)\n",
    "        self.mlp = nn.Sequential( # Did some experiments here too but not much of a change for the artitecture, does not really matter\n",
    "            nn.Linear(Hidden_DGiven, HiddenMLPMultiplier * Hidden_DGiven),\n",
    "            nn.GELU(),# Maybe add more hidden layers but not actually needed here, overfits as is,  tweak the gelu a bit but no big change observed\n",
    "            nn.Linear(HiddenMLPMultiplier * Hidden_DGiven, Hidden_DGiven),\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = x + self.mhsa(self.normComp1(x)) # Residual Connection\n",
    "        output = output + self.mlp(self.normComp2(output)) # Residual Connection\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "90b71b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Different Types of Positional Embeddings are given here\n",
    "def get_positional_embeddings1(seq_len, d):\n",
    "    resultingOutput = torch.ones(seq_len, d)\n",
    "    for i in range(seq_len):\n",
    "        for j in range(d):\n",
    "            resultingOutput[i][j] = np.sin(i / (10000 ** (2*j / d))) if j % 2 == 0 else np.cos(i / (10000 ** (2*(j - 1) / d)))\n",
    "    return resultingOutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b92f0824",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64000, 1, 2, 3600])\n",
      "torch.Size([16000, 1, 2, 3600])\n",
      "torch.Size([64000])\n",
      "torch.Size([16000])\n"
     ]
    }
   ],
   "source": [
    "#Split into trian and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(im, label, test_size=0.2, random_state=42)\n",
    "\n",
    "print(X_train.size())\n",
    "print(X_test.size())\n",
    "print(y_train.size())\n",
    "print(y_test.size())\n",
    "\n",
    "Length=30000\n",
    "Stride=800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "616045d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import librosa\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import skew, kurtosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d5bbab-a199-4710-b5b9-092f9707c59e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "53a1033a-1a88-43de-a340-2e10d7f88e46",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                                           | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.4291, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4119, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4052, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3949, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4022, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4006, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3915, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4039, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3972, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3996, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3995, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3937, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3890, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3876, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3869, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3881, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3889, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3889, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3899, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3875, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3869, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3884, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3866, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3873, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3874, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3868, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3875, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3865, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3879, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3869, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3869, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3857, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3878, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3874, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3877, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3870, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3862, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3875, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|██████▏                        | 1/5 [32:39<2:10:36, 1959.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 loss: 52.90\n",
      "tensor(1.3868, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3869, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3874, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3875, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3868, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3861, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3862, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3864, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3868, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3862, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3870, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3868, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3866, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3866, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3865, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3862, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3867, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3866, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3873, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3853, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3862, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3866, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3884, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3877, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3852, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3864, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3863, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3866, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3870, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3864, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3864, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3854, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3863, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3878, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3886, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3868, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3860, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3874, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  40%|███████████▌                 | 2/5 [1:05:04<1:37:33, 1951.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5 loss: 52.69\n",
      "tensor(1.3863, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3876, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3883, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3896, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3875, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3852, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3870, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3867, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3865, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3866, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3868, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3862, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3868, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3862, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3869, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3859, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3867, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3865, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3873, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3854, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3864, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3864, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3889, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3877, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3854, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3866, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3862, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3863, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3871, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3867, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3858, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3854, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3857, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3875, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3885, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3865, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3860, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3876, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  60%|█████████████████▍           | 3/5 [1:36:53<1:04:23, 1931.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5 loss: 52.70\n",
      "tensor(1.3864, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3878, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3883, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3897, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3875, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3851, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3872, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3870, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3862, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3869, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3867, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3859, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3869, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3861, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3872, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3859, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3868, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3864, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3871, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3856, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3864, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3861, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3887, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3875, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3856, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3866, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3860, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3863, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3874, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3866, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3857, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3855, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3855, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3870, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3882, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3864, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3859, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3877, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  80%|████████████████████████▊      | 4/5 [2:08:41<32:02, 1922.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5 loss: 52.70\n",
      "tensor(1.3863, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3877, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3881, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3897, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3874, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3850, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3873, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3872, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3860, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3871, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3863, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3858, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3870, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3860, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3874, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3859, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3869, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3864, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3869, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3857, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3864, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3859, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3885, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3873, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3858, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3866, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3859, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3863, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3875, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3865, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3857, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3857, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3853, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3866, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3881, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3864, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3859, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3877, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████| 5/5 [2:40:59<00:00, 1931.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5 loss: 52.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.39\n",
      "Test accuracy: 25.45%\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "class MyViT(nn.Module):\n",
    "    def __init__(self, Dimensions, number_patchesRow,number_patchesColumn, number_blocks, Hidden_DGiven, NumberHeadsGiven, output_dimension):\n",
    "        # This patches up the image in user specified coumn and row patches\n",
    "        super(MyViT, self).__init__()\n",
    "        self.Dimensions = Dimensions  \n",
    "        self.number_patchesRow = number_patchesRow\n",
    "        self.number_patchesColumn=number_patchesColumn\n",
    "        self.number_blocks = number_blocks\n",
    "        self.Hidden_DGiven= Hidden_DGiven\n",
    "        self.NumberHeadsGiven = NumberHeadsGiven\n",
    "        \n",
    "        self.patch_size = (math.floor(Dimensions[1] / number_patchesRow), math.floor(Dimensions[2] / number_patchesColumn))\n",
    "        \n",
    "        self.input_d = int(Dimensions[0] * self.patch_size[0] * self.patch_size[1])\n",
    "        self.linear_mapper = nn.Linear(self.input_d, self.Hidden_DGiven)\n",
    "\n",
    "        self.class_token = nn.Parameter(torch.rand(1, self.Hidden_DGiven))\n",
    "\n",
    "        self.register_buffer(\n",
    "            \"positional_embeddings1\",\n",
    "            get_positional_embeddings1(number_patchesRow*number_patchesColumn + 1, Hidden_DGiven),\n",
    "            persistent=False,\n",
    "        )\n",
    "        \n",
    "        self.blocksA = nn.ModuleList(\n",
    "            [VisionTransformer(Hidden_DGiven, NumberHeadsGiven) for _ in range(number_blocks)]\n",
    "        )\n",
    "\n",
    "        self.mlp = nn.Sequential(nn.Linear(self.Hidden_DGiven, output_dimension), nn.Softmax(dim=-1))\n",
    "\n",
    "    def forward(self, images):        \n",
    "        n, c, h, w = images.shape\n",
    "        patches1A = images[0:n,0,0:self.patch_size[0]*self.number_patchesRow,0:self.patch_size[1]*self.number_patchesColumn]#patchify(images, self.n_patches).to(self.positional_embeddings1.device)\n",
    "        Size=48#(patches1A.size(1)*patches1A.size(2))/(self.number_patchesRow*self.number_patchesColumn)\n",
    "        #print(Size)\n",
    "        patches1=patches1A.reshape(n,self.number_patchesRow*self.number_patchesColumn,Size)\n",
    "        \n",
    "        tokens1 = self.linear_mapper(patches1)\n",
    "        tokensa = torch.cat((self.class_token.expand(n, 1, -1), tokens1), dim=1)\n",
    "\n",
    "        A    = tokensa\n",
    "\n",
    "        for block in self.blocksA:\n",
    "            A = block(A)\n",
    "        \n",
    "        output = torch.ones(n,self.Hidden_DGiven)\n",
    "        \n",
    "        output[0:n,self.Hidden_DGiven*0:self.Hidden_DGiven]  = A[:, 0]\n",
    "\n",
    "        return self.mlp(output)\n",
    "\n",
    "\n",
    "def main():\n",
    "    \n",
    "    transform = ToTensor()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = MyViT(\n",
    "        (1,2,3600), number_patchesRow=1, number_patchesColumn=150, number_blocks=10, Hidden_DGiven=10, NumberHeadsGiven=10, output_dimension=4\n",
    "    ).to(device)\n",
    "\n",
    "    NUMBER_EPOCHS = 5\n",
    "    LearningRate = 0.001\n",
    "\n",
    "    # Training Data loop\n",
    "    optimizer = Adam(model.parameters(), lr= LearningRate)\n",
    "    criterion = CrossEntropyLoss()\n",
    "\n",
    "    for epoch in trange(NUMBER_EPOCHS, desc=\"Training\"):\n",
    "        training_loss = 0.0\n",
    "        for batch in range(0,Length,Stride):\n",
    "            y = y_train[batch:batch+Stride]\n",
    "            x = X_train[batch:batch+Stride,0:1,0:2,0:3600]\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            y_hat = model(x)\n",
    "            \n",
    "            loss = criterion(y_hat, y.type(torch.LongTensor))\n",
    "            print(loss)\n",
    "            training_loss += loss.detach().cpu().item()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        print(f\"Epoch {epoch + 1}/{NUMBER_EPOCHS} loss: {training_loss:.2f}\")\n",
    "\n",
    "    # Testing loop with testing data\n",
    "    with torch.no_grad():\n",
    "        correct, total = 0, 0\n",
    "        test_loss = 0.0\n",
    "        y = y_test\n",
    "        x = X_test\n",
    "\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        y_hat = model(x)\n",
    "        loss = criterion(y_hat, y.type(torch.LongTensor))\n",
    "\n",
    "        test_loss += loss.detach().cpu().item()\n",
    "\n",
    "        correct += torch.sum(torch.argmax(y_hat, dim=1) == y).detach().cpu().item()\n",
    "        total += len(x)\n",
    "        print(f\"Test loss: {test_loss:.2f}\")\n",
    "        #cm = confusion_matrix(y_hat, y)\n",
    "        print(f\"Test accuracy: {correct / total * 100:.2f}%\")\n",
    "main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c994f60-6d2a-435a-ae4a-ea1e0b2edac3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "18b8224c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                                           | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.4084, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3976, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3906, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3852, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3942, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4049, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3916, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3920, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3951, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3964, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4014, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3977, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3924, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3949, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3923, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3927, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3909, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3933, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3997, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3902, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3965, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3853, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3914, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3912, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3874, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3926, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3901, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3904, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3870, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3912, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3865, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3857, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3846, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3879, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3881, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3850, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3865, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3862, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3868, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3866, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3872, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3875, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3848, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3890, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3886, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3880, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3886, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3871, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3869, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3865, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3882, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3862, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3853, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3890, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3890, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3871, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3860, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3861, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3864, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3863, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3861, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3857, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3875, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3852, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3933, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3895, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3856, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3848, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3853, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3859, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3856, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3870, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3871, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3861, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3847, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3855, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3916, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3865, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3869, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3850, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|█████▊                       | 1/5 [1:14:58<4:59:54, 4498.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 loss: 111.15\n",
      "tensor(1.3867, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3903, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3925, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3928, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3887, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3865, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3867, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3858, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3874, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3883, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3888, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3870, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3862, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3873, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3880, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3874, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3865, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3860, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3862, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3860, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3869, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3871, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3903, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3880, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3857, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3865, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3863, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3864, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3851, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3873, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3860, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3853, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3850, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3880, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3886, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3850, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3861, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3870, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3859, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3882, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3858, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3861, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3854, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3871, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3863, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3862, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3880, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3870, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3864, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3867, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3871, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3866, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3860, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3876, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3873, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3868, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3863, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3863, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3866, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3863, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3865, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3846, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3876, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3852, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3921, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3892, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3852, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3845, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3861, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3857, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3859, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3863, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3878, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3860, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3848, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3854, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3918, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3879, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3866, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3861, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  40%|███████████▌                 | 2/5 [2:26:57<3:39:38, 4392.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5 loss: 110.96\n",
      "tensor(1.3861, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3885, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3908, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3914, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3886, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3862, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3875, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3851, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3864, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3868, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3875, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3867, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3862, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3867, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3868, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3866, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3859, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3859, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3871, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3853, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3871, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3869, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3894, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3873, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3859, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3865, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3865, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3868, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3847, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3874, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3860, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3852, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3848, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3879, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3884, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3855, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3860, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3870, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3859, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3883, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3857, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3861, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3857, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3869, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3863, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3862, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3879, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3871, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3865, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3868, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3868, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3863, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3858, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3877, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3873, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3868, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3864, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3866, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3862, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3863, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3865, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3846, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3875, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3853, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3919, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3892, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3853, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3847, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3857, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3856, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3858, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3863, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3878, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3861, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3850, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3853, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3914, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3874, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3866, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3863, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  60%|█████████████████▍           | 3/5 [3:36:35<2:23:09, 4294.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5 loss: 110.94\n",
      "tensor(1.3861, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3880, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3900, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3906, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3881, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3862, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3872, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3852, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3864, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3867, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3872, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3865, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3861, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3867, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3869, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3865, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3860, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3859, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3871, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3853, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3870, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3870, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3895, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3875, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3858, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3864, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3864, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3867, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3848, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3873, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3860, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3852, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3848, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3880, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3885, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3855, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3860, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3871, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3859, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3886, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3856, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3860, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3858, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3867, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3863, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3862, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3880, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3872, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3866, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3869, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3865, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3861, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3857, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3877, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3873, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3868, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3865, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3867, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3861, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3862, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3865, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3847, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3874, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3853, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3918, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3893, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3853, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3847, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3855, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3854, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3858, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3863, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3878, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3861, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3850, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3853, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3911, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3871, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3866, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3864, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  80%|███████████████████████▏     | 4/5 [5:15:51<1:22:30, 4950.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5 loss: 110.94\n",
      "tensor(1.3861, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3877, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3895, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3901, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3879, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3862, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3871, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3853, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3864, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3867, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3871, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3864, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3861, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3867, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3869, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3865, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3860, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3859, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3870, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3853, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3870, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3870, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3895, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3876, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3858, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3864, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3863, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3866, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3850, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3872, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3860, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3852, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3848, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3880, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3886, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3854, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3860, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3872, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3859, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3889, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3855, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3860, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3859, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3866, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3862, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3862, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3879, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3872, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3867, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3870, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3863, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3860, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3856, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3877, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3873, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3868, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3865, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3868, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3860, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3862, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3865, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3847, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3872, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3852, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3916, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3892, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3853, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3847, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3853, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3853, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3857, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3864, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3878, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3861, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3851, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3853, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3910, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3868, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3866, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3865, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████| 5/5 [6:45:11<00:00, 4862.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5 loss: 110.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.39\n",
      "Test accuracy: 24.27%\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "class MyViT(nn.Module):\n",
    "    def __init__(self, Dimensions, number_patchesRow,number_patchesColumn, number_blocks, Hidden_DGiven, NumberHeadsGiven, output_dimension):\n",
    "        # This patches up the image in user specified coumn and row patches\n",
    "        super(MyViT, self).__init__()\n",
    "        self.Dimensions = Dimensions  \n",
    "        self.number_patchesRow = number_patchesRow\n",
    "        self.number_patchesColumn=number_patchesColumn\n",
    "        self.number_blocks = number_blocks\n",
    "        self.Hidden_DGiven= Hidden_DGiven\n",
    "        self.NumberHeadsGiven = NumberHeadsGiven\n",
    "        \n",
    "        self.patch_size = (math.floor(Dimensions[1] / number_patchesRow), math.floor(Dimensions[2] / number_patchesColumn))\n",
    "        \n",
    "        self.input_d = int(Dimensions[0] * self.patch_size[0] * self.patch_size[1])\n",
    "        self.linear_mapper = nn.Linear(self.input_d, self.Hidden_DGiven)\n",
    "\n",
    "        self.class_token = nn.Parameter(torch.rand(1, self.Hidden_DGiven))\n",
    "\n",
    "        self.register_buffer(\n",
    "            \"positional_embeddings1\",\n",
    "            get_positional_embeddings1(number_patchesRow*number_patchesColumn + 1, Hidden_DGiven),\n",
    "            persistent=False,\n",
    "        )\n",
    "        \n",
    "        self.blocksA = nn.ModuleList(\n",
    "            [VisionTransformer(Hidden_DGiven, NumberHeadsGiven) for _ in range(number_blocks)]\n",
    "        )\n",
    "\n",
    "        self.mlp = nn.Sequential(nn.Linear(self.Hidden_DGiven, output_dimension), nn.Softmax(dim=-1))\n",
    "\n",
    "    def forward(self, images):        \n",
    "        n, c, h, w = images.shape\n",
    "        patches1A = images[0:n,0,0:self.patch_size[0]*self.number_patchesRow,0:self.patch_size[1]*self.number_patchesColumn]#patchify(images, self.n_patches).to(self.positional_embeddings1.device)\n",
    "        Size=48#(patches1A.size(1)*patches1A.size(2))/(self.number_patchesRow*self.number_patchesColumn)\n",
    "        #print(Size)\n",
    "        patches1=patches1A.reshape(n,self.number_patchesRow*self.number_patchesColumn,Size)\n",
    "        \n",
    "        tokens1 = self.linear_mapper(patches1)\n",
    "        tokensa = torch.cat((self.class_token.expand(n, 1, -1), tokens1), dim=1)\n",
    "\n",
    "        A    = tokensa\n",
    "\n",
    "        for block in self.blocksA:\n",
    "            A = block(A)\n",
    "        \n",
    "        output = torch.ones(n,self.Hidden_DGiven)\n",
    "        \n",
    "        output[0:n,self.Hidden_DGiven*0:self.Hidden_DGiven]  = A[:, 0]\n",
    "\n",
    "        return self.mlp(output)\n",
    "\n",
    "\n",
    "def main():\n",
    "    \n",
    "    transform = ToTensor()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = MyViT(\n",
    "        (1,2,3600), number_patchesRow=1, number_patchesColumn=150, number_blocks=10, Hidden_DGiven=10, NumberHeadsGiven=10, output_dimension=4\n",
    "    ).to(device)\n",
    "\n",
    "    NUMBER_EPOCHS = 5\n",
    "    LearningRate = 0.001\n",
    "\n",
    "    # Training Data loop\n",
    "    optimizer = Adam(model.parameters(), lr= LearningRate)\n",
    "    criterion = CrossEntropyLoss()\n",
    "\n",
    "    for epoch in trange(NUMBER_EPOCHS, desc=\"Training\"):\n",
    "        training_loss = 0.0\n",
    "        for batch in range(0,Length,Stride):\n",
    "            y = y_train[batch:batch+Stride]\n",
    "            x = X_train[batch:batch+Stride,0:1,0:2,0:3600]\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            y_hat = model(x)\n",
    "            \n",
    "            loss = criterion(y_hat, y.type(torch.LongTensor))\n",
    "            print(loss)\n",
    "            training_loss += loss.detach().cpu().item()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        print(f\"Epoch {epoch + 1}/{NUMBER_EPOCHS} loss: {training_loss:.2f}\")\n",
    "\n",
    "    # Testing loop with testing data\n",
    "    with torch.no_grad():\n",
    "        correct, total = 0, 0\n",
    "        test_loss = 0.0\n",
    "        y = y_test\n",
    "        x = X_test\n",
    "\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        y_hat = model(x)\n",
    "        loss = criterion(y_hat, y.type(torch.LongTensor))\n",
    "\n",
    "        test_loss += loss.detach().cpu().item()\n",
    "\n",
    "        correct += torch.sum(torch.argmax(y_hat, dim=1) == y).detach().cpu().item()\n",
    "        total += len(x)\n",
    "        print(f\"Test loss: {test_loss:.2f}\")\n",
    "        #cm = confusion_matrix(y_hat, y)\n",
    "        print(f\"Test accuracy: {correct / total * 100:.2f}%\")\n",
    "main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1008143",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e90bf3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3c6dcf2f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                                           | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.4028, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4045, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4012, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4003, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3925, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3880, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3891, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3889, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3860, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3847, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3876, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3854, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3813, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3824, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3799, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3779, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3738, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3736, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3775, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3689, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3729, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3667, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3679, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3676, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3586, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3599, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3509, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3522, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3599, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3335, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3412, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3348, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3406, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3156, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3036, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3035, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3037, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2834, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|██████▏                        | 1/5 [35:19<2:21:17, 2119.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 loss: 51.84\n",
      "tensor(1.2733, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2567, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2456, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2256, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2292, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2452, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2113, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2076, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2178, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2125, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2002, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1896, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1939, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1674, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1612, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1576, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1601, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1555, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1636, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1321, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1495, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1208, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1170, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1198, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1044, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0969, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0837, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0903, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0723, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0543, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0656, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0382, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0573, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0329, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0280, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0146, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0158, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9990, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  40%|███████████▌                 | 2/5 [1:09:30<1:43:57, 2079.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5 loss: 43.27\n",
      "tensor(0.9952, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9730, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9708, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9472, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9629, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9539, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9443, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9334, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9211, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9397, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9228, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9222, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9103, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8985, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8966, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8909, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8831, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8828, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8737, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8727, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8947, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8901, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8649, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8838, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8710, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8752, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8639, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8590, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8674, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8553, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8513, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8365, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8816, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8536, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8704, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8504, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8651, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8614, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  60%|█████████████████▍           | 3/5 [1:44:41<1:09:47, 2093.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5 loss: 34.09\n",
      "tensor(0.8392, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8544, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8370, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8360, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8495, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8404, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8358, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8318, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8199, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8369, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8324, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8420, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8294, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8184, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8220, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8258, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8132, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8149, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8190, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8158, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8340, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8241, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8231, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8278, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8212, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8303, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8149, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8160, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8056, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8183, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8077, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8012, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8296, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8165, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8261, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8163, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8263, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8063, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  80%|████████████████████████▊      | 4/5 [2:19:15<34:46, 2086.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5 loss: 31.36\n",
      "tensor(0.8085, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8100, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8120, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8013, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8086, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8159, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7987, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8120, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8021, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8090, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8160, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8120, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8032, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7998, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8046, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8059, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7992, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7983, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8053, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7996, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8153, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8109, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8014, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8165, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8011, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8077, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8013, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8024, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7880, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8125, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7944, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7900, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8222, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7993, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8229, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8105, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8186, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8131, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████| 5/5 [2:52:02<00:00, 2064.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5 loss: 30.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.80\n",
      "Test accuracy: 94.92%\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "class MyViT(nn.Module):\n",
    "    def __init__(self, Dimensions, number_patchesRow,number_patchesColumn, number_blocks, Hidden_DGiven, NumberHeadsGiven, output_dimension):\n",
    "        # This patches up the image in user specified coumn and row patches\n",
    "        super(MyViT, self).__init__()\n",
    "        self.Dimensions = Dimensions  \n",
    "        self.number_patchesRow = number_patchesRow\n",
    "        self.number_patchesColumn=number_patchesColumn\n",
    "        self.number_blocks = number_blocks\n",
    "        self.Hidden_DGiven= Hidden_DGiven\n",
    "        self.NumberHeadsGiven = NumberHeadsGiven\n",
    "        \n",
    "        self.patch_size = (math.floor(Dimensions[1] / number_patchesRow), math.floor(Dimensions[2] / number_patchesColumn))\n",
    "        \n",
    "        self.input_d = int(Dimensions[0] * self.patch_size[0] * self.patch_size[1])\n",
    "        self.linear_mapper = nn.Linear(self.input_d, self.Hidden_DGiven)\n",
    "\n",
    "        self.class_token = nn.Parameter(torch.rand(1, self.Hidden_DGiven))\n",
    "\n",
    "        self.register_buffer(\n",
    "            \"positional_embeddings1\",\n",
    "            get_positional_embeddings1(number_patchesRow*number_patchesColumn + 1, Hidden_DGiven),\n",
    "            persistent=False,\n",
    "        )\n",
    "        \n",
    "        self.blocksA = nn.ModuleList(\n",
    "            [VisionTransformer(Hidden_DGiven, NumberHeadsGiven) for _ in range(number_blocks)]\n",
    "        )\n",
    "\n",
    "        self.mlp = nn.Sequential(nn.Linear(self.Hidden_DGiven, output_dimension), nn.Softmax(dim=-1))\n",
    "\n",
    "    def forward(self, images):        \n",
    "        n, c, h, w = images.shape\n",
    "        patches1A = images[0:n,0,0:self.patch_size[0]*self.number_patchesRow,0:self.patch_size[1]*self.number_patchesColumn]#patchify(images, self.n_patches).to(self.positional_embeddings1.device)\n",
    "        Size=48#(patches1A.size(1)*patches1A.size(2))/(self.number_patchesRow*self.number_patchesColumn)\n",
    "        #print(Size)\n",
    "        patches1=patches1A.reshape(n,self.number_patchesRow*self.number_patchesColumn,Size)\n",
    "        \n",
    "        tokens1 = self.linear_mapper(patches1)\n",
    "        tokensa = torch.cat((self.class_token.expand(n, 1, -1), tokens1), dim=1)\n",
    "\n",
    "        A    = tokensa\n",
    "\n",
    "        for block in self.blocksA:\n",
    "            A = block(A)\n",
    "        \n",
    "        output = torch.ones(n,self.Hidden_DGiven)\n",
    "        \n",
    "        output[0:n,self.Hidden_DGiven*0:self.Hidden_DGiven]  = A[:, 0]\n",
    "\n",
    "        return self.mlp(output)\n",
    "\n",
    "\n",
    "def main():\n",
    "    \n",
    "    transform = ToTensor()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = MyViT(\n",
    "        (1,2,3600), number_patchesRow=1, number_patchesColumn=150, number_blocks=10, Hidden_DGiven=10, NumberHeadsGiven=10, output_dimension=4\n",
    "    ).to(device)\n",
    "\n",
    "    NUMBER_EPOCHS = 5\n",
    "    LearningRate = 0.001\n",
    "\n",
    "    # Training Data loop\n",
    "    optimizer = Adam(model.parameters(), lr= LearningRate)\n",
    "    criterion = CrossEntropyLoss()\n",
    "\n",
    "    for epoch in trange(NUMBER_EPOCHS, desc=\"Training\"):\n",
    "        training_loss = 0.0\n",
    "        for batch in range(0,Length,Stride):\n",
    "            y = y_train[batch:batch+Stride]\n",
    "            x = X_train[batch:batch+Stride,0:1,0:2,0:3600]\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            y_hat = model(x)\n",
    "            \n",
    "            loss = criterion(y_hat, y.type(torch.LongTensor))\n",
    "            print(loss)\n",
    "            training_loss += loss.detach().cpu().item()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        print(f\"Epoch {epoch + 1}/{NUMBER_EPOCHS} loss: {training_loss:.2f}\")\n",
    "\n",
    "    # Testing loop with testing data\n",
    "    with torch.no_grad():\n",
    "        correct, total = 0, 0\n",
    "        test_loss = 0.0\n",
    "        y = y_test\n",
    "        x = X_test\n",
    "\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        y_hat = model(x)\n",
    "        loss = criterion(y_hat, y.type(torch.LongTensor))\n",
    "\n",
    "        test_loss += loss.detach().cpu().item()\n",
    "\n",
    "        correct += torch.sum(torch.argmax(y_hat, dim=1) == y).detach().cpu().item()\n",
    "        total += len(x)\n",
    "        print(f\"Test loss: {test_loss:.2f}\")\n",
    "        #cm = confusion_matrix(y_hat, y)\n",
    "        print(f\"Test accuracy: {correct / total * 100:.2f}%\")\n",
    "main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086b2c4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f846f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015488c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3609efa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import scipy.io as sio\n",
    "from os import listdir\n",
    "from skimage import io\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets.mnist import MNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "from tqdm import tqdm, trange\n",
    "import math   \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Install Data as it is saved from MATLAB\n",
    "\n",
    "NumPerElement=99999+1\n",
    "\n",
    "im=torch.zeros(NumPerElement,1,2,3600)\n",
    "#im=torch.zeros(NumPerElement,1,128,40)\n",
    "label=torch.zeros(NumPerElement)\n",
    "\n",
    "count1=0\n",
    "count=-1\n",
    "folder_dir ='/Users/anuraagthakur/Desktop/RawData/FSK2'\n",
    "for images in os.listdir(folder_dir):\n",
    "    if images != '.DS_Store':\n",
    "        AA=sio.loadmat(folder_dir+'/'+images)\n",
    "        if(count1<NumPerElement):\n",
    "            count1=count1+1\n",
    "            count=count+1\n",
    "            for key, value in AA.items():\n",
    "                #im[count,0:1,0:128,0:40] = torch.from_numpy(value)\n",
    "                im[count,0:1,0:1,0:3600] = torch.from_numpy(value.real[0:1,0:3600])\n",
    "                im[count,0:1,1:2,0:3600] = torch.from_numpy(value.imag[0:1,0:3600].copy())\n",
    "            label[count]=0\n",
    "\n",
    "            \n",
    "folder_dir ='/Users/anuraagthakur/Desktop/RawData/FSK4'\n",
    "count2=0\n",
    "for images in os.listdir(folder_dir):\n",
    "    if images != '.DS_Store':\n",
    "        AA=sio.loadmat(folder_dir+'/'+images)\n",
    "        if(count2<NumPerElement):\n",
    "            count2=count2+1\n",
    "            count=count+1\n",
    "            for key, value in AA.items():\n",
    "                #im[count,0:1,0:128,0:40] = torch.from_numpy(value)\n",
    "                im[count,0:1,0:1,0:3600] = torch.from_numpy(value.real[0:1,0:3600])\n",
    "                im[count,0:1,1:2,0:3600] = torch.from_numpy(value.imag[0:1,0:3600].copy())\n",
    "            label[count]=1\n",
    "\n",
    "        \n",
    "folder_dir ='/Users/anuraagthakur/Desktop/RawData/FSK8'\n",
    "count3=0\n",
    "for images in os.listdir(folder_dir):\n",
    "    if images != '.DS_Store':\n",
    "        AA=sio.loadmat(folder_dir+'/'+images)\n",
    "        if(count3<NumPerElement):\n",
    "            count3=count3+1\n",
    "            count=count+1\n",
    "            for key, value in AA.items():\n",
    "                #im[count,0:1,0:128,0:40] = torch.from_numpy(value)\n",
    "                im[count,0:1,0:1,0:3600] = torch.from_numpy(value.real[0:1,0:3600])\n",
    "                im[count,0:1,1:2,0:3600] = torch.from_numpy(value.imag[0:1,0:3600].copy())\n",
    "            label[count]=2\n",
    "\n",
    " \n",
    "folder_dir ='/Users/anuraagthakur/Desktop/RawData/FSK16'\n",
    "count4=0\n",
    "for images in os.listdir(folder_dir):   \n",
    "    if images != '.DS_Store':\n",
    "        AA=sio.loadmat(folder_dir+'/'+images)\n",
    "        if(count4<NumPerElement):\n",
    "            count4=count4+1\n",
    "            count=count+1\n",
    "            for key, value in AA.items():\n",
    "                #im[count,0:1,0:128,0:40] = torch.from_numpy(value)\n",
    "                im[count,0:1,0:1,0:3600] = torch.from_numpy(value.real[0:1,0:3600])\n",
    "                im[count,0:1,1:2,0:3600] = torch.from_numpy(value.imag[0:1,0:3600].copy())\n",
    "            label[count]=3\n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a30647",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(count)\n",
    "from sklearn.utils import shuffle\n",
    "im, label = shuffle(im, label, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709509bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split into trian and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(im, label, test_size=0.2, random_state=42)\n",
    "\n",
    "print(X_train.size())\n",
    "print(X_test.size())\n",
    "print(y_train.size())\n",
    "print(y_test.size())\n",
    "\n",
    "Length=80000\n",
    "Stride=500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57927b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "class MyViT(nn.Module):\n",
    "    def __init__(self, Dimensions, number_patchesRow,number_patchesColumn, number_blocks, Hidden_DGiven, NumberHeadsGiven, output_dimension):\n",
    "        # This patches up the image in user specified coumn and row patches\n",
    "        super(MyViT, self).__init__()\n",
    "        self.Dimensions = Dimensions  \n",
    "        self.number_patchesRow = number_patchesRow\n",
    "        self.number_patchesColumn=number_patchesColumn\n",
    "        self.number_blocks = number_blocks\n",
    "        self.Hidden_DGiven= Hidden_DGiven\n",
    "        self.NumberHeadsGiven = NumberHeadsGiven\n",
    "        \n",
    "        self.patch_size = (math.floor(Dimensions[1] / number_patchesRow), math.floor(Dimensions[2] / number_patchesColumn))\n",
    "        \n",
    "        self.input_d = int(Dimensions[0] * self.patch_size[0] * self.patch_size[1])\n",
    "        self.linear_mapper = nn.Linear(self.input_d, self.Hidden_DGiven)\n",
    "\n",
    "        self.class_token = nn.Parameter(torch.rand(1, self.Hidden_DGiven))\n",
    "\n",
    "        self.register_buffer(\n",
    "            \"positional_embeddings1\",\n",
    "            get_positional_embeddings1(number_patchesRow*number_patchesColumn + 1, Hidden_DGiven),\n",
    "            persistent=False,\n",
    "        )\n",
    "        \n",
    "        self.blocksA = nn.ModuleList(\n",
    "            [VisionTransformer(Hidden_DGiven, NumberHeadsGiven) for _ in range(number_blocks)]\n",
    "        )\n",
    "\n",
    "        self.mlp = nn.Sequential(nn.Linear(self.Hidden_DGiven, output_dimension), nn.Softmax(dim=-1))\n",
    "\n",
    "    def forward(self, images):        \n",
    "        n, c, h, w = images.shape\n",
    "        patches1A = images[0:n,0,0:self.patch_size[0]*self.number_patchesRow,0:self.patch_size[1]*self.number_patchesColumn]#patchify(images, self.n_patches).to(self.positional_embeddings1.device)\n",
    "        Size=48#(patches1A.size(1)*patches1A.size(2))/(self.number_patchesRow*self.number_patchesColumn)\n",
    "        #print(Size)\n",
    "        patches1=patches1A.reshape(n,self.number_patchesRow*self.number_patchesColumn,Size)\n",
    "        \n",
    "        tokens1 = self.linear_mapper(patches1)\n",
    "        tokensa = torch.cat((self.class_token.expand(n, 1, -1), tokens1), dim=1)\n",
    "\n",
    "        A    = tokensa\n",
    "\n",
    "        for block in self.blocksA:\n",
    "            A = block(A)\n",
    "        \n",
    "        output = torch.ones(n,self.Hidden_DGiven)\n",
    "        \n",
    "        output[0:n,self.Hidden_DGiven*0:self.Hidden_DGiven]  = A[:, 0]\n",
    "\n",
    "        return self.mlp(output)\n",
    "\n",
    "\n",
    "def main():\n",
    "    \n",
    "    transform = ToTensor()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = MyViT(\n",
    "        (1,2,3600), number_patchesRow=1, number_patchesColumn=150, number_blocks=10, Hidden_DGiven=10, NumberHeadsGiven=10, output_dimension=7\n",
    "    ).to(device)\n",
    "\n",
    "    NUMBER_EPOCHS = 5\n",
    "    LearningRate = 0.001\n",
    "\n",
    "    # Training Data loop\n",
    "    optimizer = Adam(model.parameters(), lr= LearningRate)\n",
    "    criterion = CrossEntropyLoss()\n",
    "\n",
    "    for epoch in trange(NUMBER_EPOCHS, desc=\"Training\"):\n",
    "        training_loss = 0.0\n",
    "        for batch in range(0,Length,Stride):\n",
    "            y = y_train[batch:batch+Stride]\n",
    "            x = X_train[batch:batch+Stride,0:1,0:2,0:3600]\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            y_hat = model(x)\n",
    "            \n",
    "            loss = criterion(y_hat, y.type(torch.LongTensor))\n",
    "            print(loss)\n",
    "            training_loss += loss.detach().cpu().item()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        print(f\"Epoch {epoch + 1}/{NUMBER_EPOCHS} loss: {training_loss:.2f}\")\n",
    "\n",
    "    # Testing loop with testing data\n",
    "    with torch.no_grad():\n",
    "        correct, total = 0, 0\n",
    "        test_loss = 0.0\n",
    "        y = y_test\n",
    "        x = X_test\n",
    "\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        y_hat = model(x)\n",
    "        loss = criterion(y_hat, y.type(torch.LongTensor))\n",
    "\n",
    "        test_loss += loss.detach().cpu().item()\n",
    "\n",
    "        correct += torch.sum(torch.argmax(y_hat, dim=1) == y).detach().cpu().item()\n",
    "        total += len(x)\n",
    "        print(f\"Test loss: {test_loss:.2f}\")\n",
    "        #cm = confusion_matrix(y_hat, y)\n",
    "        print(f\"Test accuracy: {correct / total * 100:.2f}%\")\n",
    "main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77dc8c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077086f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7354ce70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import scipy.io as sio\n",
    "from os import listdir\n",
    "from skimage import io\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets.mnist import MNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "from tqdm import tqdm, trange\n",
    "import math   \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Install Data as it is saved from MATLAB\n",
    "\n",
    "NumPerElement=99999+1\n",
    "\n",
    "im=torch.zeros(NumPerElement,1,2,3600)\n",
    "#im=torch.zeros(NumPerElement,1,128,40)\n",
    "label=torch.zeros(NumPerElement)\n",
    "\n",
    "count1=0\n",
    "count=-1\n",
    "folder_dir ='/Users/anuraagthakur/Desktop/RawData/2CW'\n",
    "for images in os.listdir(folder_dir):\n",
    "    if images != '.DS_Store':\n",
    "        AA=sio.loadmat(folder_dir+'/'+images)\n",
    "        if(count1<NumPerElement):\n",
    "            count1=count1+1\n",
    "            count=count+1\n",
    "            for key, value in AA.items():\n",
    "                #im[count,0:1,0:128,0:40] = torch.from_numpy(value)\n",
    "                im[count,0:1,0:1,0:3600] = torch.from_numpy(value.real[0:1,0:3600])\n",
    "                im[count,0:1,1:2,0:3600] = torch.from_numpy(value.imag[0:1,0:3600].copy())\n",
    "            label[count]=0\n",
    "\n",
    "            \n",
    "folder_dir ='/Users/anuraagthakur/Desktop/RawData/4CW'\n",
    "count2=0\n",
    "for images in os.listdir(folder_dir):\n",
    "    if images != '.DS_Store':\n",
    "        AA=sio.loadmat(folder_dir+'/'+images)\n",
    "        if(count2<NumPerElement):\n",
    "            count2=count2+1\n",
    "            count=count+1\n",
    "            for key, value in AA.items():\n",
    "                #im[count,0:1,0:128,0:40] = torch.from_numpy(value)\n",
    "                im[count,0:1,0:1,0:3600] = torch.from_numpy(value.real[0:1,0:3600])\n",
    "                im[count,0:1,1:2,0:3600] = torch.from_numpy(value.imag[0:1,0:3600].copy())\n",
    "            label[count]=1\n",
    "\n",
    "        \n",
    "folder_dir ='/Users/anuraagthakur/Desktop/RawData/6CW'\n",
    "count3=0\n",
    "for images in os.listdir(folder_dir):\n",
    "    if images != '.DS_Store':\n",
    "        AA=sio.loadmat(folder_dir+'/'+images)\n",
    "        if(count3<NumPerElement):\n",
    "            count3=count3+1\n",
    "            count=count+1\n",
    "            for key, value in AA.items():\n",
    "                #im[count,0:1,0:128,0:40] = torch.from_numpy(value)\n",
    "                im[count,0:1,0:1,0:3600] = torch.from_numpy(value.real[0:1,0:3600])\n",
    "                im[count,0:1,1:2,0:3600] = torch.from_numpy(value.imag[0:1,0:3600].copy())\n",
    "            label[count]=2\n",
    "\n",
    " \n",
    "folder_dir ='/Users/anuraagthakur/Desktop/RawData/8CW'\n",
    "count4=0\n",
    "for images in os.listdir(folder_dir):   \n",
    "    if images != '.DS_Store':\n",
    "        AA=sio.loadmat(folder_dir+'/'+images)\n",
    "        if(count4<NumPerElement):\n",
    "            count4=count4+1\n",
    "            count=count+1\n",
    "            for key, value in AA.items():\n",
    "                #im[count,0:1,0:128,0:40] = torch.from_numpy(value)\n",
    "                im[count,0:1,0:1,0:3600] = torch.from_numpy(value.real[0:1,0:3600])\n",
    "                im[count,0:1,1:2,0:3600] = torch.from_numpy(value.imag[0:1,0:3600].copy())\n",
    "            label[count]=3\n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679e61c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(count)\n",
    "from sklearn.utils import shuffle\n",
    "im, label = shuffle(im, label, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc17b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split into trian and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(im, label, test_size=0.2, random_state=42)\n",
    "\n",
    "print(X_train.size())\n",
    "print(X_test.size())\n",
    "print(y_train.size())\n",
    "print(y_test.size())\n",
    "\n",
    "Length=80000\n",
    "Stride=500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774ca371",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "class MyViT(nn.Module):\n",
    "    def __init__(self, Dimensions, number_patchesRow,number_patchesColumn, number_blocks, Hidden_DGiven, NumberHeadsGiven, output_dimension):\n",
    "        # This patches up the image in user specified coumn and row patches\n",
    "        super(MyViT, self).__init__()\n",
    "        self.Dimensions = Dimensions  \n",
    "        self.number_patchesRow = number_patchesRow\n",
    "        self.number_patchesColumn=number_patchesColumn\n",
    "        self.number_blocks = number_blocks\n",
    "        self.Hidden_DGiven= Hidden_DGiven\n",
    "        self.NumberHeadsGiven = NumberHeadsGiven\n",
    "        \n",
    "        self.patch_size = (math.floor(Dimensions[1] / number_patchesRow), math.floor(Dimensions[2] / number_patchesColumn))\n",
    "        \n",
    "        self.input_d = int(Dimensions[0] * self.patch_size[0] * self.patch_size[1])\n",
    "        self.linear_mapper = nn.Linear(self.input_d, self.Hidden_DGiven)\n",
    "\n",
    "        self.class_token = nn.Parameter(torch.rand(1, self.Hidden_DGiven))\n",
    "\n",
    "        self.register_buffer(\n",
    "            \"positional_embeddings1\",\n",
    "            get_positional_embeddings1(number_patchesRow*number_patchesColumn + 1, Hidden_DGiven),\n",
    "            persistent=False,\n",
    "        )\n",
    "        \n",
    "        self.blocksA = nn.ModuleList(\n",
    "            [VisionTransformer(Hidden_DGiven, NumberHeadsGiven) for _ in range(number_blocks)]\n",
    "        )\n",
    "\n",
    "        self.mlp = nn.Sequential(nn.Linear(self.Hidden_DGiven, output_dimension), nn.Softmax(dim=-1))\n",
    "\n",
    "    def forward(self, images):        \n",
    "        n, c, h, w = images.shape\n",
    "        patches1A = images[0:n,0,0:self.patch_size[0]*self.number_patchesRow,0:self.patch_size[1]*self.number_patchesColumn]#patchify(images, self.n_patches).to(self.positional_embeddings1.device)\n",
    "        Size=72#(patches1A.size(1)*patches1A.size(2))/(self.number_patchesRow*self.number_patchesColumn)\n",
    "#        print(Size)\n",
    "        patches1=patches1A.reshape(n,self.number_patchesRow*self.number_patchesColumn,Size)\n",
    "        \n",
    "        tokens1 = self.linear_mapper(patches1)\n",
    "        tokensa = torch.cat((self.class_token.expand(n, 1, -1), tokens1), dim=1)\n",
    "\n",
    "        A    = tokensa\n",
    "\n",
    "        for block in self.blocksA:\n",
    "            A = block(A)\n",
    "        \n",
    "        output = torch.ones(n,self.Hidden_DGiven)\n",
    "        \n",
    "        output[0:n,self.Hidden_DGiven*0:self.Hidden_DGiven]  = A[:, 0]\n",
    "\n",
    "        return self.mlp(output)\n",
    "\n",
    "\n",
    "def main():\n",
    "    \n",
    "    transform = ToTensor()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = MyViT(\n",
    "        (1,2,3600), number_patchesRow=2, number_patchesColumn=50, number_blocks=10, Hidden_DGiven=10, NumberHeadsGiven=10, output_dimension=21\n",
    "    ).to(device)\n",
    "\n",
    "    NUMBER_EPOCHS = 5\n",
    "    LearningRate = 0.001\n",
    "\n",
    "    # Training Data loop\n",
    "    optimizer = Adam(model.parameters(), lr= LearningRate)\n",
    "    criterion = CrossEntropyLoss()\n",
    "\n",
    "    for epoch in trange(NUMBER_EPOCHS, desc=\"Training\"):\n",
    "        training_loss = 0.0\n",
    "        for batch in range(0,Length,Stride):\n",
    "            y = y_train[batch:batch+Stride]\n",
    "            x = X_train[batch:batch+Stride,0:1,0:2,0:3600]\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            y_hat = model(x)\n",
    "            \n",
    "            loss = criterion(y_hat, y.type(torch.LongTensor))\n",
    "            print(loss)\n",
    "            training_loss += loss.detach().cpu().item()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        print(f\"Epoch {epoch + 1}/{NUMBER_EPOCHS} loss: {training_loss:.2f}\")\n",
    "\n",
    "    # Testing loop with testing data\n",
    "    with torch.no_grad():\n",
    "        correct, total = 0, 0\n",
    "        test_loss = 0.0\n",
    "        y = y_test\n",
    "        x = X_test\n",
    "\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        y_hat = model(x)\n",
    "        loss = criterion(y_hat, y.type(torch.LongTensor))\n",
    "\n",
    "        test_loss += loss.detach().cpu().item()\n",
    "\n",
    "        correct += torch.sum(torch.argmax(y_hat, dim=1) == y).detach().cpu().item()\n",
    "        total += len(x)\n",
    "        print(f\"Test loss: {test_loss:.2f}\")\n",
    "        cm = confusion_matrix(y_hat, y)\n",
    "        print(f\"Test accuracy: {correct / total * 100:.2f}%\")\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa43983",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6bc8d95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c7029c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa72366c-5ad5-4d79-8402-84ad74e8ee33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c9eed0-a892-44a3-9c38-8d08b6e05043",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c44942a-0306-4d68-b029-b6195f7eecfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b31e9b-ee68-4ef9-a74b-51ffdbd82268",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb10bdc-d1be-4878-89c4-04f670f8859b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ad6e44-a580-45de-8b87-52954c66dc5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3040f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8f6916-5e41-4d90-ad9b-f7dac50e8f0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49cb1f4-6e20-4ee1-a860-d39e32d254bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5338e04-f157-4be2-b39f-da4b50e1bf6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c94180-e3b8-4519-936c-cc5dc3090e01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ee0f7a-8ec9-4a29-9084-3eb69d2c6769",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d04beb-15c3-46d0-8ba4-d2596fc0b0dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c32d6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc74b4b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d2e7e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cec9237",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b66e02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9387b1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import scipy.io as sio\n",
    "from os import listdir\n",
    "from skimage import io\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets.mnist import MNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "from tqdm import tqdm, trange\n",
    "import math   \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Install Data as it is saved from MATLAB\n",
    "\n",
    "NumPerElement=99999+1\n",
    "\n",
    "im=torch.zeros(NumPerElement,1,2,3600)\n",
    "#im=torch.zeros(NumPerElement,1,128,40)\n",
    "label=torch.zeros(NumPerElement)\n",
    "\n",
    "count1=0\n",
    "count=-1\n",
    "folder_dir ='/Users/anuraagthakur/Desktop/IQData/FSK2'\n",
    "for images in os.listdir(folder_dir):\n",
    "    if images != '.DS_Store':\n",
    "        AA=sio.loadmat(folder_dir+'/'+images)\n",
    "        if(count1<NumPerElement):\n",
    "            count1=count1+1\n",
    "            count=count+1\n",
    "            for key, value in AA.items():\n",
    "                #im[count,0:1,0:128,0:40] = torch.from_numpy(value)\n",
    "                im[count,0:1,0:1,0:3600] = torch.from_numpy(value.real[0:1,0:3600])\n",
    "                im[count,0:1,1:2,0:3600] = torch.from_numpy(value.imag[0:1,0:3600].copy())\n",
    "            label[count]=0\n",
    "\n",
    "            \n",
    "folder_dir ='/Users/anuraagthakur/Desktop/IQData/FSK4'\n",
    "count2=0\n",
    "for images in os.listdir(folder_dir):\n",
    "    if images != '.DS_Store':\n",
    "        AA=sio.loadmat(folder_dir+'/'+images)\n",
    "        if(count2<NumPerElement):\n",
    "            count2=count2+1\n",
    "            count=count+1\n",
    "            for key, value in AA.items():\n",
    "                #im[count,0:1,0:128,0:40] = torch.from_numpy(value)\n",
    "                im[count,0:1,0:1,0:3600] = torch.from_numpy(value.real[0:1,0:3600])\n",
    "                im[count,0:1,1:2,0:3600] = torch.from_numpy(value.imag[0:1,0:3600].copy())\n",
    "            label[count]=1\n",
    "\n",
    "        \n",
    "folder_dir ='/Users/anuraagthakur/Desktop/IQData/FSK8'\n",
    "count3=0\n",
    "for images in os.listdir(folder_dir):\n",
    "    if images != '.DS_Store':\n",
    "        AA=sio.loadmat(folder_dir+'/'+images)\n",
    "        if(count3<NumPerElement):\n",
    "            count3=count3+1\n",
    "            count=count+1\n",
    "            for key, value in AA.items():\n",
    "                #im[count,0:1,0:128,0:40] = torch.from_numpy(value)\n",
    "                im[count,0:1,0:1,0:3600] = torch.from_numpy(value.real[0:1,0:3600])\n",
    "                im[count,0:1,1:2,0:3600] = torch.from_numpy(value.imag[0:1,0:3600].copy())\n",
    "            label[count]=2\n",
    "\n",
    " \n",
    "folder_dir ='/Users/anuraagthakur/Desktop/IQData/FSK16'\n",
    "count4=0\n",
    "for images in os.listdir(folder_dir):   \n",
    "    if images != '.DS_Store':\n",
    "        AA=sio.loadmat(folder_dir+'/'+images)\n",
    "        if(count4<NumPerElement):\n",
    "            count4=count4+1\n",
    "            count=count+1\n",
    "            for key, value in AA.items():\n",
    "                #im[count,0:1,0:128,0:40] = torch.from_numpy(value)\n",
    "                im[count,0:1,0:1,0:3600] = torch.from_numpy(value.real[0:1,0:3600])\n",
    "                im[count,0:1,1:2,0:3600] = torch.from_numpy(value.imag[0:1,0:3600].copy())\n",
    "            label[count]=3\n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae37aa5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([80000, 1, 2, 3600])\n",
      "torch.Size([20000, 1, 2, 3600])\n",
      "torch.Size([80000])\n",
      "torch.Size([20000])\n"
     ]
    }
   ],
   "source": [
    "#Split into trian and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(im, label, test_size=0.2, random_state=42)\n",
    "\n",
    "print(X_train.size())\n",
    "print(X_test.size())\n",
    "print(y_train.size())\n",
    "print(y_test.size())\n",
    "\n",
    "Length=80000\n",
    "Stride=500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "35235c95",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:   0%|                                           | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.4391, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4191, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3983, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3952, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3915, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3871, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3928, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3985, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3873, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3891, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3907, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3854, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3887, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3927, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3891, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3909, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3893, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3894, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3914, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3947, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3876, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3894, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3873, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3867, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3918, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3866, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3864, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3909, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3880, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3837, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3826, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3875, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3885, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3883, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3848, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3884, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3864, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3856, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3863, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3881, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3872, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3875, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3857, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3869, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3891, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3875, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3856, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3862, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3880, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3871, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3829, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3862, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3860, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3886, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3892, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3861, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3861, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3865, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3856, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3849, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3871, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3851, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3866, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3881, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3875, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3850, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3885, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3853, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3880, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3869, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3873, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3884, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3872, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3866, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3876, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3853, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3884, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3859, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3871, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3876, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3860, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3862, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3874, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3862, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3865, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3863, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3857, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3864, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3871, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3865, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3847, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3870, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3882, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3880, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3880, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3861, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3843, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3864, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3877, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3874, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3868, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3875, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3867, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3853, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3884, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3864, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3853, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3869, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3846, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3898, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3914, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3877, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3853, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3884, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3883, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3876, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3882, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3855, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3855, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3857, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3865, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3866, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3866, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3853, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3862, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3876, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3846, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3831, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3869, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3861, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3846, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3816, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3847, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3916, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3858, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3920, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3866, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3870, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3876, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3859, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3875, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3860, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3856, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3889, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3871, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3876, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3891, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3858, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3855, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3865, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3857, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3873, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3866, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3861, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3866, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3875, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3888, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3840, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3861, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3883, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:  25%|████████▌                         | 1/4 [13:53<41:39, 833.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 loss: 222.05\n",
      "tensor(1.3898, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3897, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3857, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3861, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3863, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3852, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3860, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3858, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3854, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3895, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3848, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3862, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3873, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3872, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3859, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3861, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3881, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3884, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3869, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3864, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3862, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3860, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3852, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3856, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3852, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3872, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3873, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3863, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3848, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3854, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3857, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3869, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3852, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3860, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3868, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3879, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3855, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3863, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3852, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3879, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3859, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3869, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3851, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3857, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3886, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3867, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3860, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3857, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3872, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3866, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3844, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3863, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3856, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3880, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3885, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3856, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3859, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3865, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3867, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3845, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3861, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3869, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3864, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3867, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3875, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3839, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3871, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3850, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3874, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3864, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3871, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3880, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3871, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3867, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3872, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3855, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3877, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3861, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3866, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3870, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3859, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3860, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3867, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3863, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3863, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3862, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3861, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3862, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3867, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3866, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3854, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3864, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3876, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3876, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3870, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3862, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3851, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3863, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3869, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3863, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3864, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3866, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3864, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3857, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3879, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3861, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3856, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3869, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3849, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3886, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3888, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3871, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3847, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3873, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3858, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3873, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3873, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3848, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3855, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3866, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3865, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3859, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3874, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3860, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3878, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3863, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3848, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3845, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3862, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3863, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3847, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3830, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3849, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3902, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3850, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3913, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3867, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3867, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3885, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3851, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3884, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3848, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3853, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3889, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3864, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3869, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3872, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3854, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3854, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3866, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3854, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3869, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3862, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3859, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3863, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3871, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3880, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3850, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3864, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3874, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:  50%|█████████████████                 | 2/4 [27:04<26:56, 808.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/4 loss: 221.83\n",
      "tensor(1.3889, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3886, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3857, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3858, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3864, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3856, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3860, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3861, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3859, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3886, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3852, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3863, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3869, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3865, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3861, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3861, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3871, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3878, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3866, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3859, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3865, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3860, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3856, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3858, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3850, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3869, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3871, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3859, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3851, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3857, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3862, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3865, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3852, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3861, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3866, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3875, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3860, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3866, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3854, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3871, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3852, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3865, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3852, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3856, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3885, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3865, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3859, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3857, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3869, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3865, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3850, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3861, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3855, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3877, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3886, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3852, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3862, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3865, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3863, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3846, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3861, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3864, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3861, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3866, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3878, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3842, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3867, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3853, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3873, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3865, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3868, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3880, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3874, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3867, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3869, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3855, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3869, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3862, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3865, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3869, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3858, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3855, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3862, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3866, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3859, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3863, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3862, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3860, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3864, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3866, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3859, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3862, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3873, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3872, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3866, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3863, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3856, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3861, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3865, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3860, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3864, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3863, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3862, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3859, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3875, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3859, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3859, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3868, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3853, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3880, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3877, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3869, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3850, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3870, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3845, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3870, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3868, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3849, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3850, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3862, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3869, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3864, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3868, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3853, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3878, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3862, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3851, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3845, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3860, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3866, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3846, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3833, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3852, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3896, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3852, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3905, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3866, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3866, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3884, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3848, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3892, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3846, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3855, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3885, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3862, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3868, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3863, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3855, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3858, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3869, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3859, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3870, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3859, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3857, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3864, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3872, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3878, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3853, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3864, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3864, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:  75%|█████████████████████████▌        | 3/4 [39:11<12:51, 771.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/4 loss: 221.82\n",
      "tensor(1.3882, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3878, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3860, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3861, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3865, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3858, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3860, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3865, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3859, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3880, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3856, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3861, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3867, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3864, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3861, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3861, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3868, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3875, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3866, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3860, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3864, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3862, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3857, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3858, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3854, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3867, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3868, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3861, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3852, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3857, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3861, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3865, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3854, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3860, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3866, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3873, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3859, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3864, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3854, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3870, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3852, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3863, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3852, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3857, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3883, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3863, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3857, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3857, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3869, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3866, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3849, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3859, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3857, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3880, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3888, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3854, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3862, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3864, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3860, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3845, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3861, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3864, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3861, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3867, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3879, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3845, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3868, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3854, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3874, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3867, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3868, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3879, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3875, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3865, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3868, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3853, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3870, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3862, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3863, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3868, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3859, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3859, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3865, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3864, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3860, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3862, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3863, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3862, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3865, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3867, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3858, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3860, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3872, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3871, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3866, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3863, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3857, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3864, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3866, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3861, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3865, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3863, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3862, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3860, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3873, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3859, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3862, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3866, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3856, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3873, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3878, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3865, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3854, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3870, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3845, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3876, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3865, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3850, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3851, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3860, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3872, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3870, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3865, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3848, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3869, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3869, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3852, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3834, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3861, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3865, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3840, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3825, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3850, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3903, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3851, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3914, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3867, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3868, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3882, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3848, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3887, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3852, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3850, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3888, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3861, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3871, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3874, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3857, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3856, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3865, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3855, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3868, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3857, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3855, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3863, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3870, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3881, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3856, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3864, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3860, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████| 4/4 [53:37<00:00, 804.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/4 loss: 221.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.39\n",
      "Test accuracy: 25.30%\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "class MyViT(nn.Module):\n",
    "    def __init__(self, Dimensions, number_patchesRow,number_patchesColumn, number_blocks, Hidden_DGiven, NumberHeadsGiven, output_dimension):\n",
    "        # This patches up the image in user specified coumn and row patches\n",
    "        super(MyViT, self).__init__()\n",
    "        self.Dimensions = Dimensions  \n",
    "        self.number_patchesRow = number_patchesRow\n",
    "        self.number_patchesColumn=number_patchesColumn\n",
    "        self.number_blocks = number_blocks\n",
    "        self.Hidden_DGiven= Hidden_DGiven\n",
    "        self.NumberHeadsGiven = NumberHeadsGiven\n",
    "        \n",
    "        self.patch_size = (math.floor(Dimensions[1] / number_patchesRow), math.floor(Dimensions[2] / number_patchesColumn))\n",
    "        \n",
    "        self.input_d = int(Dimensions[0] * self.patch_size[0] * self.patch_size[1])\n",
    "        self.linear_mapper = nn.Linear(self.input_d, self.Hidden_DGiven)\n",
    "\n",
    "        self.class_token = nn.Parameter(torch.rand(1, self.Hidden_DGiven))\n",
    "\n",
    "        self.register_buffer(\n",
    "            \"positional_embeddings1\",\n",
    "            get_positional_embeddings1(number_patchesRow*number_patchesColumn + 1, Hidden_DGiven),\n",
    "            persistent=False,\n",
    "        )\n",
    "        \n",
    "        self.blocksA = nn.ModuleList(\n",
    "            [VisionTransformer(Hidden_DGiven, NumberHeadsGiven) for _ in range(number_blocks)]\n",
    "        )\n",
    "\n",
    "        self.mlp = nn.Sequential(nn.Linear(self.Hidden_DGiven, output_dimension), nn.Softmax(dim=-1))\n",
    "\n",
    "    def forward(self, images):        \n",
    "        n, c, h, w = images.shape\n",
    "        patches1A = images[0:n,0,0:self.patch_size[0]*self.number_patchesRow,0:self.patch_size[1]*self.number_patchesColumn]#patchify(images, self.n_patches).to(self.positional_embeddings1.device)\n",
    "        Size=72#(patches1A.size(1)*patches1A.size(2))/(self.number_patchesRow*self.number_patchesColumn)\n",
    "#        print(Size)\n",
    "        patches1=patches1A.reshape(n,self.number_patchesRow*self.number_patchesColumn,Size)\n",
    "        \n",
    "        tokens1 = self.linear_mapper(patches1)\n",
    "        tokensa = torch.cat((self.class_token.expand(n, 1, -1), tokens1), dim=1)\n",
    "\n",
    "        A    = tokensa\n",
    "\n",
    "        for block in self.blocksA:\n",
    "            A = block(A)\n",
    "        \n",
    "        output = torch.ones(n,self.Hidden_DGiven)\n",
    "        \n",
    "        output[0:n,self.Hidden_DGiven*0:self.Hidden_DGiven]  = A[:, 0]\n",
    "\n",
    "        return self.mlp(output)\n",
    "\n",
    "\n",
    "def main():\n",
    "    \n",
    "    transform = ToTensor()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = MyViT(\n",
    "        (1,2,3600), number_patchesRow=2, number_patchesColumn=50, number_blocks=5, Hidden_DGiven=5, NumberHeadsGiven=5, output_dimension=4\n",
    "    ).to(device)\n",
    "\n",
    "    NUMBER_EPOCHS = 4\n",
    "    LearningRate = 0.002\n",
    "\n",
    "    # Training Data loop\n",
    "    optimizer = Adam(model.parameters(), lr= LearningRate)\n",
    "    criterion = CrossEntropyLoss()\n",
    "\n",
    "    for epoch in trange(NUMBER_EPOCHS, desc=\"Training\"):\n",
    "        training_loss = 0.0\n",
    "        for batch in range(0,Length,Stride):\n",
    "            y = y_train[batch:batch+Stride]\n",
    "            x = X_train[batch:batch+Stride,0:1,0:2,0:3600]\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            y_hat = model(x)\n",
    "            \n",
    "            loss = criterion(y_hat, y.type(torch.LongTensor))\n",
    "            print(loss)\n",
    "            training_loss += loss.detach().cpu().item()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        print(f\"Epoch {epoch + 1}/{NUMBER_EPOCHS} loss: {training_loss:.2f}\")\n",
    "\n",
    "    # Testing loop with testing data\n",
    "    with torch.no_grad():\n",
    "        correct, total = 0, 0\n",
    "        test_loss = 0.0\n",
    "        y = y_test\n",
    "        x = X_test\n",
    "\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        y_hat = model(x)\n",
    "        loss = criterion(y_hat, y.type(torch.LongTensor))\n",
    "\n",
    "        test_loss += loss.detach().cpu().item()\n",
    "\n",
    "        correct += torch.sum(torch.argmax(y_hat, dim=1) == y).detach().cpu().item()\n",
    "        total += len(x)\n",
    "        print(f\"Test loss: {test_loss:.2f}\")\n",
    "        print(f\"Test accuracy: {correct / total * 100:.2f}%\")\n",
    "main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8115ca9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c9640f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af6d198",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e1019e43",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                                           | 0/5 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "reshape(): argument 'shape' failed to unpack the object at pos 3 with error \"type must be tuple of ints,but got float\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/kz/23c67y1112113d31_lhlx3_h0000gn/T/ipykernel_52577/670003322.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0mcm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Test accuracy: {correct / total * 100:.2f}%\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/kz/23c67y1112113d31_lhlx3_h0000gn/T/ipykernel_52577/670003322.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mStride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3600\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m             \u001b[0my_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/kz/23c67y1112113d31_lhlx3_h0000gn/T/ipykernel_52577/670003322.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, images)\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mSize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatches1A\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpatches1A\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber_patchesRow\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber_patchesColumn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mpatches1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpatches1A\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber_patchesRow\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber_patchesColumn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mSize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mtokens1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_mapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatches1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: reshape(): argument 'shape' failed to unpack the object at pos 3 with error \"type must be tuple of ints,but got float\""
     ]
    }
   ],
   "source": [
    "import math\n",
    "class MyViT(nn.Module):\n",
    "    def __init__(self, Dimensions, number_patchesRow,number_patchesColumn, number_blocks, Hidden_DGiven, NumberHeadsGiven, output_dimension):\n",
    "        # This patches up the image in user specified coumn and row patches\n",
    "        super(MyViT, self).__init__()\n",
    "        self.Dimensions = Dimensions  \n",
    "        self.number_patchesRow = number_patchesRow\n",
    "        self.number_patchesColumn=number_patchesColumn\n",
    "        self.number_blocks = number_blocks\n",
    "        self.Hidden_DGiven= Hidden_DGiven\n",
    "        self.NumberHeadsGiven = NumberHeadsGiven\n",
    "        \n",
    "        self.patch_size = (math.floor(Dimensions[1] / number_patchesRow), math.floor(Dimensions[2] / number_patchesColumn))\n",
    "        \n",
    "        self.input_d = int(Dimensions[0] * self.patch_size[0] * self.patch_size[1])\n",
    "        self.linear_mapper = nn.Linear(self.input_d, self.Hidden_DGiven)\n",
    "\n",
    "        self.class_token = nn.Parameter(torch.rand(1, self.Hidden_DGiven))\n",
    "\n",
    "        self.register_buffer(\n",
    "            \"positional_embeddings1\",\n",
    "            get_positional_embeddings1(number_patchesRow*number_patchesColumn + 1, Hidden_DGiven),\n",
    "            persistent=False,\n",
    "        )\n",
    "        \n",
    "        self.blocksA = nn.ModuleList(\n",
    "            [VisionTransformer(Hidden_DGiven, NumberHeadsGiven) for _ in range(number_blocks)]\n",
    "        )\n",
    "\n",
    "        self.mlp = nn.Sequential(nn.Linear(self.Hidden_DGiven, output_dimension), nn.Softmax(dim=-1))\n",
    "\n",
    "    def forward(self, images):        \n",
    "        n, c, h, w = images.shape\n",
    "        patches1A = images[0:n,0,0:self.patch_size[0]*self.number_patchesRow,0:self.patch_size[1]*self.number_patchesColumn]#patchify(images, self.n_patches).to(self.positional_embeddings1.device)\n",
    "        Size=72#(patches1A.size(1)*patches1A.size(2))/(self.number_patchesRow*self.number_patchesColumn)\n",
    "#        print(Size)\n",
    "        patches1=patches1A.reshape(n,self.number_patchesRow*self.number_patchesColumn,Size)\n",
    "        \n",
    "        tokens1 = self.linear_mapper(patches1)\n",
    "        tokensa = torch.cat((self.class_token.expand(n, 1, -1), tokens1), dim=1)\n",
    "\n",
    "        A    = tokensa\n",
    "\n",
    "        for block in self.blocksA:\n",
    "            A = block(A)\n",
    "        \n",
    "        output = torch.ones(n,self.Hidden_DGiven)\n",
    "        \n",
    "        output[0:n,self.Hidden_DGiven*0:self.Hidden_DGiven]  = A[:, 0]\n",
    "\n",
    "        return self.mlp(output)\n",
    "\n",
    "\n",
    "def main():\n",
    "    \n",
    "    transform = ToTensor()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = MyViT(\n",
    "        (1,2,3600), number_patchesRow=2, number_patchesColumn=50, number_blocks=4, Hidden_DGiven=4, NumberHeadsGiven=4, output_dimension=7\n",
    "    ).to(device)\n",
    "\n",
    "    NUMBER_EPOCHS = 5\n",
    "    LearningRate = 0.002\n",
    "\n",
    "    # Training Data loop\n",
    "    optimizer = Adam(model.parameters(), lr= LearningRate)\n",
    "    criterion = CrossEntropyLoss()\n",
    "\n",
    "    for epoch in trange(NUMBER_EPOCHS, desc=\"Training\"):\n",
    "        training_loss = 0.0\n",
    "        for batch in range(0,Length,Stride):\n",
    "            y = y_train[batch:batch+Stride]\n",
    "            x = X_train[batch:batch+Stride,0:1,0:2,0:3600]\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            y_hat = model(x)\n",
    "            \n",
    "            loss = criterion(y_hat, y.type(torch.LongTensor))\n",
    "            print(loss)\n",
    "            training_loss += loss.detach().cpu().item()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        print(f\"Epoch {epoch + 1}/{NUMBER_EPOCHS} loss: {training_loss:.2f}\")\n",
    "\n",
    "    # Testing loop with testing data\n",
    "    with torch.no_grad():\n",
    "        correct, total = 0, 0\n",
    "        test_loss = 0.0\n",
    "        y = y_test\n",
    "        x = X_test\n",
    "\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        y_hat = model(x)\n",
    "        loss = criterion(y_hat, y.type(torch.LongTensor))\n",
    "\n",
    "        test_loss += loss.detach().cpu().item()\n",
    "\n",
    "        correct += torch.sum(torch.argmax(y_hat, dim=1) == y).detach().cpu().item()\n",
    "        total += len(x)\n",
    "        print(f\"Test loss: {test_loss:.2f}\")\n",
    "        cm = confusion_matrix(y_hat, y)\n",
    "        print(f\"Test accuracy: {correct / total * 100:.2f}%\")\n",
    "main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d1f769",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fc173e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "class MyViT(nn.Module):\n",
    "    def __init__(self, Dimensions, number_patchesRow,number_patchesColumn, number_blocks, Hidden_DGiven, NumberHeadsGiven, output_dimension):\n",
    "        \n",
    "        super(MyViT, self).__init__()\n",
    "        self.Dimensions = Dimensions  \n",
    "        self.number_patchesRow = number_patchesRow\n",
    "        self.number_patchesColumn=number_patchesColumn\n",
    "        self.number_blocks = number_blocks\n",
    "        self.Hidden_DGiven= Hidden_DGiven\n",
    "        self.NumberHeadsGiven = NumberHeadsGiven\n",
    "        \n",
    "        self.patch_size = (math.floor(Dimensions[1] / number_patchesRow), math.floor(Dimensions[2] / number_patchesColumn))\n",
    "        \n",
    "        self.input_d = int(Dimensions[0] * self.patch_size[0] * self.patch_size[1])\n",
    "        self.linear_mapper = nn.Linear(self.input_d, self.Hidden_DGiven)\n",
    "\n",
    "        self.class_token = nn.Parameter(torch.rand(1, self.Hidden_DGiven))\n",
    "\n",
    "        self.register_buffer(\n",
    "            \"positional_embeddings1\",\n",
    "            get_positional_embeddings1(number_patchesRow*number_patchesColumn + 1, Hidden_DGiven),\n",
    "            persistent=False,\n",
    "        )\n",
    "        \n",
    "        self.blocksA = nn.ModuleList(\n",
    "            [VisionTransformer(Hidden_DGiven, NumberHeadsGiven) for _ in range(number_blocks)]\n",
    "        )\n",
    "\n",
    "        self.mlp = nn.Sequential(nn.Linear(self.Hidden_DGiven, output_dimension), nn.Softmax(dim=-1))\n",
    "\n",
    "    def forward(self, images):        \n",
    "        n, c, h, w = images.shape\n",
    "        patches1A = images[0:n,0,0:self.patch_size[0]*self.number_patchesRow,0:self.patch_size[1]*self.number_patchesColumn]#patchify(images, self.n_patches).to(self.positional_embeddings1.device)\n",
    "        Size=64#(patches1A.size(1)*patches1A.size(2))/(self.number_patchesRow*self.number_patchesColumn)\n",
    "        #print(Size)\n",
    "        patches1=patches1A.reshape(n,self.number_patchesRow*self.number_patchesColumn,Size)\n",
    "        \n",
    "        tokens1 = self.linear_mapper(patches1)\n",
    "        tokensa = torch.cat((self.class_token.expand(n, 1, -1), tokens1), dim=1)\n",
    "\n",
    "        A    = tokensa + self.positional_embeddings1.repeat(n, 1, 1) \n",
    "\n",
    "        for block in self.blocksA:\n",
    "            A = block(A)\n",
    "        \n",
    "        output = torch.ones(n,self.Hidden_DGiven)\n",
    "        \n",
    "        output[0:n,self.Hidden_DGiven*0:self.Hidden_DGiven]  = A[:, 0]\n",
    "\n",
    "        return self.mlp(output)\n",
    "\n",
    "\n",
    "def main():\n",
    "    \n",
    "    transform = ToTensor()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = MyViT(\n",
    "        (1, 128,40), number_patchesRow=16, number_patchesColumn=5, number_blocks=2, Hidden_DGiven=5, NumberHeadsGiven=5, output_dimension=5\n",
    "    ).to(device)\n",
    "\n",
    "    NUMBER_EPOCHS = 3\n",
    "    LearningRate = 0.003\n",
    "\n",
    "    # Training Data loop\n",
    "    optimizer = Adam(model.parameters(), lr= LearningRate)\n",
    "    criterion = CrossEntropyLoss()\n",
    "\n",
    "    for epoch in trange(NUMBER_EPOCHS, desc=\"Training\"):\n",
    "        training_loss = 0.0\n",
    "        for batch in range(0,Length,Stride):\n",
    "            y = y_train[batch:batch+Stride]\n",
    "            x = X_train[batch:batch+Stride,0:1,0:128,0:40]\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            y_hat = model(x)\n",
    "            \n",
    "            loss = criterion(y_hat, y.type(torch.LongTensor))\n",
    "            print(loss)\n",
    "            training_loss += loss.detach().cpu().item()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        print(f\"Epoch {epoch + 1}/{NUMBER_EPOCHS} loss: {training_loss:.2f}\")\n",
    "\n",
    "    # Testing loop with testing data\n",
    "    with torch.no_grad():\n",
    "        correct, total = 0, 0\n",
    "        test_loss = 0.0\n",
    "        y = y_test\n",
    "        x = X_test\n",
    "\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        y_hat = model(x)\n",
    "        loss = criterion(y_hat, y.type(torch.LongTensor))\n",
    "\n",
    "        test_loss += loss.detach().cpu().item()\n",
    "\n",
    "        correct += torch.sum(torch.argmax(y_hat, dim=1) == y).detach().cpu().item()\n",
    "        total += len(x)\n",
    "        print(f\"Test loss: {test_loss:.2f}\")\n",
    "        print(f\"Test accuracy: {correct / total * 100:.2f}%\")\n",
    "main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc84f58",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "class MyViT(nn.Module):\n",
    "    def __init__(self, Dimensions, number_patchesRow,number_patchesColumn, number_blocks, Hidden_DGiven, NumberHeadsGiven, output_dimension):\n",
    "        \n",
    "        super(MyViT, self).__init__()\n",
    "        self.Dimensions = Dimensions  \n",
    "        self.number_patchesRow = number_patchesRow\n",
    "        self.number_patchesColumn=number_patchesColumn\n",
    "        self.number_blocks = number_blocks\n",
    "        self.Hidden_DGiven= Hidden_DGiven\n",
    "        self.NumberHeadsGiven = NumberHeadsGiven\n",
    "        \n",
    "        self.patch_size = (math.floor(Dimensions[1] / number_patchesRow), math.floor(Dimensions[2] / number_patchesColumn))\n",
    "        \n",
    "        self.input_d = int(Dimensions[0] * self.patch_size[0] * self.patch_size[1])\n",
    "        self.linear_mapper = nn.Linear(self.input_d, self.Hidden_DGiven)\n",
    "\n",
    "        self.class_token = nn.Parameter(torch.rand(1, self.Hidden_DGiven))\n",
    "\n",
    "        self.register_buffer(\n",
    "            \"positional_embeddings1\",\n",
    "            get_positional_embeddings2(number_patchesRow*number_patchesColumn + 1, Hidden_DGiven),\n",
    "            persistent=False,\n",
    "        )\n",
    "        \n",
    "        self.blocksA = nn.ModuleList(\n",
    "            [VisionTransformer(Hidden_DGiven, NumberHeadsGiven) for _ in range(number_blocks)]\n",
    "        )\n",
    "\n",
    "        self.mlp = nn.Sequential(nn.Linear(self.Hidden_DGiven, output_dimension), nn.Softmax(dim=-1))\n",
    "\n",
    "    def forward(self, images):        \n",
    "        n, c, h, w = images.shape\n",
    "        patches1A = images[0:n,0,0:self.patch_size[0]*self.number_patchesRow,0:self.patch_size[1]*self.number_patchesColumn]#patchify(images, self.n_patches).to(self.positional_embeddings1.device)\n",
    "        Size=64#(patches1A.size(1)*patches1A.size(2))/(self.number_patchesRow*self.number_patchesColumn)\n",
    "        #print(Size)\n",
    "        patches1=patches1A.reshape(n,self.number_patchesRow*self.number_patchesColumn,Size)\n",
    "        \n",
    "        tokens1 = self.linear_mapper(patches1)\n",
    "        tokensa = torch.cat((self.class_token.expand(n, 1, -1), tokens1), dim=1)\n",
    "\n",
    "        A    = tokensa + self.positional_embeddings1.repeat(n, 1, 1) \n",
    "\n",
    "        for block in self.blocksA:\n",
    "            A = block(A)\n",
    "        \n",
    "        output = torch.ones(n,self.Hidden_DGiven)\n",
    "        \n",
    "        output[0:n,self.Hidden_DGiven*0:self.Hidden_DGiven]  = A[:, 0]\n",
    "\n",
    "        return self.mlp(output)\n",
    "\n",
    "\n",
    "def main():\n",
    "    \n",
    "    transform = ToTensor()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = MyViT(\n",
    "        (1, 128,40), number_patchesRow=16, number_patchesColumn=5, number_blocks=2, Hidden_DGiven=5, NumberHeadsGiven=5, output_dimension=5\n",
    "    ).to(device)\n",
    "\n",
    "    NUMBER_EPOCHS = 3\n",
    "    LearningRate = 0.003\n",
    "\n",
    "    # Training Data loop\n",
    "    optimizer = Adam(model.parameters(), lr= LearningRate)\n",
    "    criterion = CrossEntropyLoss()\n",
    "\n",
    "    for epoch in trange(NUMBER_EPOCHS, desc=\"Training\"):\n",
    "        training_loss = 0.0\n",
    "        for batch in range(0,Length,Stride):\n",
    "            y = y_train[batch:batch+Stride]\n",
    "            x = X_train[batch:batch+Stride,0:1,0:128,0:40]\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            y_hat = model(x)\n",
    "            \n",
    "            loss = criterion(y_hat, y.type(torch.LongTensor))\n",
    "            print(loss)\n",
    "            training_loss += loss.detach().cpu().item()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        print(f\"Epoch {epoch + 1}/{NUMBER_EPOCHS} loss: {training_loss:.2f}\")\n",
    "\n",
    "    # Testing loop with testing data\n",
    "    with torch.no_grad():\n",
    "        correct, total = 0, 0\n",
    "        test_loss = 0.0\n",
    "        y = y_test\n",
    "        x = X_test\n",
    "\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        y_hat = model(x)\n",
    "        loss = criterion(y_hat, y.type(torch.LongTensor))\n",
    "\n",
    "        test_loss += loss.detach().cpu().item()\n",
    "\n",
    "        correct += torch.sum(torch.argmax(y_hat, dim=1) == y).detach().cpu().item()\n",
    "        total += len(x)\n",
    "        print(f\"Test loss: {test_loss:.2f}\")\n",
    "        print(f\"Test accuracy: {correct / total * 100:.2f}%\")\n",
    "main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1faeea8d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:   0%|                                           | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.6223, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6142, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6115, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6090, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6051, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6051, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6068, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6059, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5989, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5968, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5992, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5973, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5921, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5861, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5880, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5829, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5817, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5723, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5708, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5682, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5551, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5549, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5486, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5447, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5355, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5299, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5181, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5140, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5014, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5031, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4934, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4892, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4787, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4671, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4609, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4515, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4348, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4371, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4413, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4221, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4083, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4044, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3980, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3891, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3953, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3750, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3663, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3611, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3435, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3555, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3337, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3318, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3386, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3381, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3280, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3208, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3157, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3085, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2944, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3027, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3154, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2911, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3007, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2998, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2957, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2825, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2852, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2935, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2823, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2718, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2909, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2863, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2795, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2912, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2917, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2892, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2675, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2662, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2592, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2791, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2746, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2450, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2679, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2640, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2643, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2594, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2919, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2928, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2652, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2511, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2731, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2834, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2666, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2738, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2677, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2583, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2590, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2610, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2668, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2571, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2816, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2791, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2606, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2722, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2926, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2637, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2657, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2488, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2626, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2625, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2381, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2653, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2560, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2720, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2675, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2645, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2645, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2494, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2676, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2639, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2705, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2719, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2533, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2615, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2736, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2561, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2679, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2896, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2486, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2612, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2551, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2640, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2498, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2540, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2747, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2671, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2467, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2456, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2513, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2709, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2659, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2662, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2652, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2462, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2564, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2524, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2500, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2536, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2707, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2519, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2563, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2674, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2339, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2642, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2520, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2542, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2390, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2467, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2542, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2487, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2569, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2514, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2466, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2414, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2520, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2363, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2418, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2381, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2262, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2248, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2421, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2286, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2436, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2308, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2421, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2431, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2353, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2421, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2387, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2378, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2253, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2276, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2365, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2266, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2222, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2295, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2376, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2271, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2411, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2110, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2289, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.2414, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2317, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2274, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2165, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2129, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2229, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2059, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2314, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2112, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2287, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2268, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2411, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2127, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2268, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2198, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2432, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2369, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2285, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2254, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2344, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2231, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2163, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2342, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2223, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2349, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2171, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2181, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2254, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2192, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2120, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2159, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2257, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2367, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2380, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2232, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2159, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2130, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2188, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2353, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2207, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2339, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2082, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2224, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2180, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2194, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2134, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2250, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2301, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2284, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2158, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2098, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2137, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1979, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2044, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2352, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2164, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2097, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2298, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2186, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2157, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2127, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2150, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2103, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2101, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2153, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2034, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2209, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2257, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2088, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2400, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2268, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2182, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2190, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2020, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1898, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2089, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2154, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2076, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1958, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2193, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2173, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2219, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1978, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2022, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2138, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1999, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2199, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2033, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2026, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2311, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2015, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2036, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1938, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2091, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2130, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2082, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1994, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2042, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1948, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2003, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2079, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1864, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1964, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2041, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1889, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1793, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1832, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1902, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1908, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1751, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1985, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1621, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1567, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1717, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1591, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1580, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1431, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1307, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1285, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1195, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1287, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1176, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1083, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1195, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1342, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0970, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1084, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0962, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1087, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:  33%|███████████                      | 1/3 [18:10<36:21, 1090.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 loss: 409.01\n",
      "tensor(1.1057, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0910, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0947, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1113, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0916, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0929, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0977, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0791, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0800, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0853, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0966, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0851, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0913, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0896, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0738, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0810, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0789, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0735, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0831, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0833, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0826, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0802, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0835, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1185, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1081, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0723, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0800, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0741, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0533, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0781, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0676, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0858, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0840, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0843, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0736, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0879, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0489, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0793, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0880, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0722, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0799, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0738, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0714, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0884, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0846, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0831, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0594, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0720, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0720, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0638, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0769, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0474, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0744, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0849, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0722, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0670, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0683, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0619, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0578, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0770, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0948, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0725, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0595, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0863, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0584, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0444, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0741, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0600, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0664, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0591, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0382, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0707, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0658, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0720, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0707, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0887, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0722, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0769, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0525, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0631, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0523, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0505, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0615, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0397, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0572, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0330, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0763, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0501, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0512, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0490, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0500, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0671, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0562, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0749, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0483, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0466, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0527, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0652, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0533, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0402, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0618, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0790, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0441, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0641, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0662, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0655, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0463, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0457, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0598, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0490, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0390, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0538, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0397, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0460, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0533, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0487, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0540, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0526, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0512, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0656, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0574, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0669, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0535, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0398, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0640, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0377, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0577, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0803, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0641, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0532, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0488, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0470, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0422, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0486, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0593, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0443, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0438, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0531, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0426, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0533, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0463, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0469, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0616, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0627, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0688, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0544, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0513, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0420, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0848, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0570, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0801, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0542, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0484, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0789, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0521, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0616, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0460, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0423, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0484, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0502, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0580, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0559, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0479, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0655, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0633, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0415, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0535, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0446, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0262, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0559, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0605, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0459, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0759, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0463, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0554, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0366, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0589, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0572, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0383, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0414, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0422, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0397, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0478, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0463, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0538, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0419, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0359, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0205, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0461, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0287, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0432, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0419, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0395, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0432, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0398, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0248, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0452, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0259, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0458, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0547, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0357, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0421, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0472, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0336, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0576, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0449, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0526, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0544, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0442, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0383, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0587, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0490, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0344, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0597, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0496, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0620, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0387, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0307, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0335, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0316, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0370, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0341, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0487, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0580, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0296, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0367, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0380, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0520, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0414, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0472, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0432, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0514, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0391, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0368, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0375, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0365, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0478, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0465, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0414, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0542, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0379, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0241, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0445, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0280, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0289, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0498, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0482, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0384, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0498, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0421, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0194, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0435, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0227, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0362, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0152, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0277, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0298, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0445, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0476, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0283, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0389, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0323, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0433, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0361, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0029, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0219, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0243, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0213, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0415, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0391, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0484, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0431, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0351, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0185, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0433, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0326, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0374, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0455, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0447, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0416, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0658, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0286, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0248, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0401, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0487, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0413, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0350, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0563, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0657, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0352, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0683, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0576, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0362, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0462, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0493, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0378, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0319, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0400, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0515, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0457, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0206, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0628, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0307, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0241, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0235, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0276, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0395, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0215, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0257, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0230, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0256, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0320, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0455, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0341, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0220, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0470, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0202, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0218, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0221, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0262, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:  67%|██████████████████████           | 2/3 [34:56<17:20, 1040.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 loss: 337.00\n",
      "tensor(1.0193, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0291, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0289, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0292, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0202, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0111, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0327, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0146, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0208, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0204, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0335, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0225, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0254, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0399, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0199, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0235, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0252, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0153, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0283, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0229, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0320, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0255, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0218, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0288, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0431, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0420, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0098, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0270, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0236, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0332, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0276, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0379, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0248, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0226, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0114, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0222, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0035, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0335, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0283, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0265, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0180, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0071, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0220, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0344, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0317, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0270, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0190, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0296, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0268, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0160, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0377, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0057, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0217, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0276, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0325, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0305, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0354, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0239, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0136, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0212, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0497, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0321, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0120, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0379, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0126, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0110, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0366, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0142, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0072, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0132, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0071, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0290, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0257, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0225, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0408, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0407, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0330, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0492, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0073, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0355, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0237, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0232, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0346, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0061, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0156, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0062, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0423, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0223, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0225, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0170, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0103, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0143, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0228, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0392, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0294, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0219, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0392, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0210, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0301, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0046, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0326, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0505, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0313, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0352, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0310, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0214, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0133, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0195, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0218, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0030, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9975, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0110, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0141, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0065, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0254, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0125, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0057, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0118, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0241, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0159, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0212, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0223, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0139, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9972, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0233, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0176, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0420, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0341, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0212, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0139, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0050, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0217, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0157, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0206, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0355, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0254, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0150, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0146, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0171, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0113, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9940, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0030, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0251, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0295, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0264, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0124, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0169, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0198, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0232, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0034, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0321, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0258, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0000, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0114, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0154, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0188, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0108, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0055, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0174, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0182, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0079, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0176, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0124, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0038, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0148, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0048, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0009, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0030, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9883, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0116, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0085, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0065, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0293, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0049, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0120, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9952, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0199, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0094, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0082, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0012, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0021, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0169, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9995, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0112, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9963, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9967, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9857, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0069, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9915, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0014, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9876, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9911, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9952, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9982, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0012, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9929, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9983, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9965, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0073, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0020, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0133, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9840, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0157, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0165, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0194, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0079, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9965, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9984, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0114, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0029, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0037, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0122, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0035, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0216, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9999, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9876, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0042, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0017, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9921, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9911, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0137, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0323, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9934, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0077, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0099, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0101, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0160, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0027, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0068, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9934, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9992, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9997, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9902, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0013, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9985, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9964, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0038, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9844, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9945, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9932, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9936, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0008, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9857, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9979, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0017, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0092, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9946, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9980, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9908, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9906, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0044, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0076, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9936, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0315, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0306, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0111, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9959, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0071, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0287, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9959, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9788, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9811, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9852, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9907, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9987, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9880, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9985, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9893, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9894, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9839, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9887, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9895, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9864, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0100, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9992, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9905, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9958, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9904, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9783, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9928, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9926, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9930, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9926, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9882, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9932, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9852, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0082, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0075, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9851, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9992, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0040, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9704, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9910, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0032, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9967, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9725, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9681, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9859, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9752, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9748, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9970, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9847, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9744, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9796, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9710, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9665, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9817, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9636, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9743, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9537, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9582, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9637, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9493, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9589, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9629, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9635, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|█████████████████████████████████| 3/3 [52:01<00:00, 1040.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 loss: 322.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.96\n",
      "Test accuracy: 95.31%\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "class MyViT(nn.Module):\n",
    "    def __init__(self, Dimensions, number_patchesRow,number_patchesColumn, number_blocks, Hidden_DGiven, NumberHeadsGiven, output_dimension):\n",
    "        \n",
    "        super(MyViT, self).__init__()\n",
    "        self.Dimensions = Dimensions  \n",
    "        self.number_patchesRow = number_patchesRow\n",
    "        self.number_patchesColumn=number_patchesColumn\n",
    "        self.number_blocks = number_blocks\n",
    "        self.Hidden_DGiven= Hidden_DGiven\n",
    "        self.NumberHeadsGiven = NumberHeadsGiven\n",
    "        \n",
    "        self.patch_size = (math.floor(Dimensions[1] / number_patchesRow), math.floor(Dimensions[2] / number_patchesColumn))\n",
    "        \n",
    "        self.input_d = int(Dimensions[0] * self.patch_size[0] * self.patch_size[1])\n",
    "        self.linear_mapper = nn.Linear(self.input_d, self.Hidden_DGiven)\n",
    "\n",
    "        self.class_token = nn.Parameter(torch.rand(1, self.Hidden_DGiven))\n",
    "\n",
    "        self.register_buffer(\n",
    "            \"positional_embeddings1\",\n",
    "            get_positional_embeddings3(number_patchesRow*number_patchesColumn + 1, Hidden_DGiven),\n",
    "            persistent=False,\n",
    "        )\n",
    "        \n",
    "        self.blocksA = nn.ModuleList(\n",
    "            [VisionTransformer(Hidden_DGiven, NumberHeadsGiven) for _ in range(number_blocks)]\n",
    "        )\n",
    "\n",
    "        self.mlp = nn.Sequential(nn.Linear(self.Hidden_DGiven, output_dimension), nn.Softmax(dim=-1))\n",
    "\n",
    "    def forward(self, images):        \n",
    "        n, c, h, w = images.shape\n",
    "        patches1A = images[0:n,0,0:self.patch_size[0]*self.number_patchesRow,0:self.patch_size[1]*self.number_patchesColumn]#patchify(images, self.n_patches).to(self.positional_embeddings1.device)\n",
    "        Size=64#(patches1A.size(1)*patches1A.size(2))/(self.number_patchesRow*self.number_patchesColumn)\n",
    "        #print(Size)\n",
    "        patches1=patches1A.reshape(n,self.number_patchesRow*self.number_patchesColumn,Size)\n",
    "        \n",
    "        tokens1 = self.linear_mapper(patches1)\n",
    "        tokensa = torch.cat((self.class_token.expand(n, 1, -1), tokens1), dim=1)\n",
    "\n",
    "        A    = tokensa + self.positional_embeddings1.repeat(n, 1, 1) \n",
    "\n",
    "        for block in self.blocksA:\n",
    "            A = block(A)\n",
    "        \n",
    "        output = torch.ones(n,self.Hidden_DGiven)\n",
    "        \n",
    "        output[0:n,self.Hidden_DGiven*0:self.Hidden_DGiven]  = A[:, 0]\n",
    "\n",
    "        return self.mlp(output)\n",
    "\n",
    "\n",
    "def main():\n",
    "    \n",
    "    transform = ToTensor()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = MyViT(\n",
    "        (1, 128,40), number_patchesRow=16, number_patchesColumn=5, number_blocks=2, Hidden_DGiven=5, NumberHeadsGiven=5, output_dimension=5\n",
    "    ).to(device)\n",
    "\n",
    "    NUMBER_EPOCHS = 3\n",
    "    LearningRate = 0.003\n",
    "\n",
    "    # Training Data loop\n",
    "    optimizer = Adam(model.parameters(), lr= LearningRate)\n",
    "    criterion = CrossEntropyLoss()\n",
    "\n",
    "    for epoch in trange(NUMBER_EPOCHS, desc=\"Training\"):\n",
    "        training_loss = 0.0\n",
    "        for batch in range(0,Length,Stride):\n",
    "            y = y_train[batch:batch+Stride]\n",
    "            x = X_train[batch:batch+Stride,0:1,0:128,0:40]\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            y_hat = model(x)\n",
    "            \n",
    "            loss = criterion(y_hat, y.type(torch.LongTensor))\n",
    "            print(loss)\n",
    "            training_loss += loss.detach().cpu().item()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        print(f\"Epoch {epoch + 1}/{NUMBER_EPOCHS} loss: {training_loss:.2f}\")\n",
    "\n",
    "    # Testing loop with testing data\n",
    "    with torch.no_grad():\n",
    "        correct, total = 0, 0\n",
    "        test_loss = 0.0\n",
    "        y = y_test\n",
    "        x = X_test\n",
    "\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        y_hat = model(x)\n",
    "        loss = criterion(y_hat, y.type(torch.LongTensor))\n",
    "\n",
    "        test_loss += loss.detach().cpu().item()\n",
    "\n",
    "        correct += torch.sum(torch.argmax(y_hat, dim=1) == y).detach().cpu().item()\n",
    "        total += len(x)\n",
    "        print(f\"Test loss: {test_loss:.2f}\")\n",
    "        print(f\"Test accuracy: {correct / total * 100:.2f}%\")\n",
    "main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "580eb72f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:   0%|                                           | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.6172, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6001, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6051, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5935, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5980, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5944, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5889, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5858, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5879, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5782, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5666, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5602, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5591, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5632, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5447, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5494, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5329, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5359, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5288, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5124, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5243, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5096, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5016, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5104, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4966, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4902, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4901, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4881, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4649, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4865, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4602, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4655, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4689, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4619, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4574, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4513, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4694, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4596, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4538, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4460, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4515, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4516, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4433, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4526, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4505, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4508, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4494, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4272, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4272, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4471, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4135, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4391, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4400, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4325, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4365, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4391, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4222, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4192, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4168, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4175, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4202, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4244, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4066, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4118, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4226, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4137, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4103, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4045, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4037, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4065, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3995, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4044, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3982, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3941, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4017, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3861, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3702, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3687, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3544, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3600, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3603, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3448, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3481, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3335, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3360, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3202, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3416, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3390, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3040, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2876, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2931, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3016, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2805, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2810, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2709, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2486, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2503, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2403, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2474, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2285, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2301, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2305, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2121, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2194, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2323, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1972, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1948, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1773, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1801, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1791, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1532, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1721, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1566, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1651, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1547, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1470, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1494, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1269, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1522, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1454, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1327, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1457, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1369, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1237, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1423, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1146, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1357, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1629, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1146, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1215, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1280, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1170, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1147, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1050, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1305, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1089, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1048, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1076, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1164, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1304, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1118, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1228, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1127, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1111, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1060, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1042, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1025, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0878, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1252, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1069, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1137, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1309, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1010, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1217, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1074, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1076, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0960, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1001, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1135, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0915, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0958, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0980, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0962, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0969, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0918, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0840, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0986, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0865, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0759, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0913, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0845, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0832, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0891, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0933, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0754, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0845, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0895, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0889, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0844, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0713, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0769, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0703, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0920, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0669, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0841, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0700, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0647, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0706, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0948, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0663, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0709, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0767, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0662, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0714, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0719, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0692, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0700, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0701, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0650, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0633, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0641, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0825, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0790, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0670, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0773, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0514, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0538, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0684, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0817, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0597, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0512, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0577, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0647, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0641, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0608, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0739, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0512, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0419, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0444, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0456, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0464, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0487, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0613, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0542, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0405, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0455, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0310, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0372, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0343, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0462, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0404, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0381, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0359, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0457, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0234, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0227, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0345, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0436, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0363, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0381, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0306, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0239, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0139, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0243, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0267, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0152, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0283, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0208, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0161, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0099, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0170, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0129, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0280, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0044, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0278, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0252, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0016, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0259, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0017, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0229, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0010, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0122, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0078, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0017, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0011, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0099, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9982, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9884, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0037, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0103, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0114, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0101, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9904, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0036, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9957, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9898, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9939, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9914, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0025, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9868, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9960, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0014, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9929, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9886, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9838, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9885, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9863, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9719, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9860, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9916, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9828, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9764, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9813, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9820, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9766, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9756, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9817, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9752, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9793, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9815, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9788, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9795, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9694, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9819, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9852, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9764, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9732, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9645, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9740, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9806, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9762, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9753, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9740, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9752, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9745, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9714, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9692, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9722, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:  33%|███████████▎                      | 1/3 [16:26<32:52, 986.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 loss: 376.72\n",
      "tensor(0.9666, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9622, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9607, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9696, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9620, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9627, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9707, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9699, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9572, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9667, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9661, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9651, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9651, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9711, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9683, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9610, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9614, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9601, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9683, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9616, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9733, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9525, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9600, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9645, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9696, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9681, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9597, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9647, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9596, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9596, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9517, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9549, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9590, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9531, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9491, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9673, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9585, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9561, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9641, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9516, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9684, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9514, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9516, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9571, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9540, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9546, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9611, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9571, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9382, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9488, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9470, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9549, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9453, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9482, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9521, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9492, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9476, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9472, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9417, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9456, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9557, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9453, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9473, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9428, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9355, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9401, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9479, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9497, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9518, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9417, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9441, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9403, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9453, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9488, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9401, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9486, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9416, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9365, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9376, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9374, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9347, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9443, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9396, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9411, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9468, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9324, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9420, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9392, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9372, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9378, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9391, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9434, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9478, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9293, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9354, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9373, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9450, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9378, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9394, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9354, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9460, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9306, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9336, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9512, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9377, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9376, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9329, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9300, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9285, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9334, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9308, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9265, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9327, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9315, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9310, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9307, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9318, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9298, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9320, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9353, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9292, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9328, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9332, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9326, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9340, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9342, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9346, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9329, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9363, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9345, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9292, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9312, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9364, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9323, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9367, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9282, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9314, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9386, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9281, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9270, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9394, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9308, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9273, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9345, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9370, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9293, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9277, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9338, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9272, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9337, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9371, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9279, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9236, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9262, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9338, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9425, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9417, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9235, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9270, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9248, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9288, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9310, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9308, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9265, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9309, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9278, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9286, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9267, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9267, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9310, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9242, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9260, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9280, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9256, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9257, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9180, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9328, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9258, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9272, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9295, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9248, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9254, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9355, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9205, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9245, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9336, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9272, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9225, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9275, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9327, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9253, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9288, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9237, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9243, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9199, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9234, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9274, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9225, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9343, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9202, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9234, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9254, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9313, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9312, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9172, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9183, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9242, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9234, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9300, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9286, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9257, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9191, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9217, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9267, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9204, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9157, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9258, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9239, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9249, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9215, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9216, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9229, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9206, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9234, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9205, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9278, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9213, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9299, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9246, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9271, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9217, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9246, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9296, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9242, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9248, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9206, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9191, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9214, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9275, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9231, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9264, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9186, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9206, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9234, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9198, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9173, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9164, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9219, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9211, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9259, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9241, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9185, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9206, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9162, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9245, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9237, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9196, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9257, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9180, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9229, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9234, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9259, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9227, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9171, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9201, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9287, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9175, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9134, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9214, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9194, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9242, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9253, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9222, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9171, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9170, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9228, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9256, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9230, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9234, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9184, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9280, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9201, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9173, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9203, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9209, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9204, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9164, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9209, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9237, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9142, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9192, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9216, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9170, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9175, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9204, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9156, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9211, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9225, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9268, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9180, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9179, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9185, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9210, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9221, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9187, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9177, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9220, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9253, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9188, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9185, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9289, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9245, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9181, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9257, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9271, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9248, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9169, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9240, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9174, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9194, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:  67%|██████████████████████▋           | 2/3 [33:06<16:34, 994.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 loss: 298.85\n",
      "tensor(0.9188, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9150, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9170, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9224, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9193, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9232, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9210, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9185, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9147, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9242, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9181, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9142, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9172, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9256, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9232, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9195, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9190, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9175, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9221, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9168, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9252, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9189, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9217, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9227, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9254, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9221, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9230, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9216, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9195, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9197, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9180, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9234, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9174, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9215, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9169, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9162, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9216, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9180, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9195, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9148, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9259, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9234, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9152, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9233, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9185, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9183, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9140, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9154, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9182, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9139, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9199, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9244, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9161, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9193, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9208, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9213, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9227, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9190, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9198, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9134, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9261, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9178, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9180, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9187, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9149, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9193, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9238, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9234, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9228, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9171, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9216, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9158, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9199, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9268, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9155, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9289, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9199, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9137, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9190, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9167, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9165, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9180, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9183, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9232, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9242, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9148, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9226, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9175, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9135, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9196, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9229, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9209, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9218, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9136, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9229, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9166, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9169, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9168, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9205, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9169, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9187, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9137, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9193, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9228, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9180, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9211, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9217, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9186, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9173, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9139, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9168, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9195, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9209, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9161, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9159, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9205, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9212, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9167, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9212, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9187, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9212, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9179, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9195, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9173, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9183, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9200, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9188, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9199, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9220, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9192, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9185, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9155, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9241, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9154, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9180, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9168, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9145, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9167, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9157, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9153, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9179, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9189, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9172, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9189, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9176, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9237, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9166, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9141, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9187, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9165, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9143, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9163, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9109, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9166, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9215, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9266, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9209, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9133, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9134, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9154, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9176, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9139, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9182, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9125, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9163, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9187, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9177, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9140, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9170, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9203, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9130, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9139, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9157, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9153, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9155, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9108, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9215, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9119, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9144, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9149, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9150, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9132, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9174, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9102, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9137, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9146, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9145, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9161, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9132, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9190, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9162, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9142, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9114, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9138, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9114, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9146, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9134, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9116, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9219, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9141, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9124, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9145, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9202, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9138, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9108, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9092, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9156, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9168, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9157, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9155, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9142, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9127, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9128, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9129, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9131, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9109, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9119, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9143, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9136, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9110, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9128, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9142, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9138, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9128, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9138, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9172, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9103, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9179, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9161, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9154, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9127, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9144, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9169, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9140, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9143, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9117, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9106, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9134, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9152, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9123, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9130, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9107, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9141, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9129, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9142, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9101, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9115, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9132, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9118, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9126, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9144, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9119, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9099, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9088, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9160, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9113, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9134, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9199, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9138, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9126, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9194, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9142, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9137, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9127, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9133, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9183, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9096, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9087, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9103, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9154, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9174, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9128, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9155, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9133, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9126, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9140, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9176, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9134, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9149, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9107, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9161, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9136, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9136, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9149, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9135, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9131, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9114, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9151, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9163, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9087, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9136, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9181, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9107, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9096, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9103, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9126, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9174, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9144, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9169, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9133, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9123, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9093, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9139, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9125, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9101, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9098, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9105, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9163, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9129, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9095, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9172, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9133, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9117, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9116, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9155, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9155, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9105, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9142, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9128, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9104, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████| 3/3 [49:17<00:00, 985.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 loss: 293.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.91\n",
      "Test accuracy: 99.18%\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "class MyViT(nn.Module):\n",
    "    def __init__(self, Dimensions, number_patchesRow,number_patchesColumn, number_blocks, Hidden_DGiven, NumberHeadsGiven, output_dimension):\n",
    "        \n",
    "        super(MyViT, self).__init__()\n",
    "        self.Dimensions = Dimensions  \n",
    "        self.number_patchesRow = number_patchesRow\n",
    "        self.number_patchesColumn=number_patchesColumn\n",
    "        self.number_blocks = number_blocks\n",
    "        self.Hidden_DGiven= Hidden_DGiven\n",
    "        self.NumberHeadsGiven = NumberHeadsGiven\n",
    "        \n",
    "        self.patch_size = (math.floor(Dimensions[1] / number_patchesRow), math.floor(Dimensions[2] / number_patchesColumn))\n",
    "        \n",
    "        self.input_d = int(Dimensions[0] * self.patch_size[0] * self.patch_size[1])\n",
    "        self.linear_mapper = nn.Linear(self.input_d, self.Hidden_DGiven)\n",
    "\n",
    "        self.class_token = nn.Parameter(torch.rand(1, self.Hidden_DGiven))\n",
    "\n",
    "        self.register_buffer(\n",
    "            \"positional_embeddings1\",\n",
    "            get_positional_embeddings4(number_patchesRow*number_patchesColumn + 1, Hidden_DGiven),\n",
    "            persistent=False,\n",
    "        )\n",
    "        \n",
    "        self.blocksA = nn.ModuleList(\n",
    "            [VisionTransformer(Hidden_DGiven, NumberHeadsGiven) for _ in range(number_blocks)]\n",
    "        )\n",
    "\n",
    "        self.mlp = nn.Sequential(nn.Linear(self.Hidden_DGiven, output_dimension), nn.Softmax(dim=-1))\n",
    "\n",
    "    def forward(self, images):        \n",
    "        n, c, h, w = images.shape\n",
    "        patches1A = images[0:n,0,0:self.patch_size[0]*self.number_patchesRow,0:self.patch_size[1]*self.number_patchesColumn]#patchify(images, self.n_patches).to(self.positional_embeddings1.device)\n",
    "        Size=64#(patches1A.size(1)*patches1A.size(2))/(self.number_patchesRow*self.number_patchesColumn)\n",
    "        #print(Size)\n",
    "        patches1=patches1A.reshape(n,self.number_patchesRow*self.number_patchesColumn,Size)\n",
    "        \n",
    "        tokens1 = self.linear_mapper(patches1)\n",
    "        tokensa = torch.cat((self.class_token.expand(n, 1, -1), tokens1), dim=1)\n",
    "\n",
    "        A    = tokensa + self.positional_embeddings1.repeat(n, 1, 1) \n",
    "\n",
    "        for block in self.blocksA:\n",
    "            A = block(A)\n",
    "        \n",
    "        output = torch.ones(n,self.Hidden_DGiven)\n",
    "        \n",
    "        output[0:n,self.Hidden_DGiven*0:self.Hidden_DGiven]  = A[:, 0]\n",
    "\n",
    "        return self.mlp(output)\n",
    "\n",
    "\n",
    "def main():\n",
    "    \n",
    "    transform = ToTensor()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = MyViT(\n",
    "        (1, 128,40), number_patchesRow=16, number_patchesColumn=5, number_blocks=2, Hidden_DGiven=5, NumberHeadsGiven=5, output_dimension=5\n",
    "    ).to(device)\n",
    "\n",
    "    NUMBER_EPOCHS = 3\n",
    "    LearningRate = 0.003\n",
    "\n",
    "    # Training Data loop\n",
    "    optimizer = Adam(model.parameters(), lr= LearningRate)\n",
    "    criterion = CrossEntropyLoss()\n",
    "\n",
    "    for epoch in trange(NUMBER_EPOCHS, desc=\"Training\"):\n",
    "        training_loss = 0.0\n",
    "        for batch in range(0,Length,Stride):\n",
    "            y = y_train[batch:batch+Stride]\n",
    "            x = X_train[batch:batch+Stride,0:1,0:128,0:40]\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            y_hat = model(x)\n",
    "            \n",
    "            loss = criterion(y_hat, y.type(torch.LongTensor))\n",
    "            print(loss)\n",
    "            training_loss += loss.detach().cpu().item()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        print(f\"Epoch {epoch + 1}/{NUMBER_EPOCHS} loss: {training_loss:.2f}\")\n",
    "\n",
    "    # Testing loop with testing data\n",
    "    with torch.no_grad():\n",
    "        correct, total = 0, 0\n",
    "        test_loss = 0.0\n",
    "        y = y_test\n",
    "        x = X_test\n",
    "\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        y_hat = model(x)\n",
    "        loss = criterion(y_hat, y.type(torch.LongTensor))\n",
    "\n",
    "        test_loss += loss.detach().cpu().item()\n",
    "\n",
    "        correct += torch.sum(torch.argmax(y_hat, dim=1) == y).detach().cpu().item()\n",
    "        total += len(x)\n",
    "        print(f\"Test loss: {test_loss:.2f}\")\n",
    "        print(f\"Test accuracy: {correct / total * 100:.2f}%\")\n",
    "main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "05e32b75",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:   0%|                                           | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.6194, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6177, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6057, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6103, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6013, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5986, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6017, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5901, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5834, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5854, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5851, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5857, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5808, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5746, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5696, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5665, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5632, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5531, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5500, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5453, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5388, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5343, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5286, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5370, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5234, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5112, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5083, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5050, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4765, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4963, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4758, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4877, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4830, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4751, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4663, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4655, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4513, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4643, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4730, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4569, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4442, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4589, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4501, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4534, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4611, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4484, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4454, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4348, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4256, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4479, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4213, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4335, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4429, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4465, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4397, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4432, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4345, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4311, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4243, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4326, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4370, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4308, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4261, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4322, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4395, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4315, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4308, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4285, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4239, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4280, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4325, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4376, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4336, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4323, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4416, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4303, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4141, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4147, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4098, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4204, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4252, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4163, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4215, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4135, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4214, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4103, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4387, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4354, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4179, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4060, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4192, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4260, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4060, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4227, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4181, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4005, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4024, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4114, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4131, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4006, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4149, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4078, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4076, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4088, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4149, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4005, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4028, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3923, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3785, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4018, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3630, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3875, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3889, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3794, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3934, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3774, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3747, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3720, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3747, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3657, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3677, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3589, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3634, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3577, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3576, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3524, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3427, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3763, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3207, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3391, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3416, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3303, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3556, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3429, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3565, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3680, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3243, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3383, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3403, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3446, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3265, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3224, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3314, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3032, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3056, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3082, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3222, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3095, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3202, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3066, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3087, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3382, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2855, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3312, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3155, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3034, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2828, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3112, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3059, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2758, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3034, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2818, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2869, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2786, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2954, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2583, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2812, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2667, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2515, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2621, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2536, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2631, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2751, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2606, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2604, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2488, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2725, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2666, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2518, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2405, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2371, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2392, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2641, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2368, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2412, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2250, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2433, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2361, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2553, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2313, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2201, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.2311, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2239, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2315, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2113, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2224, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1954, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1822, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2116, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1857, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2078, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2099, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2090, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1872, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2000, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1899, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1812, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1870, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1853, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1769, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1858, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1704, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1966, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1956, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1823, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1786, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1623, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1545, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1627, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1830, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1471, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1591, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1684, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1723, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1558, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1626, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1479, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1547, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1442, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1646, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1503, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1607, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1430, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1628, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1406, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1499, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1495, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1436, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1565, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1604, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1413, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1369, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1337, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1201, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1500, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1379, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1373, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1343, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1243, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1225, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1240, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1249, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1297, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1125, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1223, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1151, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0920, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1271, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1147, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1059, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1035, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1181, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1186, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1031, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0888, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1077, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0939, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0875, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0857, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0910, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1010, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0937, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0918, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0794, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1042, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0694, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0877, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0857, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0788, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0757, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0916, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0680, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0923, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0938, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0726, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0715, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0803, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0836, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0740, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0708, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0848, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0834, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0550, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0723, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0758, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0691, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0726, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0643, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0769, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0754, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0472, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0767, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0607, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0590, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0500, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0769, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0624, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0654, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0573, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0500, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0479, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0941, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0506, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0542, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0725, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0636, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0432, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0482, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0426, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0453, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:  33%|███████████▎                      | 1/3 [16:05<32:11, 965.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 loss: 412.02\n",
      "tensor(1.0539, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0523, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0407, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0368, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0269, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0437, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0499, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0434, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0394, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0326, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0411, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0316, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0473, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0568, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0416, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0338, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0406, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0425, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0386, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0240, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0323, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0234, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0269, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0488, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0478, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0274, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0463, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0259, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0129, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0191, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0310, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0408, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0183, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0471, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0162, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0434, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0191, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0229, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0541, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0007, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0384, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0352, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0210, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0462, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0324, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0431, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0460, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0135, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0376, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0524, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0115, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0343, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0562, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0257, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0244, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0249, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0172, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0270, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0139, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0342, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0319, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0160, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0176, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0343, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0094, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0139, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0248, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0051, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0179, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0068, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0246, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0321, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0131, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0315, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0024, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0380, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0201, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0248, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0137, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0065, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0134, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0127, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0156, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0118, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0348, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0136, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0159, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0171, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0053, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0076, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0052, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0237, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9948, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0206, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0040, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9953, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0116, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0039, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0083, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0289, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0027, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0247, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0054, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0143, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0059, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0153, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0038, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9989, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9897, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0105, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0153, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0015, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9996, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0021, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0022, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9956, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0065, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9959, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9913, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0027, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0047, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0047, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9853, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9949, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9951, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0064, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0080, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9922, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0008, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9956, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9847, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9944, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0012, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0163, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0077, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0069, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0063, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9920, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0041, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9883, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9893, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0069, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0075, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9921, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9945, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9911, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0057, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9959, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9960, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9948, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9826, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9984, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9816, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0108, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9881, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9908, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9864, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9776, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0126, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9991, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0009, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9992, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9934, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9761, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9876, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9847, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9986, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9997, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9833, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9886, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9996, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9986, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9955, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9910, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9900, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9906, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9824, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9886, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9900, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9903, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9816, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9806, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9825, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9825, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9821, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9808, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9842, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9925, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9979, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9901, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9859, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9874, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9845, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9897, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9837, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9816, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9791, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9760, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9929, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9931, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9967, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9895, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9877, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9931, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0027, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9828, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9881, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9787, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9811, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9938, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0051, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9816, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9832, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9858, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9741, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9887, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9987, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9860, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9787, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9773, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9916, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9942, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9786, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9666, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9932, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9841, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9777, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9711, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9818, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9845, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9809, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9736, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9769, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9816, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9791, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9814, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9785, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9808, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9884, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9772, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9658, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9747, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9654, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9682, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9733, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9600, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9825, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9687, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9781, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9736, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9744, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9784, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9786, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9681, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9805, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9853, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9794, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9693, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9808, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9813, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9685, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9621, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9899, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9645, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9709, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9634, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9749, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9797, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9778, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9652, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9627, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9713, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9725, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9767, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9746, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9811, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9614, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9797, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9688, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9771, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9875, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9611, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9738, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9777, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9700, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9724, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9753, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9822, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9803, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9690, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9640, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9867, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9668, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9824, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9709, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9847, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9734, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9666, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9823, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9707, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9674, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9637, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9746, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9761, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9737, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9690, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9663, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9620, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9798, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9631, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9618, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9666, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9740, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9627, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9710, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9627, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9711, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:  67%|██████████████████████▋           | 2/3 [32:38<16:21, 981.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 loss: 319.47\n",
      "tensor(0.9650, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9686, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9625, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9657, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9510, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9615, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9651, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9800, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9691, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9732, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9617, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9524, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9632, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9819, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9596, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9642, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9613, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9685, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9723, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9570, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9574, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9627, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9593, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9744, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9682, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9612, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9672, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9600, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9519, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9636, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9624, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9642, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9537, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9612, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9512, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9633, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9603, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9602, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9674, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9477, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9717, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9547, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9642, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9794, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9663, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9680, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9623, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9503, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9710, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9626, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9523, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9589, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9710, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9549, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9567, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9699, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9608, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9657, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9535, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9656, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9630, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9662, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9721, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9669, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9540, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9604, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9660, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9441, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9665, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9565, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9745, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9680, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9526, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9730, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9498, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9776, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9620, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9676, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9616, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9633, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9557, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9520, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9724, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9588, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9694, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9552, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9620, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9570, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9604, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9616, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9514, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9656, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9479, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9618, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9586, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9436, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9596, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9604, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9666, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9805, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9533, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9644, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9500, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9696, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9549, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9697, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9650, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9474, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9496, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9645, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9646, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9529, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9453, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9605, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9635, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9480, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9574, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9508, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9498, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9610, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9568, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9543, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9629, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9538, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9469, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9643, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9568, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9669, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9555, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9582, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9567, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9428, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9525, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9525, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9566, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9646, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9562, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9580, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9573, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9560, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9554, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9542, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9648, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9516, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9655, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9487, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9612, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9431, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9593, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9561, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9608, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9664, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9509, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9608, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9562, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9759, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9503, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9541, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9577, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9561, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9622, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9564, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9562, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9517, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9500, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9413, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9514, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9610, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9561, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9660, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9400, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9512, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9579, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9586, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9573, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9471, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9476, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9492, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9516, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9644, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9493, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9552, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9505, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9486, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9520, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9457, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9534, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9563, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9604, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9619, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9469, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9571, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9647, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9527, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9498, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9597, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9521, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9482, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9497, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9418, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9491, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9521, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9682, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9627, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9585, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9589, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9599, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9467, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9455, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9537, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9458, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9498, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9550, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9557, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9471, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9508, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9540, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9450, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9517, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9512, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9542, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9585, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9530, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9499, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9534, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9446, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9495, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9671, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9499, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9461, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9521, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9572, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9473, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9377, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9368, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9438, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9561, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9399, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9493, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9571, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9486, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9534, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9479, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9411, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9517, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9408, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9464, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9427, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9296, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9546, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9438, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9470, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9408, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9437, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9586, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9529, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9433, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9493, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9676, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9619, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9542, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9569, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9489, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9523, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9481, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9576, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9508, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9471, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9471, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9504, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9551, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9568, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9548, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9496, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9541, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9474, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9538, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9449, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9594, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9427, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9513, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9502, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9492, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9569, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9422, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9473, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9503, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9480, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9494, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9469, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9527, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9462, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9479, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9428, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9552, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9419, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9543, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9514, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9485, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9473, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9462, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9506, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9479, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9463, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9419, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9488, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9543, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9503, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9438, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9405, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9383, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9414, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9362, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9389, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9442, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9459, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9429, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9478, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9456, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9413, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████| 3/3 [48:38<00:00, 972.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 loss: 305.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.95\n",
      "Test accuracy: 95.95%\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "class MyViT(nn.Module):\n",
    "    def __init__(self, Dimensions, number_patchesRow,number_patchesColumn, number_blocks, Hidden_DGiven, NumberHeadsGiven, output_dimension):\n",
    "        \n",
    "        super(MyViT, self).__init__()\n",
    "        self.Dimensions = Dimensions  \n",
    "        self.number_patchesRow = number_patchesRow\n",
    "        self.number_patchesColumn=number_patchesColumn\n",
    "        self.number_blocks = number_blocks\n",
    "        self.Hidden_DGiven= Hidden_DGiven\n",
    "        self.NumberHeadsGiven = NumberHeadsGiven\n",
    "        \n",
    "        self.patch_size = (math.floor(Dimensions[1] / number_patchesRow), math.floor(Dimensions[2] / number_patchesColumn))\n",
    "        \n",
    "        self.input_d = int(Dimensions[0] * self.patch_size[0] * self.patch_size[1])\n",
    "        self.linear_mapper = nn.Linear(self.input_d, self.Hidden_DGiven)\n",
    "\n",
    "        self.class_token = nn.Parameter(torch.rand(1, self.Hidden_DGiven))\n",
    "\n",
    "        self.register_buffer(\n",
    "            \"positional_embeddings1\",\n",
    "            get_positional_embeddings5(number_patchesRow*number_patchesColumn + 1, Hidden_DGiven),\n",
    "            persistent=False,\n",
    "        )\n",
    "        \n",
    "        self.blocksA = nn.ModuleList(\n",
    "            [VisionTransformer(Hidden_DGiven, NumberHeadsGiven) for _ in range(number_blocks)]\n",
    "        )\n",
    "\n",
    "        self.mlp = nn.Sequential(nn.Linear(self.Hidden_DGiven, output_dimension), nn.Softmax(dim=-1))\n",
    "\n",
    "    def forward(self, images):        \n",
    "        n, c, h, w = images.shape\n",
    "        patches1A = images[0:n,0,0:self.patch_size[0]*self.number_patchesRow,0:self.patch_size[1]*self.number_patchesColumn]#patchify(images, self.n_patches).to(self.positional_embeddings1.device)\n",
    "        Size=64#(patches1A.size(1)*patches1A.size(2))/(self.number_patchesRow*self.number_patchesColumn)\n",
    "        #print(Size)\n",
    "        patches1=patches1A.reshape(n,self.number_patchesRow*self.number_patchesColumn,Size)\n",
    "        \n",
    "        tokens1 = self.linear_mapper(patches1)\n",
    "        tokensa = torch.cat((self.class_token.expand(n, 1, -1), tokens1), dim=1)\n",
    "\n",
    "        A    = tokensa + self.positional_embeddings1.repeat(n, 1, 1) \n",
    "\n",
    "        for block in self.blocksA:\n",
    "            A = block(A)\n",
    "        \n",
    "        output = torch.ones(n,self.Hidden_DGiven)\n",
    "        \n",
    "        output[0:n,self.Hidden_DGiven*0:self.Hidden_DGiven]  = A[:, 0]\n",
    "\n",
    "        return self.mlp(output)\n",
    "\n",
    "\n",
    "def main():\n",
    "    \n",
    "    transform = ToTensor()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = MyViT(\n",
    "        (1, 128,40), number_patchesRow=16, number_patchesColumn=5, number_blocks=2, Hidden_DGiven=5, NumberHeadsGiven=5, output_dimension=5\n",
    "    ).to(device)\n",
    "\n",
    "    NUMBER_EPOCHS = 3\n",
    "    LearningRate = 0.003\n",
    "\n",
    "    # Training Data loop\n",
    "    optimizer = Adam(model.parameters(), lr= LearningRate)\n",
    "    criterion = CrossEntropyLoss()\n",
    "\n",
    "    for epoch in trange(NUMBER_EPOCHS, desc=\"Training\"):\n",
    "        training_loss = 0.0\n",
    "        for batch in range(0,Length,Stride):\n",
    "            y = y_train[batch:batch+Stride]\n",
    "            x = X_train[batch:batch+Stride,0:1,0:128,0:40]\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            y_hat = model(x)\n",
    "            \n",
    "            loss = criterion(y_hat, y.type(torch.LongTensor))\n",
    "            print(loss)\n",
    "            training_loss += loss.detach().cpu().item()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        print(f\"Epoch {epoch + 1}/{NUMBER_EPOCHS} loss: {training_loss:.2f}\")\n",
    "\n",
    "    # Testing loop with testing data\n",
    "    with torch.no_grad():\n",
    "        correct, total = 0, 0\n",
    "        test_loss = 0.0\n",
    "        y = y_test\n",
    "        x = X_test\n",
    "\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        y_hat = model(x)\n",
    "        loss = criterion(y_hat, y.type(torch.LongTensor))\n",
    "\n",
    "        test_loss += loss.detach().cpu().item()\n",
    "\n",
    "        correct += torch.sum(torch.argmax(y_hat, dim=1) == y).detach().cpu().item()\n",
    "        total += len(x)\n",
    "        print(f\"Test loss: {test_loss:.2f}\")\n",
    "        print(f\"Test accuracy: {correct / total * 100:.2f}%\")\n",
    "main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6182198",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_positional_embeddings1(seq_len, d):\n",
    "    resultingOutput = torch.ones(seq_len, d)\n",
    "    LearnableParameter1 = nn.GELU()\n",
    "    for i in range(seq_len):\n",
    "        for j in range(d):\n",
    "            resultingOutput[i][j] = LearnableParameter1(torch.tensor(np.sin(i / (10000 ** (2*j / d))) if j % 2 == 0 else np.cos(i / (10000 ** (2*(j - 1) / d)))))\n",
    "    return resultingOutput\n",
    "\n",
    "def get_positional_embeddings2(seq_len, d):\n",
    "    resultingOutput = torch.ones(seq_len, d)\n",
    "    LearnableParameter2 = nn.GELU()\n",
    "    for i in range(seq_len):\n",
    "        for j in range(d):\n",
    "            resultingOutput[i][j] = LearnableParameter2(torch.tensor(np.sin(i / (10000 ** (0.4*j / d))) if j % 2 == 0 else np.cos(i / (10000 ** (0.4*(j - 1) / d)))))\n",
    "    return resultingOutput\n",
    "\n",
    "def get_positional_embeddings3(seq_len, d):\n",
    "    resultingOutput = torch.ones(seq_len, d)\n",
    "    LearnableParameter3 = nn.GELU()\n",
    "    for i in range(seq_len):\n",
    "        for j in range(d):\n",
    "            resultingOutput[i][j] = LearnableParameter3(torch.tensor(np.sin(i / (10000 ** (1*j / d))) if j % 2 == 0 else np.cos(i / (10000 ** (1*(j - 1) / d)))))\n",
    "    return resultingOutput\n",
    "\n",
    "import math\n",
    "def get_positional_embeddings4(seq_len, d):\n",
    "    resultingOutput = torch.ones(seq_len, d)\n",
    "    LearnableParameter4 = nn.GELU()\n",
    "    for i in range(seq_len):\n",
    "        for j in range(d):\n",
    "            resultingOutput[i][j] = LearnableParameter4(torch.tensor(np.sin(i / (10000 ** (3*math.sqrt(j) / (d)))) if j % 2 == 0 else np.cos(i / (10000 ** (3*math.sqrt(j - 1) / (d))))))\n",
    "    return resultingOutput\n",
    "\n",
    "import math\n",
    "def get_positional_embeddings5(seq_len, d):\n",
    "    resultingOutput = torch.ones(seq_len, d)\n",
    "    LearnableParameter5 = nn.GELU()\n",
    "    for i in range(seq_len):\n",
    "        for j in range(d):\n",
    "            resultingOutput[i][j] = LearnableParameter5(torch.tensor(np.sin(i / (10000 ** (math.sqrt(j) / (d)))) if j % 2 == 0 else np.cos(i / (10000 ** (math.sqrt(j - 1) / (d))))))\n",
    "    return resultingOutput\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6cdec544",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:   0%|                                           | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.6222, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6084, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6095, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6088, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6020, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5960, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5988, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5907, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5817, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5851, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5791, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5746, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5677, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5674, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5610, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5548, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5420, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5373, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5312, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5248, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5232, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5114, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5053, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5054, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4952, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4867, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4798, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4740, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4432, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4638, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4418, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4564, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4448, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4376, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4264, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4289, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4093, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4210, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4278, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4038, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3927, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3985, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3824, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3758, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3693, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3571, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3495, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3365, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3253, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3394, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3118, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3145, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3136, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3163, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3059, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3095, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2967, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2856, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2721, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2840, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2965, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2717, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2811, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2839, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2758, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2666, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2683, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2776, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2695, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2602, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2804, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2737, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2595, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2784, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2847, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2703, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2531, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2521, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2502, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2657, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2541, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2317, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2556, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2490, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2541, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2389, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2800, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2735, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2506, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2312, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2557, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2634, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2470, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2514, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2572, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2420, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2337, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2451, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2452, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2389, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2545, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2511, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2414, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2428, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2564, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2448, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2374, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2280, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2299, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2213, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2121, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2152, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2111, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2264, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2218, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2147, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2103, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1919, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2031, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1914, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1972, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1862, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1761, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1754, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1785, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1664, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1599, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1956, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1472, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1438, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1540, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1301, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1280, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1217, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1382, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1207, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1143, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1084, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1183, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1304, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1117, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1190, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1180, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1101, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1074, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1040, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1046, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0964, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1185, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0942, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1037, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1169, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0824, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1028, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0990, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0981, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0815, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0896, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1009, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0806, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0831, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0820, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0852, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0799, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0791, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0741, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0817, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0687, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0605, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0762, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0585, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0669, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0665, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0744, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0497, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0493, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0536, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0620, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0530, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0413, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0486, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0401, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0603, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0369, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0371, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0291, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0221, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0372, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0496, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0224, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0242, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0287, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0119, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0214, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0068, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0050, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0094, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9969, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0046, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0030, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9963, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0131, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0110, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9934, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9971, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9985, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9898, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9985, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9922, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9886, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9895, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9797, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9937, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9965, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9989, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9895, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9809, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9858, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9781, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9841, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9926, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9845, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9784, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9788, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9842, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9820, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9856, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9853, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9728, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9898, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9833, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9761, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9757, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9655, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9598, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9659, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9804, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9770, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9646, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9683, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9615, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9668, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9705, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9806, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9697, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9792, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9588, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9678, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9632, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9677, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9714, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9679, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9587, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9757, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9655, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9531, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9700, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9659, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9622, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9686, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9615, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9634, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9661, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9662, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9585, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9765, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9633, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9585, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9550, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9702, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9659, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9733, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9495, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9523, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9674, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9635, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9559, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9706, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9546, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9698, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9534, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9718, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9745, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9654, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9687, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9546, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9771, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9558, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9540, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9587, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9535, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9628, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9581, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9588, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9533, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9631, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9552, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9677, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9593, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9508, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9588, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9592, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9529, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9662, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9661, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9554, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9543, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9503, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9517, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9637, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9562, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9601, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9540, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9575, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9634, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9488, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9683, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9637, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9571, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:  33%|███████████                      | 1/3 [17:51<35:43, 1071.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 loss: 365.60\n",
      "tensor(0.9554, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9516, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9557, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9571, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9545, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9488, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9509, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9634, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9450, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9495, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9620, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9511, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9537, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9650, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9577, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9558, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9529, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9555, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9547, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9517, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9656, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9504, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9525, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9647, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9546, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9567, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9494, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9599, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9516, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9619, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9545, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9569, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9509, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9524, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9446, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9568, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9434, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9595, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9656, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9486, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9489, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9488, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9445, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9636, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9438, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9492, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9646, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9494, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9416, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9486, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9520, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9497, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9543, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9466, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9663, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9461, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9486, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9406, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9473, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9436, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9590, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9394, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9520, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9520, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9371, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9430, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9565, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9506, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9507, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9442, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9467, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9424, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9447, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9441, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9433, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9579, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9460, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9412, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9467, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9441, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9351, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9454, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9414, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9436, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9621, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9409, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9479, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9538, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9379, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9360, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9475, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9523, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9546, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9414, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9569, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9470, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9405, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9428, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9403, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9360, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9315, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9455, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9380, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9435, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9429, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9471, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9435, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9428, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9380, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9436, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9325, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9422, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9388, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9403, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9498, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9332, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9430, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9338, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9435, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9379, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9455, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9458, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9402, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9418, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9408, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9411, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9438, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9477, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9464, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9458, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9425, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9354, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9473, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9382, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9440, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9300, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9408, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9421, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9377, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9355, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9385, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9323, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9398, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9519, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9359, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9347, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9328, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9336, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9343, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9358, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9378, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9429, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9268, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9354, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9342, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9413, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9488, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9310, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9388, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9367, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9235, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9274, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9366, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9374, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9416, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9325, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9318, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9318, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9290, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9369, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9339, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9381, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9309, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9384, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9265, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9251, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9317, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9299, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9353, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9281, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9354, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9292, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9351, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9294, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9278, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9318, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9340, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9299, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9292, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9267, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9312, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9291, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9327, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9415, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9291, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9314, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9311, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9227, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9315, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9332, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9210, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9372, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9385, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9290, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9263, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9269, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9232, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9251, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9279, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9279, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9300, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9259, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9214, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9291, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9293, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9258, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9295, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9227, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9276, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9235, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9297, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9255, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9274, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9285, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9352, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9285, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9259, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9302, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9337, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9350, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9358, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9308, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9279, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9267, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9199, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9179, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9247, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9343, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9265, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9220, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9266, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9226, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9243, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9223, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9271, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9244, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9189, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9190, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9258, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9225, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9280, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9252, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9228, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9186, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9229, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9260, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9206, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9283, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9242, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9210, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9240, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9244, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9213, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9229, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9281, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9216, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9237, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9191, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9233, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9239, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9298, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9255, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9280, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9160, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9187, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9244, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9218, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9220, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9244, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9202, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9247, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9239, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9209, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9279, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9234, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9293, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9216, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9261, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9213, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9223, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9211, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9167, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9207, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9184, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9243, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9199, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9214, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9215, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9275, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9259, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9176, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9202, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9227, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9194, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9286, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9258, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9201, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9204, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9172, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9176, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9263, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9253, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9245, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9267, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9200, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9257, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9217, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9246, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9201, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9209, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:  67%|██████████████████████           | 2/3 [39:59<20:22, 1222.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 loss: 299.64\n",
      "tensor(0.9184, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9159, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9200, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9206, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9261, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9160, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9229, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9191, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9176, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9221, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9260, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9207, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9221, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9289, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9185, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9231, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9227, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9160, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9223, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9191, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9304, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9185, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9192, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9273, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9241, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9271, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9340, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9254, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9209, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9328, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9222, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9222, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9275, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9218, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9178, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9202, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9225, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9201, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9247, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9201, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9204, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9217, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9215, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9272, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9145, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9218, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9239, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9163, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9138, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9218, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9241, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9218, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9218, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9193, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9281, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9198, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9260, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9152, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9174, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9188, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9214, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9191, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9199, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9239, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9167, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9194, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9219, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9277, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9392, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9180, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9279, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9368, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9252, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9247, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9262, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9319, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9190, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9188, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9241, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9212, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9172, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9191, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9173, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9188, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9290, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9196, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9214, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9237, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9147, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9194, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9176, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9231, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9312, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9221, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9254, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9195, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9192, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9174, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9165, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9217, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9177, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9187, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9166, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9202, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9217, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9252, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9206, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9217, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9180, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9176, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9147, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9205, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9186, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9166, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9219, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9171, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9240, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9229, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9221, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9156, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9198, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9186, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9221, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9240, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9155, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9204, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9247, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9225, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9211, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9254, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9170, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9170, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9293, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9155, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9182, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9232, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9238, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9205, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9176, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9154, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9170, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9210, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9208, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9230, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9173, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9152, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9150, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9156, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9133, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9208, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9198, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9218, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9130, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9210, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9218, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9220, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9241, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9153, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9224, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9154, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9139, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9137, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9213, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9209, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9208, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9146, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9165, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9184, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9157, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9196, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9215, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9225, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9180, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9188, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9176, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9147, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9208, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9173, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9207, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9147, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9237, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9152, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9166, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9168, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9128, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9170, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9175, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9157, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9153, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9123, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9205, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9164, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9188, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9238, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9134, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9172, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9178, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9141, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9204, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9247, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9135, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9239, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9200, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9205, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9168, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9172, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9138, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9143, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9169, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9223, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9185, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9148, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9177, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9211, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9159, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9162, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9248, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9132, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9167, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9142, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9187, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9126, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9181, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9171, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9226, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9169, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9132, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9191, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9232, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9175, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9197, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9206, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9166, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9185, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9134, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9141, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9166, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9272, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9208, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9166, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9171, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9176, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9223, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9191, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9221, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9173, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9148, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9159, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9194, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9167, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9204, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9137, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9168, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9126, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9160, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9223, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9159, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9206, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9168, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9145, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9185, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9202, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9180, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9146, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9216, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9160, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9192, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9138, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9153, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9197, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9259, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9190, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9191, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9158, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9224, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9190, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9188, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9186, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9195, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9166, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9181, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9213, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9191, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9206, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9158, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9238, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9160, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9228, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9158, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9130, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9153, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9120, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9141, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9150, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9207, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9134, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9201, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9168, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9250, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9232, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9175, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9210, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9191, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9201, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9251, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9206, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9180, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9176, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9155, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9131, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9203, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9214, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9231, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9227, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9162, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9209, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9165, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9171, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9149, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9179, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████| 3/3 [1:05:34<00:00, 1311.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 loss: 294.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.92\n",
      "Test accuracy: 98.87%\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "class MyViT(nn.Module):\n",
    "    def __init__(self, Dimensions, number_patchesRow,number_patchesColumn, number_blocks, Hidden_DGiven, NumberHeadsGiven, output_dimension):\n",
    "        \n",
    "        super(MyViT, self).__init__()\n",
    "        self.Dimensions = Dimensions  \n",
    "        self.number_patchesRow = number_patchesRow\n",
    "        self.number_patchesColumn=number_patchesColumn\n",
    "        self.number_blocks = number_blocks\n",
    "        self.Hidden_DGiven= Hidden_DGiven\n",
    "        self.NumberHeadsGiven = NumberHeadsGiven\n",
    "        \n",
    "        self.patch_size = (math.floor(Dimensions[1] / number_patchesRow), math.floor(Dimensions[2] / number_patchesColumn))\n",
    "        \n",
    "        self.input_d = int(Dimensions[0] * self.patch_size[0] * self.patch_size[1])\n",
    "        self.linear_mapper = nn.Linear(self.input_d, self.Hidden_DGiven)\n",
    "\n",
    "        self.class_token = nn.Parameter(torch.rand(1, self.Hidden_DGiven))\n",
    "\n",
    "        self.register_buffer(\n",
    "            \"positional_embeddings1\",\n",
    "            get_positional_embeddings1(number_patchesRow*number_patchesColumn + 1, Hidden_DGiven),\n",
    "            persistent=False,\n",
    "        )\n",
    "        \n",
    "        self.blocksA = nn.ModuleList(\n",
    "            [VisionTransformer(Hidden_DGiven, NumberHeadsGiven) for _ in range(number_blocks)]\n",
    "        )\n",
    "\n",
    "        self.mlp = nn.Sequential(nn.Linear(self.Hidden_DGiven, output_dimension), nn.Softmax(dim=-1))\n",
    "\n",
    "    def forward(self, images):        \n",
    "        n, c, h, w = images.shape\n",
    "        patches1A = images[0:n,0,0:self.patch_size[0]*self.number_patchesRow,0:self.patch_size[1]*self.number_patchesColumn]#patchify(images, self.n_patches).to(self.positional_embeddings1.device)\n",
    "        Size=64#(patches1A.size(1)*patches1A.size(2))/(self.number_patchesRow*self.number_patchesColumn)\n",
    "        #print(Size)\n",
    "        patches1=patches1A.reshape(n,self.number_patchesRow*self.number_patchesColumn,Size)\n",
    "        \n",
    "        tokens1 = self.linear_mapper(patches1)\n",
    "        tokensa = torch.cat((self.class_token.expand(n, 1, -1), tokens1), dim=1)\n",
    "\n",
    "        A    = tokensa + self.positional_embeddings1.repeat(n, 1, 1) \n",
    "\n",
    "        for block in self.blocksA:\n",
    "            A = block(A)\n",
    "        \n",
    "        output = torch.ones(n,self.Hidden_DGiven)\n",
    "        \n",
    "        output[0:n,self.Hidden_DGiven*0:self.Hidden_DGiven]  = A[:, 0]\n",
    "\n",
    "        return self.mlp(output)\n",
    "\n",
    "\n",
    "def main():\n",
    "    \n",
    "    transform = ToTensor()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = MyViT(\n",
    "        (1, 128,40), number_patchesRow=16, number_patchesColumn=5, number_blocks=2, Hidden_DGiven=5, NumberHeadsGiven=5, output_dimension=5\n",
    "    ).to(device)\n",
    "\n",
    "    NUMBER_EPOCHS = 3\n",
    "    LearningRate = 0.003\n",
    "\n",
    "    # Training Data loop\n",
    "    optimizer = Adam(model.parameters(), lr= LearningRate)\n",
    "    criterion = CrossEntropyLoss()\n",
    "\n",
    "    for epoch in trange(NUMBER_EPOCHS, desc=\"Training\"):\n",
    "        training_loss = 0.0\n",
    "        for batch in range(0,Length,Stride):\n",
    "            y = y_train[batch:batch+Stride]\n",
    "            x = X_train[batch:batch+Stride,0:1,0:128,0:40]\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            y_hat = model(x)\n",
    "            \n",
    "            loss = criterion(y_hat, y.type(torch.LongTensor))\n",
    "            print(loss)\n",
    "            training_loss += loss.detach().cpu().item()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        print(f\"Epoch {epoch + 1}/{NUMBER_EPOCHS} loss: {training_loss:.2f}\")\n",
    "\n",
    "    # Testing loop with testing data\n",
    "    with torch.no_grad():\n",
    "        correct, total = 0, 0\n",
    "        test_loss = 0.0\n",
    "        y = y_test\n",
    "        x = X_test\n",
    "\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        y_hat = model(x)\n",
    "        loss = criterion(y_hat, y.type(torch.LongTensor))\n",
    "\n",
    "        test_loss += loss.detach().cpu().item()\n",
    "\n",
    "        correct += torch.sum(torch.argmax(y_hat, dim=1) == y).detach().cpu().item()\n",
    "        total += len(x)\n",
    "        print(f\"Test loss: {test_loss:.2f}\")\n",
    "        print(f\"Test accuracy: {correct / total * 100:.2f}%\")\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "713c95a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:   0%|                                           | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.5892, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5778, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5768, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5685, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5697, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5670, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5579, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5521, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5596, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5492, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5392, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5346, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5321, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5307, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5096, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5160, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4992, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4986, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4925, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4728, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4826, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4690, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4601, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4728, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4556, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4526, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4518, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4524, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4268, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4565, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4287, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4411, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4435, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4357, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4335, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4328, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4444, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4423, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4433, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4356, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4372, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4435, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4353, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4386, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4407, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4389, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4386, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4225, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4213, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4468, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4133, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4378, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4398, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4365, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4414, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4472, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4319, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4308, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4271, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4309, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4306, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4350, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4254, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4305, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4437, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4377, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4353, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4287, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4289, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4379, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4399, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4426, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4415, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4397, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4467, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4383, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4212, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4230, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4237, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4323, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4362, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4333, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4359, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4263, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4344, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4248, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4508, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4477, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4380, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4249, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4392, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4442, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4244, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4461, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4338, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4226, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4234, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4283, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4361, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4244, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4433, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4337, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4216, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4322, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4438, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4275, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4276, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4303, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4235, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4261, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4191, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4370, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4373, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4396, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4242, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4340, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4203, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4282, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4303, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4416, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4314, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4358, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4365, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4364, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4357, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4238, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4295, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4415, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4182, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4384, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4276, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4214, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4219, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4279, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4527, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4336, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4299, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4198, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4297, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4336, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4368, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4345, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4429, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4282, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4403, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4346, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4323, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4372, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4585, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4165, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4389, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4446, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4343, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4376, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4327, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4253, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4200, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4386, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4253, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4345, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4356, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4313, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4361, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4307, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4319, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4245, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4276, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4170, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4260, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4189, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4238, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4179, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4261, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4151, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4215, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4305, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4256, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4272, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4176, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4168, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3943, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3961, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4093, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3938, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3910, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3899, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3895, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3786, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3880, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3565, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3604, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.3634, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3461, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3346, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3262, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3230, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3420, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2943, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3259, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3153, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3181, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3010, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3228, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2943, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3038, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2936, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3023, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2963, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2973, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2859, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3027, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2777, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2990, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2982, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2899, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2797, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2752, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2651, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2783, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2859, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2659, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2713, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2791, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2940, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2926, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2847, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2590, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2738, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2693, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2934, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2696, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2725, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2616, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2782, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2725, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2645, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2567, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2687, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2824, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2857, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2734, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2637, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2592, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2549, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2660, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2661, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2689, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2654, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2732, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2528, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2628, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2683, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2751, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2611, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2651, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2563, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2435, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2612, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2804, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2482, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2845, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2726, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2638, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2599, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2390, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2491, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2625, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2532, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2542, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2402, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2599, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2642, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2563, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2472, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2711, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2512, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2766, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2626, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2775, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2479, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2704, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2435, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2563, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2513, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2519, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2551, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2613, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2544, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2450, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2394, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2526, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2543, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2230, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2498, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2443, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2323, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2397, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2238, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2505, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2461, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2268, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2483, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2406, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2255, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2419, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2448, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2481, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2461, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2441, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2288, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2372, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2350, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2382, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2329, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2480, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2417, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2170, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2440, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2235, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2389, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:  33%|███████████                      | 1/3 [23:08<46:17, 1388.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 loss: 438.99\n",
      "tensor(1.2493, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2214, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2192, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2229, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2297, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2183, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2495, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2084, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2113, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2215, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2522, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2392, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2204, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2349, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2369, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2262, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2039, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2357, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2255, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2463, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2405, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2181, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2206, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2541, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2062, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2334, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2001, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2140, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1837, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2187, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2193, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2146, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2243, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1955, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1948, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2086, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1677, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1933, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2089, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2047, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1984, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1870, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1792, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1902, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1883, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1862, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1760, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1731, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1836, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1745, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1771, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2215, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1756, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1986, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1837, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1897, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1774, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1412, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1768, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1461, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1690, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1408, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1584, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1671, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1429, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1320, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1683, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1287, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1563, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1243, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1239, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1281, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1464, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1842, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1279, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1676, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1473, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1560, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1093, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1365, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1106, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1300, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1007, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1494, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1328, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1142, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1286, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1181, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1105, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1208, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0784, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1760, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0960, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1235, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1049, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1008, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0955, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0925, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1135, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0710, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1092, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0730, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0874, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0968, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0992, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0777, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0689, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0674, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0727, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0677, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0542, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0717, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0566, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0713, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0732, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0584, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0648, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0516, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0588, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0488, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0572, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0621, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0567, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0489, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0570, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0439, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0507, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0626, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0361, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0482, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0451, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0365, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0327, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0428, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0407, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0414, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0263, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0429, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0334, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0290, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0244, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0413, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0197, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0353, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0225, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0252, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0137, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0106, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0261, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0148, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0277, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0260, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9993, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0151, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0131, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0197, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0130, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0149, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0106, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0115, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0160, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0016, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9934, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0231, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0225, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0336, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0106, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0120, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0103, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9988, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0066, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0101, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0050, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0070, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0051, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0105, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0250, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9990, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0134, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9921, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0037, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9863, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0248, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9903, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9922, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9860, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9884, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9876, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9818, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9963, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9885, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9962, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9871, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9950, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9944, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9997, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9979, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9869, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0101, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9810, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9809, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9891, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0034, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9811, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9982, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9835, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9955, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9852, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9906, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9821, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9912, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9763, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9918, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9952, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9878, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9853, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9887, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9733, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9820, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9801, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9795, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9757, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9872, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9893, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9747, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9796, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9845, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9828, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9789, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9819, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9813, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9906, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9736, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9985, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9951, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9878, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9744, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9898, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9734, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9814, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9805, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9728, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9722, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9858, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9824, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9727, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9957, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9771, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9802, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9776, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9736, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9777, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9796, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9723, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9839, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9799, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9673, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9973, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9743, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9713, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9771, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9776, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9889, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9765, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9629, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9793, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9751, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9756, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9724, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9644, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9831, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9823, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9786, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9879, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9658, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9684, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9792, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9928, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9755, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9894, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9895, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9757, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9843, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9881, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9985, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9666, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9892, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9744, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9786, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9552, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9776, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9751, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9762, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9776, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9694, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9720, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9684, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9701, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9647, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9674, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9720, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9812, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9819, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9688, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9966, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9835, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9794, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9825, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9798, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9710, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9631, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9856, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9679, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9751, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9742, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9867, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9568, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9959, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9619, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9879, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:  67%|██████████████████████           | 2/3 [40:09<19:32, 1172.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 loss: 337.98\n",
      "tensor(0.9809, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9747, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9665, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9685, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9773, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9692, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9744, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9608, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9592, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9668, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9662, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9663, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9591, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9841, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9710, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9784, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9563, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9595, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9607, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9634, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9759, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9648, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9754, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9668, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9611, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9617, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9575, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9593, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9576, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9765, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9625, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9647, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9702, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9555, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9575, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9695, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9576, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9646, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9656, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9610, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9609, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9648, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9613, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9656, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9755, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9584, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9716, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9587, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9537, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9675, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9692, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9734, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9614, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9616, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9641, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9748, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9672, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9667, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9560, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9826, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9718, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9801, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9706, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9757, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9557, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9640, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9569, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9596, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9702, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9701, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9629, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9499, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9623, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9606, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9671, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9548, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9700, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9697, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9488, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9746, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9567, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9609, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9626, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9530, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9540, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9584, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9628, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9682, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9589, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9571, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9582, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9595, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9590, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9529, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9580, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9673, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9530, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9634, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9711, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9580, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9791, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9510, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9769, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9495, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9713, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9652, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9603, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9733, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9583, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9713, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9494, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9558, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9786, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9666, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9682, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9707, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9583, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9638, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9557, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9547, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9523, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9606, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9548, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9526, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9444, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9564, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9507, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9658, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9600, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9584, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9629, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9615, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9561, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9507, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9634, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9540, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9434, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9558, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9591, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9577, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9518, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9637, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9527, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9578, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9588, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9532, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9497, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9502, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9515, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9583, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9620, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9546, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9463, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9574, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9626, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9657, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9573, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9629, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9498, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9565, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9621, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9484, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9433, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9507, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9556, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9532, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9498, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9587, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9580, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9536, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9562, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9529, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9461, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9458, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9396, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9507, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9512, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9617, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9463, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9494, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9490, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9477, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9638, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9407, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9619, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9469, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9451, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9557, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9433, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9557, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9512, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9460, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9411, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9555, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9521, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9578, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9567, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9392, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9603, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9379, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9428, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9559, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9559, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9439, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9422, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9412, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9479, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9544, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9400, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9398, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9379, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9423, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9390, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9444, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9480, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9427, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9411, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9395, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9396, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9335, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9350, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9355, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9464, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9432, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9400, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9376, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9441, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9496, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9390, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9415, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9342, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9450, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9437, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9384, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9419, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9405, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9401, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9480, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9371, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9383, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9398, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9354, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9363, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9342, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9381, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9336, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9328, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9417, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9421, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9333, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9408, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9374, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9331, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9394, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9425, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9376, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9432, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9445, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9295, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9319, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9337, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9427, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9354, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9369, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9262, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9419, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9343, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9349, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9283, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9287, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9394, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9313, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9374, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9335, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9319, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9284, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9369, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9348, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9343, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9383, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9355, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9314, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9366, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9378, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9290, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9271, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9337, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9337, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9311, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9202, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9324, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9277, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9271, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9414, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9295, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9333, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9288, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9321, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9303, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9340, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9245, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9286, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9287, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9361, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9297, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9345, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9304, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9315, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9354, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9289, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9275, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9311, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9259, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9309, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9281, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9351, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9306, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9268, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9260, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9306, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|█████████████████████████████████| 3/3 [56:59<00:00, 1139.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 loss: 304.38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.93\n",
      "Test accuracy: 97.52%\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "class MyViT(nn.Module):\n",
    "    def __init__(self, Dimensions, number_patchesRow,number_patchesColumn, number_blocks, Hidden_DGiven, NumberHeadsGiven, output_dimension):\n",
    "        \n",
    "        super(MyViT, self).__init__()\n",
    "        self.Dimensions = Dimensions  \n",
    "        self.number_patchesRow = number_patchesRow\n",
    "        self.number_patchesColumn=number_patchesColumn\n",
    "        self.number_blocks = number_blocks\n",
    "        self.Hidden_DGiven= Hidden_DGiven\n",
    "        self.NumberHeadsGiven = NumberHeadsGiven\n",
    "        \n",
    "        self.patch_size = (math.floor(Dimensions[1] / number_patchesRow), math.floor(Dimensions[2] / number_patchesColumn))\n",
    "        \n",
    "        self.input_d = int(Dimensions[0] * self.patch_size[0] * self.patch_size[1])\n",
    "        self.linear_mapper = nn.Linear(self.input_d, self.Hidden_DGiven)\n",
    "\n",
    "        self.class_token = nn.Parameter(torch.rand(1, self.Hidden_DGiven))\n",
    "\n",
    "        self.register_buffer(\n",
    "            \"positional_embeddings1\",\n",
    "            get_positional_embeddings2(number_patchesRow*number_patchesColumn + 1, Hidden_DGiven),\n",
    "            persistent=False,\n",
    "        )\n",
    "        \n",
    "        self.blocksA = nn.ModuleList(\n",
    "            [VisionTransformer(Hidden_DGiven, NumberHeadsGiven) for _ in range(number_blocks)]\n",
    "        )\n",
    "\n",
    "        self.mlp = nn.Sequential(nn.Linear(self.Hidden_DGiven, output_dimension), nn.Softmax(dim=-1))\n",
    "\n",
    "    def forward(self, images):        \n",
    "        n, c, h, w = images.shape\n",
    "        patches1A = images[0:n,0,0:self.patch_size[0]*self.number_patchesRow,0:self.patch_size[1]*self.number_patchesColumn]#patchify(images, self.n_patches).to(self.positional_embeddings1.device)\n",
    "        Size=64#(patches1A.size(1)*patches1A.size(2))/(self.number_patchesRow*self.number_patchesColumn)\n",
    "        #print(Size)\n",
    "        patches1=patches1A.reshape(n,self.number_patchesRow*self.number_patchesColumn,Size)\n",
    "        \n",
    "        tokens1 = self.linear_mapper(patches1)\n",
    "        tokensa = torch.cat((self.class_token.expand(n, 1, -1), tokens1), dim=1)\n",
    "\n",
    "        A    = tokensa + self.positional_embeddings1.repeat(n, 1, 1) \n",
    "\n",
    "        for block in self.blocksA:\n",
    "            A = block(A)\n",
    "        \n",
    "        output = torch.ones(n,self.Hidden_DGiven)\n",
    "        \n",
    "        output[0:n,self.Hidden_DGiven*0:self.Hidden_DGiven]  = A[:, 0]\n",
    "\n",
    "        return self.mlp(output)\n",
    "\n",
    "\n",
    "def main():\n",
    "    \n",
    "    transform = ToTensor()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = MyViT(\n",
    "        (1, 128,40), number_patchesRow=16, number_patchesColumn=5, number_blocks=2, Hidden_DGiven=5, NumberHeadsGiven=5, output_dimension=5\n",
    "    ).to(device)\n",
    "\n",
    "    NUMBER_EPOCHS = 3\n",
    "    LearningRate = 0.003\n",
    "\n",
    "    # Training Data loop\n",
    "    optimizer = Adam(model.parameters(), lr= LearningRate)\n",
    "    criterion = CrossEntropyLoss()\n",
    "\n",
    "    for epoch in trange(NUMBER_EPOCHS, desc=\"Training\"):\n",
    "        training_loss = 0.0\n",
    "        for batch in range(0,Length,Stride):\n",
    "            y = y_train[batch:batch+Stride]\n",
    "            x = X_train[batch:batch+Stride,0:1,0:128,0:40]\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            y_hat = model(x)\n",
    "            \n",
    "            loss = criterion(y_hat, y.type(torch.LongTensor))\n",
    "            print(loss)\n",
    "            training_loss += loss.detach().cpu().item()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        print(f\"Epoch {epoch + 1}/{NUMBER_EPOCHS} loss: {training_loss:.2f}\")\n",
    "\n",
    "    # Testing loop with testing data\n",
    "    with torch.no_grad():\n",
    "        correct, total = 0, 0\n",
    "        test_loss = 0.0\n",
    "        y = y_test\n",
    "        x = X_test\n",
    "\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        y_hat = model(x)\n",
    "        loss = criterion(y_hat, y.type(torch.LongTensor))\n",
    "\n",
    "        test_loss += loss.detach().cpu().item()\n",
    "\n",
    "        correct += torch.sum(torch.argmax(y_hat, dim=1) == y).detach().cpu().item()\n",
    "        total += len(x)\n",
    "        print(f\"Test loss: {test_loss:.2f}\")\n",
    "        print(f\"Test accuracy: {correct / total * 100:.2f}%\")\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b2d64176",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:   0%|                                           | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.6192, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6206, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6062, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6126, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6084, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6096, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6037, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6103, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6093, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6043, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6049, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6023, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6022, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5980, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5989, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5960, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5969, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5935, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5907, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5912, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5840, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5853, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5842, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5842, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5819, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5728, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5711, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5672, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5633, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5595, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5559, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5524, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5462, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5382, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5294, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5226, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5025, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5073, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5048, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4910, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4687, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4689, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4594, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4467, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4496, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4246, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4060, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4044, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3782, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3827, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3684, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3529, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3559, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3606, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3369, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3258, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3276, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3226, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3071, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3168, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3196, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2879, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3042, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2989, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3066, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2923, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2913, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2980, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2762, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2654, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2969, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2832, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2812, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2908, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2861, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2848, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2606, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2626, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2553, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2769, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2711, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2438, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2636, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2571, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2630, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2526, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2845, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2807, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2591, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2437, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2642, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2707, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2532, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2605, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2583, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2481, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2421, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2444, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2513, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2435, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2675, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2625, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2494, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2504, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2627, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2438, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2471, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2292, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2350, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2411, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2286, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2384, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2391, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2531, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2499, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2466, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2437, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2294, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2412, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2419, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2491, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2427, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2250, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2363, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2442, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2330, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2441, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2582, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2275, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2458, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2244, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2300, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2276, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2281, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2523, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2382, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2229, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2171, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2359, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2401, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2334, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2307, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2401, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2204, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2253, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2227, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2238, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2273, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2482, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2233, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2307, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2410, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2048, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2299, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2238, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2273, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2201, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2253, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2237, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2208, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2419, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2301, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2208, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2302, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2279, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2036, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2179, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2147, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2045, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2035, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2144, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2225, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2280, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2132, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2118, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2316, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2194, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2375, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2290, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2265, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2044, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2254, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2283, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2277, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2198, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2097, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2184, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2216, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2277, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2013, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2129, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.2239, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2145, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2097, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2033, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2010, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2087, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1913, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2181, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2080, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1956, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1929, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2096, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1922, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1880, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1944, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1780, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1697, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1772, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1683, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1626, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1443, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1415, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1533, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1435, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1473, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1177, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0977, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1166, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1012, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0968, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0917, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0956, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0789, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0950, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0900, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0867, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0814, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0795, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0852, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0771, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0652, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0627, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0805, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0596, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0623, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0746, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0653, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0688, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0505, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0700, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0465, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0452, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0427, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0553, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0352, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0473, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0334, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0448, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0426, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0386, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0476, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0541, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0430, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0318, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0171, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0151, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0404, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0496, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0384, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0203, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0113, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0262, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0379, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0080, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0135, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0216, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0151, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0031, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0072, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0246, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0194, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0146, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9914, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0104, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0015, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0040, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0193, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0023, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0035, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0179, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9958, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0086, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0088, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9993, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0040, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9956, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9962, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9983, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9893, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9981, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9873, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9847, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9952, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0014, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9864, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9861, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9838, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9917, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9927, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9759, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9871, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9827, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9864, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9931, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9797, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9889, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0088, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0241, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9901, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9873, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9836, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9717, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9646, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9758, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9830, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9721, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9807, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9729, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9769, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:  33%|███████████                      | 1/3 [18:45<37:31, 1125.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 loss: 389.93\n",
      "tensor(0.9695, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9566, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9583, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9601, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9599, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9629, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9765, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9651, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9772, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9665, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9667, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9676, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9677, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9646, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9618, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9636, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9551, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9574, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9583, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9452, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9652, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9469, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9580, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9747, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9628, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9478, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9602, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9567, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9434, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9549, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9561, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9502, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9459, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9395, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9369, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9647, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9489, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9636, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9741, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9547, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9593, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9495, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9663, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9605, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9562, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9595, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9482, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9428, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9520, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9494, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9568, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9545, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9530, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9498, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9588, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9556, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9615, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9552, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9486, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9573, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9537, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9496, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9615, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9513, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9407, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9435, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9544, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9406, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9527, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9521, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9465, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9575, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9491, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9483, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9462, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9615, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9466, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9481, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9459, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9453, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9347, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9503, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9559, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9434, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9514, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9496, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9559, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9458, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9602, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9471, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9435, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9588, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9445, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9527, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9551, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9449, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9467, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9481, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9416, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9486, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9407, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9498, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9422, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9526, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9412, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9595, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9609, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9558, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9440, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9610, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9455, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9438, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9485, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9567, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9506, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9404, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9474, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9302, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9366, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9568, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9597, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9640, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9624, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9551, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9472, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9484, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9508, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9520, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9639, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9618, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9565, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9506, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9578, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9619, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9645, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9777, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9602, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9430, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9410, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9388, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9396, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9447, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9376, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9337, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9450, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9377, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9392, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9362, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9423, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9313, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9426, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9548, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9370, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9455, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9322, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9446, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9453, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9385, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9438, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9526, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9711, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9817, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9682, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9615, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9577, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9412, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9399, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9328, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9456, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9530, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9434, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9501, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9525, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9578, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9703, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9794, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9903, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9802, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9699, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9771, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9816, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9698, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9791, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9487, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9365, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9320, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9341, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9430, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9400, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9363, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9295, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9287, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9299, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9318, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9346, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9367, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9416, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9363, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9370, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9354, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9341, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9469, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9481, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9434, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9474, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9421, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9470, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9338, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9393, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9320, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9425, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9410, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9417, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9743, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9802, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9744, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9558, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9450, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9385, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9350, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9540, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9570, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9504, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9582, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9674, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9717, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9642, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9786, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9557, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9526, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9496, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9608, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9461, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9491, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9453, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9381, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9491, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9443, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9383, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9422, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9422, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9344, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9314, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9343, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9340, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9342, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9421, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9313, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9380, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9395, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9305, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9404, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9374, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9360, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9365, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9423, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9290, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9410, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9427, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9422, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9375, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9330, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9313, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9304, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9380, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9356, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9258, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9282, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9300, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9383, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9388, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9368, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9434, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9865, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0206, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9850, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9749, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9809, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9900, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9661, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9546, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9455, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9364, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9510, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9407, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9542, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9514, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9472, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9504, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9461, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9451, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9506, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9377, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9445, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9526, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9349, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9435, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9362, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9399, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9411, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9469, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9460, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9445, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9377, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9372, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9333, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9426, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9354, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9282, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9252, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9266, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9296, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9295, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9228, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9249, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9321, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9421, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9398, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9366, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9414, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:  67%|██████████████████████           | 2/3 [38:03<19:04, 1144.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 loss: 303.82\n",
      "tensor(0.9308, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9345, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9748, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9864, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9992, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9915, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0028, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0217, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0016, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9683, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9476, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9423, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9398, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9450, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9348, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9424, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9319, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9342, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9391, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9283, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9442, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9400, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9492, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9492, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9414, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9452, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9387, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9335, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9243, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9280, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9315, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9300, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9264, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9224, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9254, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9431, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9348, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9371, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9305, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9332, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9301, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9295, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9313, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9334, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9306, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9296, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9396, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9445, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9439, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9385, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9533, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9426, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9419, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9504, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9404, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9335, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9327, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9330, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9198, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9253, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9295, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9355, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9370, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9278, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9264, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9315, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9359, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9237, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9284, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9271, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9283, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9342, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9344, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9292, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9305, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9392, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9312, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9366, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9245, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9273, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9273, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9322, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9285, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9238, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9310, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9306, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9350, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9237, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9279, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9284, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9283, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9378, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9330, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9333, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9341, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9227, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9301, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9291, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9203, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9287, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9313, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9429, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9433, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9484, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9479, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9387, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9315, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9255, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9293, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9339, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9268, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9215, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9311, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9309, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9392, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9287, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9370, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9297, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9256, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9295, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9235, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9267, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9263, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9270, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9241, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9236, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9285, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9280, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9339, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9298, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9258, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9247, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9282, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9203, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9291, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9319, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9241, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9255, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9277, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9260, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9205, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9353, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9369, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9338, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9412, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9334, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9371, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9339, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9366, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9324, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9408, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9430, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9249, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9320, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9673, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0199, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0527, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0697, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1156, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1031, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0857, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0756, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0574, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0137, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0194, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0075, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9816, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9875, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9718, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9825, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9469, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9498, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9462, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9506, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9421, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9371, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9423, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9462, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9420, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9412, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9420, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9360, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9311, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9297, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9331, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9254, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9291, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9252, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9335, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9311, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9168, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9272, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9257, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9230, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9222, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9286, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9325, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9301, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9487, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9389, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9423, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9383, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9433, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9457, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9431, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9415, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9397, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9246, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9205, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9249, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9236, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9266, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9224, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9290, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9328, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9388, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9411, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9331, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9298, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9366, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9431, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9310, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9378, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9334, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9388, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9405, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9278, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9331, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9360, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9426, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9482, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9595, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9580, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9561, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9737, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9704, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9786, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9576, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9620, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9559, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9503, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9591, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9509, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9422, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9381, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9260, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9365, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9284, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9286, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9276, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9222, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9372, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9288, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9266, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9293, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9291, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9235, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9333, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9330, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9291, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9331, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9298, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9248, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9253, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9291, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9321, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9214, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9241, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9229, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9296, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9323, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9422, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9280, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9355, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9415, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9348, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9350, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9380, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9412, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9360, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9437, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9310, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9270, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9385, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9266, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9256, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9248, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9219, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9270, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9193, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9260, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9349, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9237, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9334, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9401, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9320, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9359, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9265, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9304, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9362, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9285, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9478, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9548, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9550, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9541, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9527, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9514, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9596, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9624, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9572, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9567, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9438, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9603, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9524, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9294, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9428, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9477, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9562, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9519, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9578, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|█████████████████████████████████| 3/3 [57:07<00:00, 1142.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 loss: 301.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.97\n",
      "Test accuracy: 93.72%\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "class MyViT(nn.Module):\n",
    "    def __init__(self, Dimensions, number_patchesRow,number_patchesColumn, number_blocks, Hidden_DGiven, NumberHeadsGiven, output_dimension):\n",
    "        \n",
    "        super(MyViT, self).__init__()\n",
    "        self.Dimensions = Dimensions  \n",
    "        self.number_patchesRow = number_patchesRow\n",
    "        self.number_patchesColumn=number_patchesColumn\n",
    "        self.number_blocks = number_blocks\n",
    "        self.Hidden_DGiven= Hidden_DGiven\n",
    "        self.NumberHeadsGiven = NumberHeadsGiven\n",
    "        \n",
    "        self.patch_size = (math.floor(Dimensions[1] / number_patchesRow), math.floor(Dimensions[2] / number_patchesColumn))\n",
    "        \n",
    "        self.input_d = int(Dimensions[0] * self.patch_size[0] * self.patch_size[1])\n",
    "        self.linear_mapper = nn.Linear(self.input_d, self.Hidden_DGiven)\n",
    "\n",
    "        self.class_token = nn.Parameter(torch.rand(1, self.Hidden_DGiven))\n",
    "\n",
    "        self.register_buffer(\n",
    "            \"positional_embeddings1\",\n",
    "            get_positional_embeddings3(number_patchesRow*number_patchesColumn + 1, Hidden_DGiven),\n",
    "            persistent=False,\n",
    "        )\n",
    "        \n",
    "        self.blocksA = nn.ModuleList(\n",
    "            [VisionTransformer(Hidden_DGiven, NumberHeadsGiven) for _ in range(number_blocks)]\n",
    "        )\n",
    "\n",
    "        self.mlp = nn.Sequential(nn.Linear(self.Hidden_DGiven, output_dimension), nn.Softmax(dim=-1))\n",
    "\n",
    "    def forward(self, images):        \n",
    "        n, c, h, w = images.shape\n",
    "        patches1A = images[0:n,0,0:self.patch_size[0]*self.number_patchesRow,0:self.patch_size[1]*self.number_patchesColumn]#patchify(images, self.n_patches).to(self.positional_embeddings1.device)\n",
    "        Size=64#(patches1A.size(1)*patches1A.size(2))/(self.number_patchesRow*self.number_patchesColumn)\n",
    "        #print(Size)\n",
    "        patches1=patches1A.reshape(n,self.number_patchesRow*self.number_patchesColumn,Size)\n",
    "        \n",
    "        tokens1 = self.linear_mapper(patches1)\n",
    "        tokensa = torch.cat((self.class_token.expand(n, 1, -1), tokens1), dim=1)\n",
    "\n",
    "        A    = tokensa + self.positional_embeddings1.repeat(n, 1, 1) \n",
    "\n",
    "        for block in self.blocksA:\n",
    "            A = block(A)\n",
    "        \n",
    "        output = torch.ones(n,self.Hidden_DGiven)\n",
    "        \n",
    "        output[0:n,self.Hidden_DGiven*0:self.Hidden_DGiven]  = A[:, 0]\n",
    "\n",
    "        return self.mlp(output)\n",
    "\n",
    "\n",
    "def main():\n",
    "    \n",
    "    transform = ToTensor()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = MyViT(\n",
    "        (1, 128,40), number_patchesRow=16, number_patchesColumn=5, number_blocks=2, Hidden_DGiven=5, NumberHeadsGiven=5, output_dimension=5\n",
    "    ).to(device)\n",
    "\n",
    "    NUMBER_EPOCHS = 3\n",
    "    LearningRate = 0.003\n",
    "\n",
    "    # Training Data loop\n",
    "    optimizer = Adam(model.parameters(), lr= LearningRate)\n",
    "    criterion = CrossEntropyLoss()\n",
    "\n",
    "    for epoch in trange(NUMBER_EPOCHS, desc=\"Training\"):\n",
    "        training_loss = 0.0\n",
    "        for batch in range(0,Length,Stride):\n",
    "            y = y_train[batch:batch+Stride]\n",
    "            x = X_train[batch:batch+Stride,0:1,0:128,0:40]\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            y_hat = model(x)\n",
    "            \n",
    "            loss = criterion(y_hat, y.type(torch.LongTensor))\n",
    "            print(loss)\n",
    "            training_loss += loss.detach().cpu().item()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        print(f\"Epoch {epoch + 1}/{NUMBER_EPOCHS} loss: {training_loss:.2f}\")\n",
    "\n",
    "    # Testing loop with testing data\n",
    "    with torch.no_grad():\n",
    "        correct, total = 0, 0\n",
    "        test_loss = 0.0\n",
    "        y = y_test\n",
    "        x = X_test\n",
    "\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        y_hat = model(x)\n",
    "        loss = criterion(y_hat, y.type(torch.LongTensor))\n",
    "\n",
    "        test_loss += loss.detach().cpu().item()\n",
    "\n",
    "        correct += torch.sum(torch.argmax(y_hat, dim=1) == y).detach().cpu().item()\n",
    "        total += len(x)\n",
    "        print(f\"Test loss: {test_loss:.2f}\")\n",
    "        print(f\"Test accuracy: {correct / total * 100:.2f}%\")\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "26b15203",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:   0%|                                           | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.6169, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6282, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6177, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6145, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6151, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6133, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6176, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6123, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6102, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6042, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6138, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6132, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6110, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6046, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6029, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6082, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6092, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6044, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6039, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6019, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5969, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5994, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5985, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5990, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5922, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5956, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5890, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5889, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5923, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5928, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5862, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5798, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5773, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5703, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5710, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5664, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5678, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5558, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5562, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5503, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5433, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5352, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5301, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5190, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5188, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5115, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4984, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4845, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4704, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4834, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4591, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4734, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4539, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4377, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4476, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4405, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4184, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4157, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4086, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4021, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3786, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3896, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3732, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3581, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3897, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3804, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3718, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3565, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3425, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3511, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3524, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3371, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3245, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3291, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3176, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3267, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2927, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2891, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3033, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2958, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2942, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2696, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2584, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2553, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2593, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2375, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2649, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2528, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2328, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2182, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2271, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2289, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1985, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2091, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2034, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1848, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1706, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1835, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1762, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1684, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1780, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1642, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1418, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1596, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1659, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1387, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1410, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1204, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1326, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1362, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1064, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1260, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1169, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1300, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1299, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1165, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1144, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0928, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1058, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1211, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1126, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1147, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1064, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0948, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1093, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0805, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1009, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1201, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0805, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0821, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0861, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0793, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0798, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0654, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0847, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0722, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0621, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0637, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0632, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0589, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0546, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0592, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0495, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0529, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0497, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0476, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0357, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0477, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0510, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0408, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0510, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0552, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0266, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0423, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0239, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0390, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0269, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0178, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0208, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0211, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0287, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0266, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0037, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0155, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0383, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0084, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0246, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0244, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0135, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0363, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0024, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0205, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0204, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0236, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0067, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9999, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0036, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0063, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0118, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0082, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0132, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0020, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9929, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0023, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0034, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9974, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0047, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0209, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0077, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9980, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0042, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9898, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9907, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9987, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9993, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0033, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9822, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0011, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9900, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9978, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0047, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0075, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9843, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9930, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9982, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0078, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0025, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9959, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9954, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9932, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9938, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9942, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9999, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9990, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9964, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9925, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9860, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9970, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9903, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9905, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9973, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9903, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9878, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9986, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9868, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9733, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9875, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9929, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0011, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9850, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9972, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0028, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9896, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9718, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9859, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9865, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9887, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9875, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9884, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9767, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9873, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9907, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9723, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9830, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9791, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9854, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9812, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9815, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9789, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9803, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9897, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9767, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9759, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9788, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9911, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9678, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9827, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9838, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9813, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9753, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9687, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9852, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9696, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9813, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9719, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9860, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9889, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9779, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9892, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9934, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9886, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9835, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9701, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9867, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9966, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9749, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9718, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9890, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9667, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9790, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9696, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9800, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9921, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9757, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9811, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9734, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9754, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9714, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9619, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9703, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9929, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9638, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9718, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9687, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9886, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9709, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9709, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9898, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9723, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9625, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9736, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9724, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9673, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9689, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9700, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9696, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9620, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9552, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9601, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9658, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9631, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9717, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9598, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9609, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9654, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9664, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9603, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9603, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9728, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:  33%|███████████▎                      | 1/3 [15:38<31:17, 938.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 loss: 367.93\n",
      "tensor(0.9584, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9555, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9544, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9520, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9531, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9622, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9577, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9727, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9516, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9665, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9651, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9537, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9686, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9643, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9613, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9563, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9608, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9603, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9649, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9650, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9580, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9566, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9574, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9718, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9710, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9489, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9658, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9574, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9419, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9555, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9536, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9557, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9470, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9482, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9531, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9509, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9476, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9543, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9605, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9435, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9617, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9496, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9587, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9626, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9472, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9547, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9600, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9556, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9503, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9523, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9477, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9529, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9515, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9533, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9523, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9556, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9600, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9432, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9461, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9476, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9581, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9596, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9546, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9554, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9521, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9487, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9645, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9444, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9570, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9430, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9518, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9620, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9576, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9568, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9516, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9700, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9602, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9538, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9514, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9540, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9448, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9498, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9450, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9494, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9529, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9469, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9563, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9549, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9457, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9452, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9440, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9628, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9551, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9549, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9503, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9485, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9480, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9589, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9518, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9515, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9529, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9542, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9497, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9561, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9535, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9565, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9477, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9444, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9379, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9582, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9539, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9475, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9464, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9461, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9512, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9440, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9473, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9477, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9375, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9571, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9474, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9444, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9555, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9451, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9421, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9450, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9527, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9547, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9473, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9415, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9403, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9416, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9456, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9359, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9432, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9447, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9517, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9484, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9447, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9364, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9459, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9439, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9444, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9567, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9555, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9405, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9406, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9378, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9432, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9438, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9398, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9442, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9341, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9450, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9332, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9446, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9364, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9359, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9408, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9381, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9477, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9368, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9325, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9388, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9475, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9337, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9404, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9391, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9431, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9482, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9322, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9323, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9445, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9423, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9368, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9324, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9361, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9356, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9383, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9422, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9404, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9405, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9319, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9284, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9417, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9354, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9334, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9388, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9436, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9385, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9269, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9407, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9350, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9351, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9353, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9396, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9394, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9256, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9343, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9324, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9379, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9370, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9463, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9303, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9347, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9376, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9396, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9336, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9382, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9335, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9412, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9326, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9334, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9393, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9308, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9277, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9374, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9332, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9236, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9293, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9362, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9299, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9318, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9320, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9329, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9292, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9292, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9445, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9358, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9331, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9326, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9374, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9318, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9327, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9235, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9276, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9258, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9320, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9288, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9343, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9278, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9281, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9289, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9296, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9256, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9270, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9325, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9251, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9308, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9451, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9318, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9295, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9287, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9343, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9329, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9292, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9255, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9259, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9344, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9308, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9328, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9276, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9314, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9230, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9296, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9328, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9283, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9279, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9222, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9294, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9372, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9376, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9288, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9187, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9424, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9304, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9256, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9269, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9332, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9236, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9289, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9268, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9224, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9308, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9278, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9330, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9262, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9290, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9262, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9171, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9294, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9303, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9258, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9238, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9299, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9362, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9289, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9314, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9330, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9315, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9248, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9239, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9252, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9257, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9259, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9236, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9324, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9256, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9238, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9204, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9279, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9247, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9239, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9261, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9227, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9303, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9240, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9267, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9211, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9306, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:  67%|██████████████████████▋           | 2/3 [31:18<15:39, 939.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 loss: 301.34\n",
      "tensor(0.9276, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9252, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9284, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9223, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9245, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9340, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9236, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9295, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9282, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9241, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9247, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9269, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9303, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9279, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9258, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9184, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9208, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9287, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9242, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9241, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9280, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9235, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9283, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9274, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9294, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9284, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9214, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9200, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9204, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9296, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9209, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9240, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9201, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9174, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9158, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9260, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9257, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9227, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9202, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9171, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9336, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9185, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9252, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9299, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9253, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9221, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9268, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9249, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9220, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9207, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9198, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9242, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9189, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9233, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9215, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9251, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9296, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9224, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9221, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9224, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9278, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9308, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9285, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9266, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9154, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9237, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9287, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9165, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9234, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9169, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9218, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9287, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9239, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9181, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9204, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9288, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9231, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9262, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9237, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9226, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9161, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9195, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9218, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9185, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9261, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9163, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9255, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9255, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9164, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9214, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9196, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9282, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9240, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9240, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9277, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9162, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9264, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9276, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9221, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9262, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9304, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9268, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9220, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9224, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9251, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9398, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9280, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9176, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9207, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9323, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9193, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9225, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9226, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9252, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9304, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9165, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9343, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9214, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9221, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9208, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9240, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9207, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9319, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9253, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9211, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9217, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9323, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9306, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9282, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9247, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9268, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9168, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9239, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9183, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9234, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9222, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9282, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9232, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9213, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9163, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9191, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9223, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9240, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9246, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9267, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9157, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9235, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9169, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9242, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9207, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9219, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9252, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9160, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9197, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9189, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9202, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9235, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9164, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9237, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9165, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9226, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9130, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9189, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9183, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9219, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9171, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9186, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9182, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9255, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9257, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9251, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9172, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9260, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9195, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9230, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9154, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9227, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9174, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9170, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9231, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9286, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9203, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9154, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9146, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9233, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9218, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9202, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9235, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9201, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9192, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9158, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9190, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9161, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9141, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9174, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9215, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9178, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9164, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9216, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9176, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9211, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9197, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9229, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9172, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9248, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9208, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9213, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9167, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9154, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9158, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9227, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9196, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9194, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9200, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9205, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9129, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9200, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9199, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9133, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9200, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9208, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9174, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9186, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9178, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9181, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9186, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9153, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9287, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9182, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9226, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9162, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9211, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9166, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9166, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9154, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9153, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9171, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9158, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9165, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9213, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9171, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9205, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9196, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9168, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9191, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9172, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9150, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9171, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9185, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9252, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9173, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9185, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9152, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9162, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9167, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9136, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9175, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9170, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9158, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9183, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9182, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9121, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9208, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9107, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9173, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9208, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9116, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9094, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9139, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9195, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9240, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9197, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9184, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9111, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9263, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9175, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9167, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9121, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9221, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9153, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9194, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9146, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9136, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9196, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9169, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9192, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9146, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9199, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9166, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9102, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9196, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9180, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9170, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9152, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9182, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9203, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9218, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9214, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9172, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9201, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9161, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9179, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9216, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9182, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9174, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9142, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9204, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9167, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9201, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9159, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9202, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9205, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9176, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9166, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9106, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9164, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9185, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9169, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9124, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9209, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████| 3/3 [46:43<00:00, 934.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 loss: 294.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.92\n",
      "Test accuracy: 98.83%\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "class MyViT(nn.Module):\n",
    "    def __init__(self, Dimensions, number_patchesRow,number_patchesColumn, number_blocks, Hidden_DGiven, NumberHeadsGiven, output_dimension):\n",
    "        \n",
    "        super(MyViT, self).__init__()\n",
    "        self.Dimensions = Dimensions  \n",
    "        self.number_patchesRow = number_patchesRow\n",
    "        self.number_patchesColumn=number_patchesColumn\n",
    "        self.number_blocks = number_blocks\n",
    "        self.Hidden_DGiven= Hidden_DGiven\n",
    "        self.NumberHeadsGiven = NumberHeadsGiven\n",
    "        \n",
    "        self.patch_size = (math.floor(Dimensions[1] / number_patchesRow), math.floor(Dimensions[2] / number_patchesColumn))\n",
    "        \n",
    "        self.input_d = int(Dimensions[0] * self.patch_size[0] * self.patch_size[1])\n",
    "        self.linear_mapper = nn.Linear(self.input_d, self.Hidden_DGiven)\n",
    "\n",
    "        self.class_token = nn.Parameter(torch.rand(1, self.Hidden_DGiven))\n",
    "\n",
    "        self.register_buffer(\n",
    "            \"positional_embeddings1\",\n",
    "            get_positional_embeddings4(number_patchesRow*number_patchesColumn + 1, Hidden_DGiven),\n",
    "            persistent=False,\n",
    "        )\n",
    "        \n",
    "        self.blocksA = nn.ModuleList(\n",
    "            [VisionTransformer(Hidden_DGiven, NumberHeadsGiven) for _ in range(number_blocks)]\n",
    "        )\n",
    "\n",
    "        self.mlp = nn.Sequential(nn.Linear(self.Hidden_DGiven, output_dimension), nn.Softmax(dim=-1))\n",
    "\n",
    "    def forward(self, images):        \n",
    "        n, c, h, w = images.shape\n",
    "        patches1A = images[0:n,0,0:self.patch_size[0]*self.number_patchesRow,0:self.patch_size[1]*self.number_patchesColumn]#patchify(images, self.n_patches).to(self.positional_embeddings1.device)\n",
    "        Size=64#(patches1A.size(1)*patches1A.size(2))/(self.number_patchesRow*self.number_patchesColumn)\n",
    "        #print(Size)\n",
    "        patches1=patches1A.reshape(n,self.number_patchesRow*self.number_patchesColumn,Size)\n",
    "        \n",
    "        tokens1 = self.linear_mapper(patches1)\n",
    "        tokensa = torch.cat((self.class_token.expand(n, 1, -1), tokens1), dim=1)\n",
    "\n",
    "        A    = tokensa + self.positional_embeddings1.repeat(n, 1, 1) \n",
    "\n",
    "        for block in self.blocksA:\n",
    "            A = block(A)\n",
    "        \n",
    "        output = torch.ones(n,self.Hidden_DGiven)\n",
    "        \n",
    "        output[0:n,self.Hidden_DGiven*0:self.Hidden_DGiven]  = A[:, 0]\n",
    "\n",
    "        return self.mlp(output)\n",
    "\n",
    "\n",
    "def main():\n",
    "    \n",
    "    transform = ToTensor()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = MyViT(\n",
    "        (1, 128,40), number_patchesRow=16, number_patchesColumn=5, number_blocks=2, Hidden_DGiven=5, NumberHeadsGiven=5, output_dimension=5\n",
    "    ).to(device)\n",
    "\n",
    "    NUMBER_EPOCHS = 3\n",
    "    LearningRate = 0.003\n",
    "\n",
    "    # Training Data loop\n",
    "    optimizer = Adam(model.parameters(), lr= LearningRate)\n",
    "    criterion = CrossEntropyLoss()\n",
    "\n",
    "    for epoch in trange(NUMBER_EPOCHS, desc=\"Training\"):\n",
    "        training_loss = 0.0\n",
    "        for batch in range(0,Length,Stride):\n",
    "            y = y_train[batch:batch+Stride]\n",
    "            x = X_train[batch:batch+Stride,0:1,0:128,0:40]\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            y_hat = model(x)\n",
    "            \n",
    "            loss = criterion(y_hat, y.type(torch.LongTensor))\n",
    "            print(loss)\n",
    "            training_loss += loss.detach().cpu().item()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        print(f\"Epoch {epoch + 1}/{NUMBER_EPOCHS} loss: {training_loss:.2f}\")\n",
    "\n",
    "    # Testing loop with testing data\n",
    "    with torch.no_grad():\n",
    "        correct, total = 0, 0\n",
    "        test_loss = 0.0\n",
    "        y = y_test\n",
    "        x = X_test\n",
    "\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        y_hat = model(x)\n",
    "        loss = criterion(y_hat, y.type(torch.LongTensor))\n",
    "\n",
    "        test_loss += loss.detach().cpu().item()\n",
    "\n",
    "        correct += torch.sum(torch.argmax(y_hat, dim=1) == y).detach().cpu().item()\n",
    "        total += len(x)\n",
    "        print(f\"Test loss: {test_loss:.2f}\")\n",
    "        print(f\"Test accuracy: {correct / total * 100:.2f}%\")\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1854b9a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:   0%|                                           | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.5877, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5738, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5602, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5588, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5503, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5448, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5444, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5264, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5301, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5228, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5189, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5211, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5161, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5111, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4924, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5023, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4911, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4842, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4820, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4693, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4702, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4639, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4559, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4720, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4496, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4435, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4388, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4379, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4079, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4389, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4099, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4243, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4192, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4057, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4003, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4005, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3918, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3953, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4069, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3916, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3794, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3847, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3777, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3644, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3761, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3616, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3498, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3439, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3278, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3549, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3243, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3371, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3293, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3281, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3288, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3260, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3113, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3112, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3000, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3043, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3028, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2910, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2989, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2906, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3130, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3018, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2894, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3017, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2835, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2799, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3094, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2949, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2853, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2993, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2926, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2996, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2702, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2668, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2711, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2832, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2817, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2535, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2701, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2650, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2699, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2606, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2942, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2947, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2720, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2485, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2760, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2823, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2637, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2731, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2707, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2563, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2538, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2584, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2624, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2595, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2753, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2772, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2628, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2701, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2820, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2592, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2614, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2467, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2537, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2555, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2282, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2528, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2455, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2589, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2575, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2495, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2478, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2354, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2502, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2389, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2438, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2401, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2209, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2258, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2263, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2187, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2146, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2291, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1862, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1943, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1967, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1897, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1890, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1763, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1899, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1700, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1605, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1603, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1577, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1589, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1352, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1437, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1399, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1265, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1300, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1274, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1224, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1093, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1225, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1002, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1158, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1196, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0928, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1143, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1030, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0962, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0823, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0866, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0936, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0839, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0800, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0778, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0663, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0836, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0863, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0598, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0701, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0642, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0540, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0628, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0707, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0534, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0695, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0612, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0534, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0547, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0570, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0451, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0478, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0454, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0350, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0399, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0583, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0412, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0442, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0381, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0385, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0252, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0543, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0239, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0291, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0357, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0269, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0225, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0152, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0207, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0342, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0049, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0185, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0298, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0021, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0383, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0203, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0113, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0280, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0290, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0162, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0370, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0271, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0174, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0221, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0112, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0158, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0251, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0309, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0115, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0117, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0062, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0128, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0188, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9969, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0051, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0038, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9904, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0084, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0041, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0038, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0024, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0081, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0090, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0112, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0060, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9872, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9968, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9921, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9908, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9815, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0055, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0000, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9872, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9768, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9798, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9891, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9811, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9799, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9819, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9909, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9799, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9861, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9917, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9661, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9841, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9869, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9829, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9831, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9735, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9755, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9876, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9778, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9785, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9659, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9852, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9768, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9814, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9675, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9696, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9808, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9770, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9772, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9713, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9769, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9793, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9735, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9594, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9729, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9735, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9688, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9822, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9796, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9700, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9781, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9637, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9769, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9761, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9731, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9757, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9543, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9637, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9722, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9668, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9741, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9590, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9519, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9701, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9622, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9613, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9702, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9575, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9632, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9664, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9589, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9741, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9688, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9547, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9625, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9577, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9667, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9560, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9549, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9658, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9536, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9554, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9420, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9482, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9531, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9568, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9520, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9579, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9576, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9474, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:  33%|███████████▎                      | 1/3 [15:43<31:26, 943.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 loss: 368.21\n",
      "tensor(0.9529, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9504, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9486, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9511, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9529, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9488, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9541, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9494, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9542, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9573, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9526, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9443, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9480, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9453, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9448, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9405, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9458, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9465, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9569, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9449, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9555, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9483, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9440, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9537, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9393, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9485, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9456, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9471, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9380, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9499, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9408, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9387, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9431, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9379, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9436, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9395, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9372, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9548, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9405, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9344, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9354, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9520, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9329, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9495, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9477, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9425, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9448, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9432, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9421, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9472, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9379, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9347, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9358, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9341, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9404, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9318, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9344, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9354, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9307, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9332, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9349, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9337, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9380, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9346, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9319, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9276, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9339, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9284, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9365, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9348, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9362, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9339, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9307, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9280, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9265, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9385, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9315, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9269, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9253, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9382, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9264, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9196, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9309, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9300, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9309, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9221, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9324, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9234, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9220, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9255, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9258, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9281, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9222, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9235, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9257, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9237, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9269, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9279, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9260, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9211, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9217, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9267, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9204, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9281, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9271, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9252, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9267, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9221, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9227, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9250, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9261, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9230, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9205, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9221, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9224, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9188, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9231, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9248, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9226, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9186, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9245, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9200, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9279, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9164, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9328, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9168, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9235, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9181, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9246, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9271, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9226, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9176, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9209, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9196, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9253, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9185, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9262, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9264, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9186, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9205, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9183, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9293, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9213, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9184, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9159, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9264, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9160, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9160, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9154, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9206, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9234, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9230, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9179, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9212, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9167, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9171, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9174, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9194, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9193, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9170, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9159, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9190, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9127, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9181, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9158, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9159, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9145, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9132, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9172, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9177, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9134, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9176, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9143, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9188, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9122, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9136, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9131, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9172, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9117, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9153, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9152, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9167, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9197, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9160, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9140, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9158, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9158, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9138, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9125, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9115, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9140, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9143, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9138, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9183, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9085, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9134, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9138, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9155, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9164, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9144, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9108, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9176, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9209, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9105, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9147, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9135, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9128, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9150, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9179, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9150, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9177, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9150, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9118, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9171, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9155, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9143, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9168, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9139, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9099, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9109, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9157, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9138, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9150, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9135, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9153, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9150, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9109, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9137, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9128, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9152, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9143, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9171, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9181, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9114, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9146, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9130, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9166, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9167, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9141, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9136, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9136, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9117, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9210, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9184, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9150, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9112, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9150, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9138, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9113, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9126, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9104, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9137, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9109, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9116, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9106, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9119, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9160, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9132, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9160, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9084, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9107, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9144, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9128, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9141, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9148, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9102, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9112, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9146, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9119, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9117, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9149, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9123, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9159, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9107, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9124, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9162, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9124, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9130, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9121, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9126, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9133, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9095, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9098, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9126, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9094, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9155, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9108, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9153, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9135, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9145, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9133, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9132, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9144, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9124, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9102, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9100, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9145, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9114, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9113, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9136, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9089, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9106, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9133, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9093, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9096, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9101, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9120, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9131, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9125, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9089, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9131, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9117, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9148, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9123, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9094, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9115, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9097, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9141, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9107, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9086, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:  67%|██████████████████████           | 2/3 [33:42<17:03, 1023.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 loss: 295.31\n",
      "tensor(0.9077, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9101, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9114, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9102, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9071, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9087, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9119, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9135, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9121, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9158, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9155, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9086, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9161, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9107, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9107, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9085, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9136, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9123, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9114, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9096, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9105, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9075, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9092, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9094, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9088, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9093, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9098, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9113, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9094, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9102, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9113, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9088, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9101, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9128, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9128, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9114, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9109, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9125, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9078, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9126, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9118, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9109, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9074, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9151, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9162, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9073, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9115, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9122, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9158, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9119, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9081, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9115, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9107, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9100, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9135, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9116, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9181, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9101, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9100, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9074, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9140, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9110, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9127, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9114, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9084, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9097, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9111, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9104, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9089, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9110, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9145, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9107, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9098, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9090, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9091, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9139, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9116, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9086, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9084, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9097, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9086, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9095, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9115, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9120, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9104, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9091, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9098, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9077, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9122, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9069, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9109, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9091, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9117, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9115, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9080, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9091, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9149, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9108, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9137, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9087, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9109, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9072, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9087, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9124, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9088, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9117, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9139, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9084, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9091, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9129, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9077, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9085, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9102, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9128, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9150, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9113, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9102, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9126, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9102, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9097, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9083, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9107, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9091, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9094, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9094, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9082, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9121, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9126, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9116, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9082, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9118, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9119, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9109, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9100, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9117, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9081, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9087, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9103, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9097, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9072, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9070, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9097, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9121, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9084, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9090, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9106, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9078, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9064, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9080, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9087, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9086, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9153, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9089, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9119, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9111, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9119, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9112, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9100, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9091, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9100, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9120, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9117, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9058, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9127, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9133, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9094, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9070, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9091, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9108, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9108, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9078, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9106, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9113, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9143, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9085, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9063, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9092, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9066, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9073, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9113, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9128, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9097, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9126, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9104, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9130, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9097, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9096, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9121, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9066, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9110, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9071, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9095, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9072, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9085, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9062, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9079, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9101, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9120, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9120, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9106, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9099, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9119, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9098, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9081, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9105, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9088, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9075, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9068, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9085, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9078, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9088, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9092, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9065, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9105, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9110, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9072, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9114, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9108, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9086, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9097, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9158, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9081, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9099, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9072, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9114, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9098, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9072, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9088, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9069, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9115, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9107, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9094, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9098, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9068, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9099, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9085, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9079, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9099, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9082, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9053, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9088, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9091, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9144, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9083, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9097, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9090, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9068, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9086, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9076, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9090, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9103, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9082, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9079, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9076, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9083, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9072, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9127, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9094, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9082, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9055, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9082, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9076, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9100, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9097, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9098, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9057, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9087, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9074, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9082, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9096, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9115, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9098, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9089, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9061, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9069, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9122, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9073, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9087, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9095, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9087, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9100, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9074, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9072, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9081, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9060, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9100, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9079, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9099, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9090, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9087, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9110, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9067, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9081, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9089, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9090, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9075, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9100, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9084, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9109, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9093, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9060, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9084, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9080, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9090, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9096, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9078, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9081, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9097, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9102, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9068, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9117, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9084, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9090, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9113, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9064, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9101, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9073, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9100, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9083, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9099, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|█████████████████████████████████| 3/3 [51:55<00:00, 1038.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 loss: 291.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.91\n",
      "Test accuracy: 99.71%\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "class MyViT(nn.Module):\n",
    "    def __init__(self, Dimensions, number_patchesRow,number_patchesColumn, number_blocks, Hidden_DGiven, NumberHeadsGiven, output_dimension):\n",
    "        \n",
    "        super(MyViT, self).__init__()\n",
    "        self.Dimensions = Dimensions  \n",
    "        self.number_patchesRow = number_patchesRow\n",
    "        self.number_patchesColumn=number_patchesColumn\n",
    "        self.number_blocks = number_blocks\n",
    "        self.Hidden_DGiven= Hidden_DGiven\n",
    "        self.NumberHeadsGiven = NumberHeadsGiven\n",
    "        \n",
    "        self.patch_size = (math.floor(Dimensions[1] / number_patchesRow), math.floor(Dimensions[2] / number_patchesColumn))\n",
    "        \n",
    "        self.input_d = int(Dimensions[0] * self.patch_size[0] * self.patch_size[1])\n",
    "        self.linear_mapper = nn.Linear(self.input_d, self.Hidden_DGiven)\n",
    "\n",
    "        self.class_token = nn.Parameter(torch.rand(1, self.Hidden_DGiven))\n",
    "\n",
    "        self.register_buffer(\n",
    "            \"positional_embeddings1\",\n",
    "            get_positional_embeddings5(number_patchesRow*number_patchesColumn + 1, Hidden_DGiven),\n",
    "            persistent=False,\n",
    "        )\n",
    "        \n",
    "        self.blocksA = nn.ModuleList(\n",
    "            [VisionTransformer(Hidden_DGiven, NumberHeadsGiven) for _ in range(number_blocks)]\n",
    "        )\n",
    "\n",
    "        self.mlp = nn.Sequential(nn.Linear(self.Hidden_DGiven, output_dimension), nn.Softmax(dim=-1))\n",
    "\n",
    "    def forward(self, images):        \n",
    "        n, c, h, w = images.shape\n",
    "        patches1A = images[0:n,0,0:self.patch_size[0]*self.number_patchesRow,0:self.patch_size[1]*self.number_patchesColumn]#patchify(images, self.n_patches).to(self.positional_embeddings1.device)\n",
    "        Size=64#(patches1A.size(1)*patches1A.size(2))/(self.number_patchesRow*self.number_patchesColumn)\n",
    "        #print(Size)\n",
    "        patches1=patches1A.reshape(n,self.number_patchesRow*self.number_patchesColumn,Size)\n",
    "        \n",
    "        tokens1 = self.linear_mapper(patches1)\n",
    "        tokensa = torch.cat((self.class_token.expand(n, 1, -1), tokens1), dim=1)\n",
    "\n",
    "        A    = tokensa + self.positional_embeddings1.repeat(n, 1, 1) \n",
    "\n",
    "        for block in self.blocksA:\n",
    "            A = block(A)\n",
    "        \n",
    "        output = torch.ones(n,self.Hidden_DGiven)\n",
    "        \n",
    "        output[0:n,self.Hidden_DGiven*0:self.Hidden_DGiven]  = A[:, 0]\n",
    "\n",
    "        return self.mlp(output)\n",
    "\n",
    "\n",
    "def main():\n",
    "    \n",
    "    transform = ToTensor()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = MyViT(\n",
    "        (1, 128,40), number_patchesRow=16, number_patchesColumn=5, number_blocks=2, Hidden_DGiven=5, NumberHeadsGiven=5, output_dimension=5\n",
    "    ).to(device)\n",
    "\n",
    "    NUMBER_EPOCHS = 3\n",
    "    LearningRate = 0.003\n",
    "\n",
    "    # Training Data loop\n",
    "    optimizer = Adam(model.parameters(), lr= LearningRate)\n",
    "    criterion = CrossEntropyLoss()\n",
    "\n",
    "    for epoch in trange(NUMBER_EPOCHS, desc=\"Training\"):\n",
    "        training_loss = 0.0\n",
    "        for batch in range(0,Length,Stride):\n",
    "            y = y_train[batch:batch+Stride]\n",
    "            x = X_train[batch:batch+Stride,0:1,0:128,0:40]\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            y_hat = model(x)\n",
    "            \n",
    "            loss = criterion(y_hat, y.type(torch.LongTensor))\n",
    "            print(loss)\n",
    "            training_loss += loss.detach().cpu().item()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        print(f\"Epoch {epoch + 1}/{NUMBER_EPOCHS} loss: {training_loss:.2f}\")\n",
    "\n",
    "    # Testing loop with testing data\n",
    "    with torch.no_grad():\n",
    "        correct, total = 0, 0\n",
    "        test_loss = 0.0\n",
    "        y = y_test\n",
    "        x = X_test\n",
    "\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        y_hat = model(x)\n",
    "        loss = criterion(y_hat, y.type(torch.LongTensor))\n",
    "\n",
    "        test_loss += loss.detach().cpu().item()\n",
    "\n",
    "        correct += torch.sum(torch.argmax(y_hat, dim=1) == y).detach().cpu().item()\n",
    "        total += len(x)\n",
    "        print(f\"Test loss: {test_loss:.2f}\")\n",
    "        print(f\"Test accuracy: {correct / total * 100:.2f}%\")\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "103475b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_positional_embeddings1(seq_len, d):\n",
    "    resultingOutput = torch.ones(seq_len, d)\n",
    "    LearnableParameter1 = nn.LeakyReLU(0.2)\n",
    "    for i in range(seq_len):\n",
    "        for j in range(d):\n",
    "            resultingOutput[i][j] = LearnableParameter1(torch.tensor(np.sin(i / (10000 ** (2*j / d))) if j % 2 == 0 else np.cos(i / (10000 ** (2*(j - 1) / d)))))\n",
    "    return resultingOutput\n",
    "\n",
    "def get_positional_embeddings2(seq_len, d):\n",
    "    resultingOutput = torch.ones(seq_len, d)\n",
    "    LearnableParameter2 = nn.LeakyReLU(0.2)\n",
    "    for i in range(seq_len):\n",
    "        for j in range(d):\n",
    "            resultingOutput[i][j] = LearnableParameter2(torch.tensor(np.sin(i / (10000 ** (0.4*j / d))) if j % 2 == 0 else np.cos(i / (10000 ** (0.4*(j - 1) / d)))))\n",
    "    return resultingOutput\n",
    "\n",
    "def get_positional_embeddings3(seq_len, d):\n",
    "    resultingOutput = torch.ones(seq_len, d)\n",
    "    LearnableParameter3 = nn.LeakyReLU(0.2)\n",
    "    for i in range(seq_len):\n",
    "        for j in range(d):\n",
    "            resultingOutput[i][j] = LearnableParameter3(torch.tensor(np.sin(i / (10000 ** (1*j / d))) if j % 2 == 0 else np.cos(i / (10000 ** (1*(j - 1) / d)))))\n",
    "    return resultingOutput\n",
    "\n",
    "import math\n",
    "def get_positional_embeddings4(seq_len, d):\n",
    "    resultingOutput = torch.ones(seq_len, d)\n",
    "    LearnableParameter4 = nn.LeakyReLU(0.2)\n",
    "    for i in range(seq_len):\n",
    "        for j in range(d):\n",
    "            resultingOutput[i][j] = LearnableParameter4(torch.tensor(np.sin(i / (10000 ** (3*math.sqrt(j) / (d)))) if j % 2 == 0 else np.cos(i / (10000 ** (3*math.sqrt(j - 1) / (d))))))\n",
    "    return resultingOutput\n",
    "\n",
    "import math\n",
    "def get_positional_embeddings5(seq_len, d):\n",
    "    resultingOutput = torch.ones(seq_len, d)\n",
    "    LearnableParameter5 = nn.LeakyReLU(0.2)\n",
    "    for i in range(seq_len):\n",
    "        for j in range(d):\n",
    "            resultingOutput[i][j] = LearnableParameter5(torch.tensor(np.sin(i / (10000 ** (math.sqrt(j) / (d)))) if j % 2 == 0 else np.cos(i / (10000 ** (math.sqrt(j - 1) / (d))))))\n",
    "    return resultingOutput\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "537a9358",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:   0%|                                           | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.6156, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6162, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6076, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6103, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6064, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6048, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6082, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6048, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5992, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6008, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5984, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5996, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5965, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5932, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5940, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5909, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5874, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5836, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5818, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5781, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5748, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5704, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5642, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5625, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5524, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5478, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5399, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5327, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5108, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5247, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4999, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5050, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4972, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4826, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4740, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4691, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4667, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4664, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4710, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4605, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4505, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4598, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4512, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4474, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4571, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4474, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4429, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4323, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4233, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4537, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4221, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4386, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4423, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4431, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4409, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4429, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4332, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4322, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4263, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4315, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4284, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4259, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4221, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4233, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4363, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4275, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4207, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4178, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4092, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4081, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4258, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4172, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4085, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4137, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4098, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4000, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3756, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3684, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3702, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3731, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3690, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3400, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3445, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3441, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3411, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3263, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3608, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3555, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3219, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2994, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3296, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3304, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3020, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3073, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3130, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2908, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2859, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2984, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2981, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2917, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3014, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3010, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2934, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2962, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3117, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2854, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2808, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2630, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2724, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2842, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2467, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2763, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2651, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2813, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2760, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2711, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2714, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2579, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2778, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2679, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2770, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2749, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2579, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2646, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2763, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2563, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2723, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2912, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2487, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2597, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2571, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2616, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2542, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2557, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2754, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2659, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2459, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2426, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2582, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2651, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2578, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2600, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2636, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2421, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2549, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2513, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2424, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2480, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2670, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2442, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2465, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2651, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2238, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2529, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2389, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2489, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2409, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2443, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2438, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2375, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2496, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2367, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2448, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2499, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2497, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2237, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2463, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2419, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2194, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2282, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2428, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2327, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2381, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2387, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2512, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2334, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2400, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2397, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2285, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2283, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2203, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2283, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2375, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2391, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2288, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2224, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2334, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2349, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2389, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2077, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2350, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.2414, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2292, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2189, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2158, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2169, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2168, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2013, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2356, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2240, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2198, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2269, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2276, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2211, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2204, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2157, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2299, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2378, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2349, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2312, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2261, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2376, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2238, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2403, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2358, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2409, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2201, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2106, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2171, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2184, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2153, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2177, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2254, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2446, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2422, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2310, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2158, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2195, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2325, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2368, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2278, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2381, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2199, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2337, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2363, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2234, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1994, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2252, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2439, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2329, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2239, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2136, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2083, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2084, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2136, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2228, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2281, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2200, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2281, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2098, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2206, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2130, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2257, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1992, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2136, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2121, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2034, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2209, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2054, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2023, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2353, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2171, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2088, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2224, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1839, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2000, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2032, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2002, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2074, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1927, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2023, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2154, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2069, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1904, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2059, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1993, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1939, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2113, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1977, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1899, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2099, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1939, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1874, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1912, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1959, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1950, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1824, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1863, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1825, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1588, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1917, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1810, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1559, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1710, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1726, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1714, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1495, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1522, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1582, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1536, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1427, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1612, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1381, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1455, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1562, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1571, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1297, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1337, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1334, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1166, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1259, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1389, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1283, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1211, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1207, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1502, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1023, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1154, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1145, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1234, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:  33%|███████████▎                      | 1/3 [16:20<32:40, 980.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 loss: 414.48\n",
      "tensor(1.1148, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0879, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0984, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1298, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1166, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1156, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1201, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1083, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0984, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1138, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1263, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0959, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1064, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1213, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1245, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0925, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1012, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0920, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1151, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1218, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1042, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0773, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0971, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1095, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1088, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0829, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0937, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0903, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0792, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0789, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0800, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1046, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1014, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0928, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0732, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0789, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0508, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0952, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0961, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0772, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0680, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0748, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0831, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1122, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0938, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0761, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0732, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0755, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0830, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0646, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0615, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0574, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0882, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0900, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0842, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0797, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0744, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0469, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0625, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0628, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0894, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0652, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0663, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0613, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0670, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0443, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0720, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0699, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0729, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0546, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0636, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0725, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0493, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0570, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0857, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0720, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0634, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0696, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0373, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0633, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0598, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0419, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0651, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0518, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0510, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0320, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0798, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0743, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0629, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0587, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0402, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0645, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0702, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0578, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0651, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0527, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0569, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0558, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0646, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0408, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0710, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0488, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0447, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0750, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0810, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0543, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0585, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0391, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0504, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0439, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0447, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0558, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0538, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0472, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0386, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0592, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0450, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0565, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0631, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0687, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0579, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0636, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0596, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0499, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0753, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0397, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0557, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0744, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0486, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0557, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0458, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0311, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0527, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0545, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0506, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0376, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0461, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0516, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0550, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0588, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0493, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0477, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0590, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0532, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0678, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0476, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0508, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0449, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0768, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0592, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0498, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0791, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0348, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0619, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0462, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0636, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0490, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0553, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0454, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0421, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0514, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0418, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0502, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0524, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0637, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0505, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0542, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0503, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0484, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0499, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0597, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0587, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0684, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0515, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0454, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0465, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0461, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0647, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0360, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0442, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0308, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0427, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0380, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0494, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0587, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0220, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0334, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0185, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0411, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0337, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0371, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0297, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0331, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0234, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0383, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0333, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0285, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0214, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0242, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0264, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0200, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0363, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0359, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0350, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0442, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0461, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0320, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0339, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0301, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0349, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0518, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0215, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0292, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0434, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0470, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0404, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0389, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0221, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0291, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0243, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0127, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0193, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0256, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0125, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0287, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0265, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0296, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0141, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0330, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0423, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0244, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0322, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0191, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0351, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0310, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0255, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0080, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0135, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0294, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0233, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0289, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0288, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0198, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0060, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0229, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0213, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0253, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0254, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0286, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0191, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0216, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0112, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0160, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0079, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0178, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0074, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9999, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0174, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0043, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0120, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0157, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0072, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0056, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0068, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9837, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9967, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0074, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9932, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9968, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0091, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9994, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0161, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0085, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9933, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0062, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9979, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9829, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9962, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0063, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9890, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9846, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9777, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9919, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0068, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9825, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9956, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9851, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9986, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9900, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9785, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9814, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9861, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9774, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9797, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9793, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9953, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9897, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9757, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9804, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9860, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9661, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9780, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9718, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9768, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9806, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9759, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9771, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9729, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9741, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9799, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9862, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9758, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9694, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9599, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9696, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9715, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9593, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9682, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9634, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9704, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:  67%|██████████████████████▋           | 2/3 [31:58<15:55, 955.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 loss: 333.58\n",
      "tensor(0.9661, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9646, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9657, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9741, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9645, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9625, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9591, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9640, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9560, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9593, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9606, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9487, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9603, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9625, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9690, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9606, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9522, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9522, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9609, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9496, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9603, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9480, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9576, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9553, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9595, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9548, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9548, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9552, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9559, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9528, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9526, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9495, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9430, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9468, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9381, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9537, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9468, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9522, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9533, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9442, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9502, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9497, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9368, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9616, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9425, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9498, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9614, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9473, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9439, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9459, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9457, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9488, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9474, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9481, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9475, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9528, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9404, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9415, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9393, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9380, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9501, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9439, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9434, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9481, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9412, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9384, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9502, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9400, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9452, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9405, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9522, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9528, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9446, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9511, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9596, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9522, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9465, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9503, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9400, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9458, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9391, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9473, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9402, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9397, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9534, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9330, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9494, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9389, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9394, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9423, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9396, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9560, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9507, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9408, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9409, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9324, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9376, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9510, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9430, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9376, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9454, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9439, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9474, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9436, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9383, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9422, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9476, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9417, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9286, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9438, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9489, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9408, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9331, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9413, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9402, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9406, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9373, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9313, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9364, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9452, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9381, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9392, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9367, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9421, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9343, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9342, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9464, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9325, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9414, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9376, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9352, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9331, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9433, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9340, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9438, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9360, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9422, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9394, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9382, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9295, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9395, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9422, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9412, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9427, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9399, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9406, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9279, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9358, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9289, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9319, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9377, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9443, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9283, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9386, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9352, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9364, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9337, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9267, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9378, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9314, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9387, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9348, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9263, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9399, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9413, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9376, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9394, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9301, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9450, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9385, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9341, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9385, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9524, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9521, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9398, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9367, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9397, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9415, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9414, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9456, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9395, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9465, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9451, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9315, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9367, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9364, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9395, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9474, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9377, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9451, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9371, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9439, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9322, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9331, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9346, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9319, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9294, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9268, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9288, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9332, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9301, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9326, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9346, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9318, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9395, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9323, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9313, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9358, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9366, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9394, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9323, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9273, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9343, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9334, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9418, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9259, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9328, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9372, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9375, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9354, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9354, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9347, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9314, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9232, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9224, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9286, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9223, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9385, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9365, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9289, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9387, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9283, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9336, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9370, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9221, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9213, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9232, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9252, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9304, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9323, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9299, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9330, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9437, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9285, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9384, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9267, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9397, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9275, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9304, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9272, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9265, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9333, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9310, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9310, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9350, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9302, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9290, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9318, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9307, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9331, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9278, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9256, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9276, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9311, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9332, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9359, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9297, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9342, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9280, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9376, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9360, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9253, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9285, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9211, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9346, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9340, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9308, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9248, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9319, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9227, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9219, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9250, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9240, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9384, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9253, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9266, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9261, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9296, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9294, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9244, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9233, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9262, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9212, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9207, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9255, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9252, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9317, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9224, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9279, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9284, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9273, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9263, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9260, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9322, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9230, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9293, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9285, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9259, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9222, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9259, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9306, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9314, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9310, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9269, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9251, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9262, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9235, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9309, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9210, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9250, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████| 3/3 [47:38<00:00, 952.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 loss: 300.37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.93\n",
      "Test accuracy: 97.81%\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "class MyViT(nn.Module):\n",
    "    def __init__(self, Dimensions, number_patchesRow,number_patchesColumn, number_blocks, Hidden_DGiven, NumberHeadsGiven, output_dimension):\n",
    "        \n",
    "        super(MyViT, self).__init__()\n",
    "        self.Dimensions = Dimensions  \n",
    "        self.number_patchesRow = number_patchesRow\n",
    "        self.number_patchesColumn=number_patchesColumn\n",
    "        self.number_blocks = number_blocks\n",
    "        self.Hidden_DGiven= Hidden_DGiven\n",
    "        self.NumberHeadsGiven = NumberHeadsGiven\n",
    "        \n",
    "        self.patch_size = (math.floor(Dimensions[1] / number_patchesRow), math.floor(Dimensions[2] / number_patchesColumn))\n",
    "        \n",
    "        self.input_d = int(Dimensions[0] * self.patch_size[0] * self.patch_size[1])\n",
    "        self.linear_mapper = nn.Linear(self.input_d, self.Hidden_DGiven)\n",
    "\n",
    "        self.class_token = nn.Parameter(torch.rand(1, self.Hidden_DGiven))\n",
    "\n",
    "        self.register_buffer(\n",
    "            \"positional_embeddings1\",\n",
    "            get_positional_embeddings1(number_patchesRow*number_patchesColumn + 1, Hidden_DGiven),\n",
    "            persistent=False,\n",
    "        )\n",
    "        \n",
    "        self.blocksA = nn.ModuleList(\n",
    "            [VisionTransformer(Hidden_DGiven, NumberHeadsGiven) for _ in range(number_blocks)]\n",
    "        )\n",
    "\n",
    "        self.mlp = nn.Sequential(nn.Linear(self.Hidden_DGiven, output_dimension), nn.Softmax(dim=-1))\n",
    "\n",
    "    def forward(self, images):        \n",
    "        n, c, h, w = images.shape\n",
    "        patches1A = images[0:n,0,0:self.patch_size[0]*self.number_patchesRow,0:self.patch_size[1]*self.number_patchesColumn]#patchify(images, self.n_patches).to(self.positional_embeddings1.device)\n",
    "        Size=64#(patches1A.size(1)*patches1A.size(2))/(self.number_patchesRow*self.number_patchesColumn)\n",
    "        #print(Size)\n",
    "        patches1=patches1A.reshape(n,self.number_patchesRow*self.number_patchesColumn,Size)\n",
    "        \n",
    "        tokens1 = self.linear_mapper(patches1)\n",
    "        tokensa = torch.cat((self.class_token.expand(n, 1, -1), tokens1), dim=1)\n",
    "\n",
    "        A    = tokensa + self.positional_embeddings1.repeat(n, 1, 1) \n",
    "\n",
    "        for block in self.blocksA:\n",
    "            A = block(A)\n",
    "        \n",
    "        output = torch.ones(n,self.Hidden_DGiven)\n",
    "        \n",
    "        output[0:n,self.Hidden_DGiven*0:self.Hidden_DGiven]  = A[:, 0]\n",
    "\n",
    "        return self.mlp(output)\n",
    "\n",
    "\n",
    "def main():\n",
    "    \n",
    "    transform = ToTensor()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = MyViT(\n",
    "        (1, 128,40), number_patchesRow=16, number_patchesColumn=5, number_blocks=2, Hidden_DGiven=5, NumberHeadsGiven=5, output_dimension=5\n",
    "    ).to(device)\n",
    "\n",
    "    NUMBER_EPOCHS = 3\n",
    "    LearningRate = 0.003\n",
    "\n",
    "    # Training Data loop\n",
    "    optimizer = Adam(model.parameters(), lr= LearningRate)\n",
    "    criterion = CrossEntropyLoss()\n",
    "\n",
    "    for epoch in trange(NUMBER_EPOCHS, desc=\"Training\"):\n",
    "        training_loss = 0.0\n",
    "        for batch in range(0,Length,Stride):\n",
    "            y = y_train[batch:batch+Stride]\n",
    "            x = X_train[batch:batch+Stride,0:1,0:128,0:40]\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            y_hat = model(x)\n",
    "            \n",
    "            loss = criterion(y_hat, y.type(torch.LongTensor))\n",
    "            print(loss)\n",
    "            training_loss += loss.detach().cpu().item()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        print(f\"Epoch {epoch + 1}/{NUMBER_EPOCHS} loss: {training_loss:.2f}\")\n",
    "\n",
    "    # Testing loop with testing data\n",
    "    with torch.no_grad():\n",
    "        correct, total = 0, 0\n",
    "        test_loss = 0.0\n",
    "        y = y_test\n",
    "        x = X_test\n",
    "\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        y_hat = model(x)\n",
    "        loss = criterion(y_hat, y.type(torch.LongTensor))\n",
    "\n",
    "        test_loss += loss.detach().cpu().item()\n",
    "\n",
    "        correct += torch.sum(torch.argmax(y_hat, dim=1) == y).detach().cpu().item()\n",
    "        total += len(x)\n",
    "        print(f\"Test loss: {test_loss:.2f}\")\n",
    "        print(f\"Test accuracy: {correct / total * 100:.2f}%\")\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "378b31fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:   0%|                                           | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.5987, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5962, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5918, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5823, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5816, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5768, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5729, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5629, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5596, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5533, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5402, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5408, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5325, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5270, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5103, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5156, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4997, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4943, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4933, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4822, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4860, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4748, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4688, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4775, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4611, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4604, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4559, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4566, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4273, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4614, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4343, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4508, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4494, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4407, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4374, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4377, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4390, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4432, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4491, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4383, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4319, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4413, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4343, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4379, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4464, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4376, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4323, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4195, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4094, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4335, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4032, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4182, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4203, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4162, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4105, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4095, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3943, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3888, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3766, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3775, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3704, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3604, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3530, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3471, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3613, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3480, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3339, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3363, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3173, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3126, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3368, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3185, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3158, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3228, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3139, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3239, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2934, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2873, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2928, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3029, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3025, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2717, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2846, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2857, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2853, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2738, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3125, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3091, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2904, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2736, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3010, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3008, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2727, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2855, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2912, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2791, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2661, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2747, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2771, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2740, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3054, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3019, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2793, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2845, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3041, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2880, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2897, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2745, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2842, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2706, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2623, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2781, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2678, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2958, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2767, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2846, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2762, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2603, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2708, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2835, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2864, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2910, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2671, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2706, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2830, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2706, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2801, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2958, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2571, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2721, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2652, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2739, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2605, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2694, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2894, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2773, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2604, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2563, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2623, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2844, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2813, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2827, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2800, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2586, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2692, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2689, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2639, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2640, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2896, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2707, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2688, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2910, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2595, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2910, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2764, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2706, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2585, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2743, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2728, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2643, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2762, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2706, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2684, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2644, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2739, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2515, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2750, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2555, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2503, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2567, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2592, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2567, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2667, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2571, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2603, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2689, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2744, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2755, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2673, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2615, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2491, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2603, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2658, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2531, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2594, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2566, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2643, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2548, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2764, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2471, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2630, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.2699, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2653, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2601, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2569, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2507, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2523, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2420, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2628, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2514, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2596, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2539, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2696, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2499, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2513, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2585, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2597, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2648, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2590, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2552, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2547, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2481, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2511, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2650, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2529, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2470, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2368, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2258, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2385, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2393, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2252, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2204, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2211, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2290, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2258, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2164, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1852, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1920, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1856, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1912, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1721, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1653, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1472, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1651, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1380, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1348, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1351, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1310, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1428, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1436, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1277, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1188, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1041, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1023, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1178, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1077, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1088, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0973, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1036, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0908, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0849, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0979, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1030, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0951, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0948, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0828, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0709, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0980, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0888, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0877, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0809, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0731, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0787, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0836, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0576, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0720, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0778, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0554, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0718, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0663, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0808, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0652, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0618, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0388, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0486, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0411, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0479, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0628, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0470, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0424, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0500, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0467, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0474, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0426, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0387, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0354, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0396, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0439, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0361, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0213, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0344, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0244, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0178, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0275, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0300, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0259, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0217, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0146, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0239, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0134, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9958, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0137, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0126, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0022, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0192, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0115, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0098, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9970, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9993, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9915, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9922, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9940, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9975, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9836, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9839, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9960, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9868, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9882, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9848, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9892, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:  33%|███████████▎                      | 1/3 [15:43<31:27, 943.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 loss: 400.01\n",
      "tensor(0.9854, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9798, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9793, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9832, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9780, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9754, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9772, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9725, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9676, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9660, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9860, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9795, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9775, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9706, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9699, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9700, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9733, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9670, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9685, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9657, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9721, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9662, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9640, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9639, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9585, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9596, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9595, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9605, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9489, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9582, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9483, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9628, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9573, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9589, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9531, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9624, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9488, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9585, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9534, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9427, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9521, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9439, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9513, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9615, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9548, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9587, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9528, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9434, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9422, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9444, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9475, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9452, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9382, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9409, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9465, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9362, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9570, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9454, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9389, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9456, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9498, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9544, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9502, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9452, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9385, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9354, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9435, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9341, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9441, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9347, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9429, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9488, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9423, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9435, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9419, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9502, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9437, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9524, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9335, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9326, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9270, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9419, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9409, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9352, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9356, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9302, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9395, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9356, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9351, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9376, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9337, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9475, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9323, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9365, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9417, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9324, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9331, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9368, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9367, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9387, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9353, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9390, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9330, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9447, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9325, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9409, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9373, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9287, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9316, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9401, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9396, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9291, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9344, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9325, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9382, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9283, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9404, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9274, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9296, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9301, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9345, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9288, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9422, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9280, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9281, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9302, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9417, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9362, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9342, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9329, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9363, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9282, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9343, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9279, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9346, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9283, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9331, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9265, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9300, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9250, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9223, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9357, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9304, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9328, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9318, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9297, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9280, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9282, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9293, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9311, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9356, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9341, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9256, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9294, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9260, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9299, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9290, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9291, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9293, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9297, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9335, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9254, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9263, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9230, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9290, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9235, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9249, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9226, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9328, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9334, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9307, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9231, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9272, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9290, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9313, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9274, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9367, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9301, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9315, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9292, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9275, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9293, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9270, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9232, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9254, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9247, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9293, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9254, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9271, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9297, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9211, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9263, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9259, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9277, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9277, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9261, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9303, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9237, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9332, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9348, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9360, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9243, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9231, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9207, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9221, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9243, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9263, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9267, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9236, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9237, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9274, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9224, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9177, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9288, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9229, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9209, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9227, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9177, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9200, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9234, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9265, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9206, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9279, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9251, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9218, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9223, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9225, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9267, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9300, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9284, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9229, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9277, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9242, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9245, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9186, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9200, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9220, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9217, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9209, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9261, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9163, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9232, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9245, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9183, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9269, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9222, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9213, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9217, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9211, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9222, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9251, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9253, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9187, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9215, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9231, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9223, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9225, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9232, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9279, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9200, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9245, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9238, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9201, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9212, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9242, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9260, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9171, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9190, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9215, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9238, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9253, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9230, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9243, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9136, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9224, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9206, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9217, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9195, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9238, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9160, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9229, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9200, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9140, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9249, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9168, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9226, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9210, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9232, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9253, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9200, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9257, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9177, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9242, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9175, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9198, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9186, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9278, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9170, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9187, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9198, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9176, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9193, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9238, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9296, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9258, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9170, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9289, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9243, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9216, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9206, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9226, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9208, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9202, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9177, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9167, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9220, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9211, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9256, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9171, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9272, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:  67%|██████████████████████▋           | 2/3 [31:30<15:45, 945.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 loss: 298.92\n",
      "tensor(0.9208, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9187, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9337, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9199, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9156, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9236, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9298, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9283, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9254, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9201, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9190, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9160, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9237, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9248, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9191, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9188, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9219, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9179, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9262, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9176, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9248, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9221, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9236, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9197, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9225, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9211, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9175, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9190, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9175, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9186, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9165, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9220, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9155, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9195, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9194, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9254, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9188, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9204, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9166, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9196, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9207, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9191, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9208, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9245, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9151, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9264, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9241, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9158, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9217, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9191, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9163, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9220, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9133, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9206, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9175, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9211, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9221, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9260, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9192, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9204, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9248, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9239, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9253, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9230, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9175, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9228, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9216, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9121, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9164, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9149, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9173, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9224, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9154, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9182, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9196, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9240, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9214, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9253, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9197, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9194, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9176, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9179, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9193, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9193, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9222, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9137, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9231, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9168, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9196, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9183, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9176, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9252, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9195, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9221, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9229, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9136, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9203, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9207, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9222, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9284, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9174, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9197, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9157, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9285, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9275, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9237, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9201, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9175, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9173, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9242, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9179, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9172, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9196, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9167, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9246, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9171, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9283, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9196, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9143, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9239, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9171, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9189, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9203, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9231, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9158, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9171, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9242, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9281, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9269, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9210, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9204, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9166, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9243, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9168, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9199, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9227, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9212, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9176, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9191, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9172, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9153, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9223, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9205, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9217, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9256, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9223, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9192, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9171, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9226, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9245, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9258, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9232, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9176, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9163, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9220, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9234, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9197, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9183, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9194, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9244, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9210, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9172, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9223, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9204, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9182, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9111, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9148, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9137, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9240, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9212, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9203, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9154, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9235, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9161, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9208, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9170, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9200, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9164, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9162, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9175, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9189, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9188, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9158, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9163, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9199, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9153, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9171, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9194, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9183, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9201, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9097, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9140, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9174, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9166, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9191, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9197, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9203, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9169, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9237, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9250, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9233, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9239, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9189, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9158, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9179, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9225, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9225, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9188, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9174, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9165, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9254, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9213, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9181, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9250, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9168, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9164, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9196, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9185, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9135, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9187, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9248, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9144, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9186, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9164, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9197, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9190, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9166, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9251, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9210, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9217, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9181, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9198, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9197, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9215, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9177, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9217, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9175, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9166, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9159, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9258, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9157, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9247, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9257, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9172, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9189, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9245, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9181, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9175, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9182, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9183, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9198, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9259, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9134, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9192, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9164, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9187, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9204, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9193, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9208, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9168, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9198, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9224, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9171, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9127, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9181, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9220, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9139, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9125, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9199, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9224, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9222, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9192, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9191, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9084, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9186, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9180, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9154, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9143, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9199, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9130, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9171, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9178, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9100, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9185, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9163, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9207, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9173, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9174, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9214, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9125, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9220, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9199, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9203, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9173, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9138, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9158, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9273, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9203, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9180, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9166, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9134, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9181, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9223, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9267, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9193, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9141, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9289, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9205, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9171, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9181, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9179, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9203, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9179, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9172, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9122, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9173, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9181, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9173, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9144, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9188, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████| 3/3 [48:07<00:00, 962.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 loss: 294.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.92\n",
      "Test accuracy: 98.66%\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "class MyViT(nn.Module):\n",
    "    def __init__(self, Dimensions, number_patchesRow,number_patchesColumn, number_blocks, Hidden_DGiven, NumberHeadsGiven, output_dimension):\n",
    "        \n",
    "        super(MyViT, self).__init__()\n",
    "        self.Dimensions = Dimensions  \n",
    "        self.number_patchesRow = number_patchesRow\n",
    "        self.number_patchesColumn=number_patchesColumn\n",
    "        self.number_blocks = number_blocks\n",
    "        self.Hidden_DGiven= Hidden_DGiven\n",
    "        self.NumberHeadsGiven = NumberHeadsGiven\n",
    "        \n",
    "        self.patch_size = (math.floor(Dimensions[1] / number_patchesRow), math.floor(Dimensions[2] / number_patchesColumn))\n",
    "        \n",
    "        self.input_d = int(Dimensions[0] * self.patch_size[0] * self.patch_size[1])\n",
    "        self.linear_mapper = nn.Linear(self.input_d, self.Hidden_DGiven)\n",
    "\n",
    "        self.class_token = nn.Parameter(torch.rand(1, self.Hidden_DGiven))\n",
    "\n",
    "        self.register_buffer(\n",
    "            \"positional_embeddings1\",\n",
    "            get_positional_embeddings2(number_patchesRow*number_patchesColumn + 1, Hidden_DGiven),\n",
    "            persistent=False,\n",
    "        )\n",
    "        \n",
    "        self.blocksA = nn.ModuleList(\n",
    "            [VisionTransformer(Hidden_DGiven, NumberHeadsGiven) for _ in range(number_blocks)]\n",
    "        )\n",
    "\n",
    "        self.mlp = nn.Sequential(nn.Linear(self.Hidden_DGiven, output_dimension), nn.Softmax(dim=-1))\n",
    "\n",
    "    def forward(self, images):        \n",
    "        n, c, h, w = images.shape\n",
    "        patches1A = images[0:n,0,0:self.patch_size[0]*self.number_patchesRow,0:self.patch_size[1]*self.number_patchesColumn]#patchify(images, self.n_patches).to(self.positional_embeddings1.device)\n",
    "        Size=64#(patches1A.size(1)*patches1A.size(2))/(self.number_patchesRow*self.number_patchesColumn)\n",
    "        #print(Size)\n",
    "        patches1=patches1A.reshape(n,self.number_patchesRow*self.number_patchesColumn,Size)\n",
    "        \n",
    "        tokens1 = self.linear_mapper(patches1)\n",
    "        tokensa = torch.cat((self.class_token.expand(n, 1, -1), tokens1), dim=1)\n",
    "\n",
    "        A    = tokensa + self.positional_embeddings1.repeat(n, 1, 1) \n",
    "\n",
    "        for block in self.blocksA:\n",
    "            A = block(A)\n",
    "        \n",
    "        output = torch.ones(n,self.Hidden_DGiven)\n",
    "        \n",
    "        output[0:n,self.Hidden_DGiven*0:self.Hidden_DGiven]  = A[:, 0]\n",
    "\n",
    "        return self.mlp(output)\n",
    "\n",
    "\n",
    "def main():\n",
    "    \n",
    "    transform = ToTensor()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = MyViT(\n",
    "        (1, 128,40), number_patchesRow=16, number_patchesColumn=5, number_blocks=2, Hidden_DGiven=5, NumberHeadsGiven=5, output_dimension=5\n",
    "    ).to(device)\n",
    "\n",
    "    NUMBER_EPOCHS = 3\n",
    "    LearningRate = 0.003\n",
    "\n",
    "    # Training Data loop\n",
    "    optimizer = Adam(model.parameters(), lr= LearningRate)\n",
    "    criterion = CrossEntropyLoss()\n",
    "\n",
    "    for epoch in trange(NUMBER_EPOCHS, desc=\"Training\"):\n",
    "        training_loss = 0.0\n",
    "        for batch in range(0,Length,Stride):\n",
    "            y = y_train[batch:batch+Stride]\n",
    "            x = X_train[batch:batch+Stride,0:1,0:128,0:40]\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            y_hat = model(x)\n",
    "            \n",
    "            loss = criterion(y_hat, y.type(torch.LongTensor))\n",
    "            print(loss)\n",
    "            training_loss += loss.detach().cpu().item()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        print(f\"Epoch {epoch + 1}/{NUMBER_EPOCHS} loss: {training_loss:.2f}\")\n",
    "\n",
    "    # Testing loop with testing data\n",
    "    with torch.no_grad():\n",
    "        correct, total = 0, 0\n",
    "        test_loss = 0.0\n",
    "        y = y_test\n",
    "        x = X_test\n",
    "\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        y_hat = model(x)\n",
    "        loss = criterion(y_hat, y.type(torch.LongTensor))\n",
    "\n",
    "        test_loss += loss.detach().cpu().item()\n",
    "\n",
    "        correct += torch.sum(torch.argmax(y_hat, dim=1) == y).detach().cpu().item()\n",
    "        total += len(x)\n",
    "        print(f\"Test loss: {test_loss:.2f}\")\n",
    "        print(f\"Test accuracy: {correct / total * 100:.2f}%\")\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8a381517",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:   0%|                                           | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.6204, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6050, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6120, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5982, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5944, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5841, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5639, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5624, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5715, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5554, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5458, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5413, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5414, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5424, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5234, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5347, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5225, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5250, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5208, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5037, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5136, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5042, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4952, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5095, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4916, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4852, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4872, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4869, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4668, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4882, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4628, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4644, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4730, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4627, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4596, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4493, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4694, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4573, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4546, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4482, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4485, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4496, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4441, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4567, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4619, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4576, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4533, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4331, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4284, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4481, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4209, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4433, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4466, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4416, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4433, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4424, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4332, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4356, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4363, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4366, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4307, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4397, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4229, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4290, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4488, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4424, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4434, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4282, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4277, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4379, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4377, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4456, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4466, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4397, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4447, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4377, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4245, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4262, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4232, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4262, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4364, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4398, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4375, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4255, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4331, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4269, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4455, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4408, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4386, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4284, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4353, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4416, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4224, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4456, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4326, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4222, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4230, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4274, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4356, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4225, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4382, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4278, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4180, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4281, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4383, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4225, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4224, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4268, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4163, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4201, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4117, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4279, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4283, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4264, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4149, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4193, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4089, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4147, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4164, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4197, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4107, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4108, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4090, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4046, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4009, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3813, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3841, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3931, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3548, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3656, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3532, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3398, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3363, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3259, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3464, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3219, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2995, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2894, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2929, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2963, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2772, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2807, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2770, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2602, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2545, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2475, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2535, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2390, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2503, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2272, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2326, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2377, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1963, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2283, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2001, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1945, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1757, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1860, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1805, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1630, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1652, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1627, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1464, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1468, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1466, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1219, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1387, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1217, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1142, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1220, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1148, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1125, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1182, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1181, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0964, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1084, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1242, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1106, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1078, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0946, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0894, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0979, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1211, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0797, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1147, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0836, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0883, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0805, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1178, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0903, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0856, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0881, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0833, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0772, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0768, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0767, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0730, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0554, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0597, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0562, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0505, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0696, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0669, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0506, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0547, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0417, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0294, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0307, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0453, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0255, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0224, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0177, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0110, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0193, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0159, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0142, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0063, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9965, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9915, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9895, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9888, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9832, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9877, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9844, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9865, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9814, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9850, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9716, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9744, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9685, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9657, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9712, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9671, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9616, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9529, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9523, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9540, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9664, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9645, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9531, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9575, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9513, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9504, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9522, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9594, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9544, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9586, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9500, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9515, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9448, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9499, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9451, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9476, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9409, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9492, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9457, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9437, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9545, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9420, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9415, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9440, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9416, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9477, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9397, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9454, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9421, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9509, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9467, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9407, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9449, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9421, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9491, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9486, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9318, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9433, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9478, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9394, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9435, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9408, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9457, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9392, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9346, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9384, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9459, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9348, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9383, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9340, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9429, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9343, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9325, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9416, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9343, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9321, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9264, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9352, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9323, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9344, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9318, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9386, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9336, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9329, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9367, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9318, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9347, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9290, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9347, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9374, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9305, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9329, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9287, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9341, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9359, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9373, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9288, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9343, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9366, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9276, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9333, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9320, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9337, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:  33%|███████████                      | 1/3 [17:01<34:03, 1021.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 loss: 386.45\n",
      "tensor(0.9341, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9302, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9242, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9328, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9331, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9255, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9326, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9284, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9236, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9319, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9304, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9241, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9267, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9344, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9285, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9284, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9303, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9267, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9338, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9287, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9406, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9226, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9290, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9447, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9297, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9376, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9426, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9317, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9318, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9333, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9328, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9288, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9309, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9282, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9240, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9284, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9252, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9266, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9278, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9216, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9313, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9274, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9249, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9261, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9209, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9196, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9315, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9190, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9227, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9249, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9237, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9253, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9267, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9221, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9252, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9293, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9225, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9265, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9297, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9237, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9306, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9241, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9187, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9244, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9241, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9212, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9249, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9254, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9266, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9215, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9269, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9258, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9218, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9242, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9215, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9289, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9246, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9243, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9185, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9216, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9196, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9222, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9201, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9230, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9240, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9197, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9236, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9198, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9161, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9213, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9196, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9252, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9279, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9207, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9209, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9263, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9217, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9154, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9219, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9228, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9209, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9160, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9151, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9186, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9226, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9298, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9251, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9223, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9158, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9213, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9192, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9295, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9244, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9242, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9222, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9220, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9185, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9232, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9255, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9183, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9270, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9227, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9231, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9290, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9205, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9272, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9243, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9305, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9237, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9284, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9247, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9184, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9265, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9175, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9231, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9160, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9196, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9242, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9158, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9204, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9175, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9157, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9210, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9212, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9234, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9163, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9188, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9204, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9171, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9222, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9214, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9233, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9152, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9213, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9214, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9241, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9200, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9237, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9183, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9167, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9171, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9200, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9186, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9166, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9252, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9183, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9200, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9172, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9191, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9200, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9166, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9192, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9190, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9254, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9200, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9185, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9198, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9210, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9191, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9148, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9159, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9161, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9157, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9165, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9197, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9248, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9200, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9194, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9196, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9229, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9207, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9205, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9153, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9216, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9164, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9180, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9209, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9153, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9192, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9159, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9173, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9244, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9245, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9187, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9120, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9144, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9228, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9236, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9221, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9230, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9198, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9201, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9202, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9270, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9174, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9171, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9186, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9222, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9234, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9150, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9202, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9204, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9221, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9228, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9168, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9252, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9186, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9206, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9331, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9276, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9186, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9295, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9283, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9229, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9219, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9234, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9342, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9393, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9290, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9215, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9222, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9277, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9202, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9184, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9276, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9200, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9142, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9181, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9202, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9165, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9225, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9175, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9149, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9177, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9203, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9218, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9166, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9209, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9168, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9182, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9177, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9168, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9187, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9137, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9172, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9170, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9195, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9181, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9165, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9185, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9171, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9165, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9153, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9168, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9167, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9217, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9207, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9203, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9192, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9184, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9190, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9197, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9183, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9204, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9171, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9189, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9142, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9167, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9197, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9164, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9223, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9155, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9106, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9147, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9143, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9133, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9158, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9192, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9209, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9162, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9157, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9208, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9173, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9164, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9139, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9164, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9185, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9143, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9142, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9194, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9280, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9173, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9190, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9197, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9160, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9214, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9168, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9158, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9140, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9182, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:  67%|██████████████████████           | 2/3 [34:47<17:27, 1047.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 loss: 295.02\n",
      "tensor(0.9136, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9154, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9158, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9236, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9220, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9122, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9187, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9165, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9108, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9169, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9198, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9147, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9127, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9200, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9173, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9113, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9133, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9148, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9187, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9199, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9166, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9132, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9160, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9199, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9187, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9178, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9218, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9174, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9150, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9186, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9172, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9207, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9190, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9220, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9125, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9157, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9168, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9124, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9178, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9157, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9195, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9239, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9155, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9171, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9140, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9148, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9213, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9089, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9146, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9162, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9177, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9175, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9192, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9150, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9174, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9213, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9181, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9174, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9183, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9141, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9166, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9148, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9173, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9169, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9167, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9162, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9215, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9170, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9189, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9170, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9253, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9221, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9126, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9226, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9205, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9191, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9163, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9150, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9161, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9158, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9140, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9168, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9157, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9169, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9194, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9108, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9186, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9184, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9093, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9177, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9171, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9193, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9196, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9129, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9164, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9159, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9162, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9130, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9164, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9185, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9152, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9118, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9118, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9167, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9159, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9210, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9230, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9141, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9134, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9215, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9171, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9241, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9201, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9215, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9139, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9174, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9130, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9154, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9184, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9149, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9138, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9176, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9153, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9184, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9168, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9241, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9170, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9139, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9214, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9209, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9181, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9158, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9254, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9165, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9186, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9088, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9167, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9179, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9132, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9162, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9154, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9137, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9187, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9160, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9179, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9129, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9165, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9169, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9119, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9163, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9147, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9172, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9155, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9175, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9202, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9188, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9170, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9163, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9166, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9125, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9143, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9143, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9164, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9109, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9211, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9178, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9191, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9162, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9150, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9162, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9183, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9160, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9141, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9235, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9173, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9157, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9122, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9155, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9183, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9147, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9150, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9127, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9112, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9142, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9176, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9189, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9169, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9119, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9174, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9206, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9166, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9201, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9127, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9243, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9134, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9155, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9150, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9128, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9210, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9137, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9167, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9230, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9254, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9163, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9107, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9112, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9183, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9198, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9196, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9210, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9169, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9160, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9181, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9270, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9185, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9143, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9160, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9159, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9202, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9185, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9159, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9164, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9185, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9211, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9166, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9217, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9194, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9210, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9199, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9155, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9167, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9228, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9138, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9157, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9182, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9176, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9173, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9237, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9190, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9165, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9146, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9151, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9155, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9152, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9154, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9098, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9133, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9176, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9142, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9133, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9183, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9157, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9153, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9129, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9154, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9199, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9170, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9183, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9131, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9184, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9134, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9223, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9166, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9136, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9201, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9223, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9122, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9124, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9157, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9140, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9189, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9145, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9144, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9166, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9127, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9178, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9191, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9175, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9174, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9162, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9193, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9162, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9116, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9187, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9164, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9207, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9146, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9132, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9178, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9186, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9202, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9148, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9110, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9204, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9170, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9145, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9196, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9233, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9195, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9160, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9148, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9197, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9196, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9142, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9130, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9143, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9156, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9157, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9154, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9155, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9222, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9148, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9189, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9186, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9144, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9206, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9104, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9124, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9110, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9156, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|█████████████████████████████████| 3/3 [53:02<00:00, 1060.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 loss: 293.38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.91\n",
      "Test accuracy: 99.03%\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "class MyViT(nn.Module):\n",
    "    def __init__(self, Dimensions, number_patchesRow,number_patchesColumn, number_blocks, Hidden_DGiven, NumberHeadsGiven, output_dimension):\n",
    "        \n",
    "        super(MyViT, self).__init__()\n",
    "        self.Dimensions = Dimensions  \n",
    "        self.number_patchesRow = number_patchesRow\n",
    "        self.number_patchesColumn=number_patchesColumn\n",
    "        self.number_blocks = number_blocks\n",
    "        self.Hidden_DGiven= Hidden_DGiven\n",
    "        self.NumberHeadsGiven = NumberHeadsGiven\n",
    "        \n",
    "        self.patch_size = (math.floor(Dimensions[1] / number_patchesRow), math.floor(Dimensions[2] / number_patchesColumn))\n",
    "        \n",
    "        self.input_d = int(Dimensions[0] * self.patch_size[0] * self.patch_size[1])\n",
    "        self.linear_mapper = nn.Linear(self.input_d, self.Hidden_DGiven)\n",
    "\n",
    "        self.class_token = nn.Parameter(torch.rand(1, self.Hidden_DGiven))\n",
    "\n",
    "        self.register_buffer(\n",
    "            \"positional_embeddings1\",\n",
    "            get_positional_embeddings3(number_patchesRow*number_patchesColumn + 1, Hidden_DGiven),\n",
    "            persistent=False,\n",
    "        )\n",
    "        \n",
    "        self.blocksA = nn.ModuleList(\n",
    "            [VisionTransformer(Hidden_DGiven, NumberHeadsGiven) for _ in range(number_blocks)]\n",
    "        )\n",
    "\n",
    "        self.mlp = nn.Sequential(nn.Linear(self.Hidden_DGiven, output_dimension), nn.Softmax(dim=-1))\n",
    "\n",
    "    def forward(self, images):        \n",
    "        n, c, h, w = images.shape\n",
    "        patches1A = images[0:n,0,0:self.patch_size[0]*self.number_patchesRow,0:self.patch_size[1]*self.number_patchesColumn]#patchify(images, self.n_patches).to(self.positional_embeddings1.device)\n",
    "        Size=64#(patches1A.size(1)*patches1A.size(2))/(self.number_patchesRow*self.number_patchesColumn)\n",
    "        #print(Size)\n",
    "        patches1=patches1A.reshape(n,self.number_patchesRow*self.number_patchesColumn,Size)\n",
    "        \n",
    "        tokens1 = self.linear_mapper(patches1)\n",
    "        tokensa = torch.cat((self.class_token.expand(n, 1, -1), tokens1), dim=1)\n",
    "\n",
    "        A    = tokensa + self.positional_embeddings1.repeat(n, 1, 1) \n",
    "\n",
    "        for block in self.blocksA:\n",
    "            A = block(A)\n",
    "        \n",
    "        output = torch.ones(n,self.Hidden_DGiven)\n",
    "        \n",
    "        output[0:n,self.Hidden_DGiven*0:self.Hidden_DGiven]  = A[:, 0]\n",
    "\n",
    "        return self.mlp(output)\n",
    "\n",
    "\n",
    "def main():\n",
    "    \n",
    "    transform = ToTensor()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = MyViT(\n",
    "        (1, 128,40), number_patchesRow=16, number_patchesColumn=5, number_blocks=2, Hidden_DGiven=5, NumberHeadsGiven=5, output_dimension=5\n",
    "    ).to(device)\n",
    "\n",
    "    NUMBER_EPOCHS = 3\n",
    "    LearningRate = 0.003\n",
    "\n",
    "    # Training Data loop\n",
    "    optimizer = Adam(model.parameters(), lr= LearningRate)\n",
    "    criterion = CrossEntropyLoss()\n",
    "\n",
    "    for epoch in trange(NUMBER_EPOCHS, desc=\"Training\"):\n",
    "        training_loss = 0.0\n",
    "        for batch in range(0,Length,Stride):\n",
    "            y = y_train[batch:batch+Stride]\n",
    "            x = X_train[batch:batch+Stride,0:1,0:128,0:40]\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            y_hat = model(x)\n",
    "            \n",
    "            loss = criterion(y_hat, y.type(torch.LongTensor))\n",
    "            print(loss)\n",
    "            training_loss += loss.detach().cpu().item()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        print(f\"Epoch {epoch + 1}/{NUMBER_EPOCHS} loss: {training_loss:.2f}\")\n",
    "\n",
    "    # Testing loop with testing data\n",
    "    with torch.no_grad():\n",
    "        correct, total = 0, 0\n",
    "        test_loss = 0.0\n",
    "        y = y_test\n",
    "        x = X_test\n",
    "\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        y_hat = model(x)\n",
    "        loss = criterion(y_hat, y.type(torch.LongTensor))\n",
    "\n",
    "        test_loss += loss.detach().cpu().item()\n",
    "\n",
    "        correct += torch.sum(torch.argmax(y_hat, dim=1) == y).detach().cpu().item()\n",
    "        total += len(x)\n",
    "        print(f\"Test loss: {test_loss:.2f}\")\n",
    "        print(f\"Test accuracy: {correct / total * 100:.2f}%\")\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "74b59b88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:   0%|                                           | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.6244, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6141, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6229, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6135, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6151, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6141, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6037, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6108, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6110, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6059, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6045, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5956, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5972, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5976, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5950, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5906, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5891, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5893, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5840, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5794, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5808, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5737, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5709, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5687, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5679, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5607, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5580, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5521, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5415, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5384, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5334, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5340, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5211, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5211, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5137, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5134, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4918, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5025, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5001, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4773, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4748, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4756, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4627, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4676, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4535, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4439, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4450, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4351, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4301, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4237, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4104, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3991, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4091, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4141, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3948, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3934, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3844, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3723, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3568, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3604, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3767, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3426, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3453, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3452, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3297, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3142, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3153, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3212, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3067, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2890, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3078, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3024, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2941, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3039, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3049, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2960, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2765, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2718, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2613, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2863, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2797, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2470, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2736, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2636, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2697, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2618, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2958, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2959, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2665, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2525, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2692, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2857, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2735, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2784, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2716, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2587, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2574, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2628, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2729, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2617, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2775, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2821, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2609, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2720, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2969, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2660, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2718, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2511, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2673, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2599, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2402, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2675, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2550, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2699, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2661, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2628, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2694, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2456, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2715, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2624, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2703, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2758, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2534, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2546, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2722, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2447, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2637, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2825, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2320, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2433, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2397, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2315, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2277, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2220, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2432, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2169, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1989, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1892, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1932, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1958, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1731, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1676, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1677, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1528, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1407, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1218, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1256, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1084, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1239, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1051, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1072, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1064, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0746, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0895, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0855, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0802, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0691, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0720, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0629, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0518, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0693, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0488, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0494, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0409, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0521, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0346, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0401, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0336, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0154, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0249, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0192, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0302, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0240, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0244, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0036, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0027, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0046, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0103, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9995, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9965, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9943, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9828, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9974, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9961, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9825, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9865, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9820, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9908, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9896, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9825, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9798, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9767, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9723, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9779, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9709, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9701, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9701, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9829, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9830, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9786, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9669, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9753, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9738, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9685, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9760, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9805, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9695, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9562, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9721, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9793, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9687, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9618, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9646, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9661, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9573, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9709, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9698, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9541, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9639, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9673, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9684, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9639, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9644, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9758, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9605, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9727, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9677, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9525, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9643, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9541, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9559, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9649, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9592, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9547, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9599, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9512, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9504, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9687, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9590, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9532, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9437, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9563, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9613, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9554, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9433, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9577, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9564, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9529, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9512, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9473, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9572, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9579, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9502, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9442, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9447, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9562, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9544, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9737, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9595, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9443, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9580, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9560, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9488, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9469, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9417, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9504, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9552, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9458, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9469, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9417, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9486, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9490, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9487, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9405, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9400, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9445, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9482, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9540, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9436, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9541, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9378, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9560, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9400, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9416, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9404, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9449, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9439, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9414, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9478, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9414, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9519, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9427, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9371, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9417, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9415, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9462, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9426, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9510, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9506, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9542, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9391, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9452, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9409, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9392, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9464, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9439, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9411, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9417, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9303, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9421, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9436, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9430, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9367, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9438, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9438, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9452, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9364, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9402, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9448, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9446, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:  33%|███████████                      | 1/3 [17:26<34:52, 1046.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 loss: 369.54\n",
      "tensor(0.9344, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9342, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9380, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9419, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9329, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9466, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9364, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9400, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9397, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9572, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9433, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9432, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9483, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9408, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9406, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9426, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9430, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9440, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9486, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9411, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9441, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9499, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9507, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9402, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9362, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9550, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9350, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9332, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9404, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9510, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9344, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9325, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9388, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9420, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9398, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9451, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9393, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9593, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9488, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9383, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9378, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9586, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9364, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9431, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9382, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9505, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9403, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9370, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9413, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9460, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9327, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9316, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9424, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9273, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9370, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9448, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9309, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9330, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9363, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9343, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9357, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9385, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9431, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9403, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9275, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9247, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9381, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9378, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9365, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9402, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9421, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9319, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9304, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9330, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9342, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9360, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9354, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9250, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9371, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9392, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9313, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9240, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9377, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9262, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9354, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9347, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9326, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9281, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9318, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9293, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9313, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9409, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9217, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9343, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9306, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9242, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9311, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9269, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9396, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9352, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9284, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9320, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9307, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9329, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9309, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9388, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9320, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9272, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9256, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9291, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9304, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9275, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9312, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9302, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9337, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9221, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9258, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9361, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9284, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9311, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9241, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9282, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9269, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9318, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9281, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9271, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9240, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9252, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9219, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9272, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9261, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9166, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9185, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9230, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9198, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9190, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9187, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9179, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9195, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9130, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9210, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9162, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9199, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9193, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9203, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9184, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9134, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9180, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9195, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9192, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9207, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9233, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9110, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9199, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9140, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9196, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9195, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9155, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9173, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9173, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9206, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9159, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9223, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9220, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9196, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9168, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9144, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9154, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9177, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9146, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9154, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9162, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9216, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9192, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9191, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9146, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9169, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9174, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9144, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9149, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9147, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9119, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9198, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9142, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9151, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9219, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9152, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9113, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9156, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9125, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9138, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9160, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9181, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9156, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9134, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9141, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9151, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9218, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9167, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9143, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9172, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9131, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9192, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9225, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9148, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9209, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9139, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9120, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9151, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9157, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9214, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9119, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9181, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9143, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9151, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9143, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9207, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9105, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9147, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9129, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9137, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9148, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9154, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9177, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9186, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9134, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9142, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9170, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9143, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9127, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9115, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9170, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9117, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9126, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9135, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9153, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9132, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9151, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9144, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9116, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9146, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9127, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9230, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9134, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9157, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9120, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9127, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9211, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9157, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9137, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9145, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9109, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9098, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9092, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9146, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9117, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9159, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9108, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9152, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9122, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9143, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9142, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9150, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9157, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9114, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9081, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9126, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9124, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9090, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9121, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9164, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9160, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9124, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9122, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9126, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9160, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9113, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9156, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9103, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9110, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9110, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9146, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9091, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9136, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9110, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9170, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9126, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9130, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9125, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9118, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9166, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9141, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9093, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9124, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9150, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9147, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9151, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9162, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9157, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9174, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9100, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9132, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9129, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9141, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9146, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9117, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9132, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9136, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9163, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9148, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9161, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9149, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9129, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9206, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9163, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9177, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9090, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9126, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9070, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9104, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:  67%|██████████████████████           | 2/3 [35:13<17:38, 1058.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 loss: 295.58\n",
      "tensor(0.9144, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9114, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9140, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9124, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9132, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9143, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9148, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9098, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9176, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9172, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9076, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9114, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9093, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9095, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9131, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9120, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9121, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9146, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9146, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9111, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9136, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9141, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9141, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9100, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9093, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9150, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9078, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9130, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9102, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9105, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9127, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9089, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9135, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9128, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9097, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9157, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9146, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9111, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9105, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9139, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9097, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9146, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9109, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9107, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9135, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9130, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9195, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9129, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9125, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9132, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9158, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9091, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9118, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9104, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9122, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9109, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9154, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9125, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9084, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9113, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9127, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9172, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9172, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9096, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9082, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9061, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9130, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9083, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9085, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9104, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9141, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9103, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9113, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9137, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9097, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9165, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9151, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9082, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9144, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9148, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9106, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9116, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9166, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9099, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9120, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9096, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9083, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9079, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9137, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9124, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9141, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9136, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9107, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9131, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9114, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9095, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9105, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9127, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9131, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9125, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9092, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9128, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9138, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9142, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9110, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9141, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9145, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9115, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9086, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9097, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9076, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9146, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9103, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9159, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9165, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9097, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9115, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9157, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9118, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9149, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9099, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9127, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9123, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9162, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9114, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9113, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9157, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9150, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9112, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9106, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9164, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9135, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9181, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9145, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9137, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9134, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9158, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9094, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9127, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9110, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9207, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9141, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9110, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9103, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9125, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9150, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9094, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9110, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9132, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9127, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9155, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9140, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9102, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9107, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9102, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9113, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9148, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9110, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9096, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9125, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9110, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9144, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9129, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9149, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9145, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9154, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9082, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9156, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9139, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9096, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9135, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9138, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9149, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9148, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9159, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9115, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9116, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9157, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9110, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9103, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9131, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9099, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9136, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9118, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9146, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9149, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9140, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9121, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9092, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9111, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9113, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9116, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9119, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9101, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9085, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9108, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9115, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9102, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9124, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9100, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9150, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9095, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9131, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9145, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9092, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9136, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9093, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9102, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9103, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9092, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9118, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9076, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9144, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9099, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9114, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9103, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9168, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9100, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9112, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9076, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9096, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9110, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9130, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9096, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9126, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9106, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9104, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9071, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9116, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9128, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9081, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9127, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9092, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9102, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9109, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9099, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9101, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9125, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9116, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9096, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9138, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9119, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9169, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9079, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9132, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9073, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9099, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9110, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9107, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9097, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9090, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9102, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9084, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9070, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9104, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9078, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9120, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9086, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9115, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9139, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9124, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9097, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9126, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9121, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9088, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9076, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9127, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9103, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9086, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9088, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9126, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9112, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9101, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9107, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9096, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9113, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9094, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9123, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9090, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9087, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9096, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9098, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9065, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9105, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9111, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9100, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9094, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9109, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9116, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9104, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9142, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9110, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9055, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9108, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9085, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9128, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9117, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9102, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9125, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9143, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9093, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9104, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9092, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9098, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9104, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9124, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9110, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9105, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9135, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9107, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9102, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9132, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9091, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9166, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9111, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9144, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9084, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9104, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9060, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9085, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|█████████████████████████████████| 3/3 [51:16<00:00, 1025.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 loss: 291.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.91\n",
      "Test accuracy: 99.38%\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "class MyViT(nn.Module):\n",
    "    def __init__(self, Dimensions, number_patchesRow,number_patchesColumn, number_blocks, Hidden_DGiven, NumberHeadsGiven, output_dimension):\n",
    "        \n",
    "        super(MyViT, self).__init__()\n",
    "        self.Dimensions = Dimensions  \n",
    "        self.number_patchesRow = number_patchesRow\n",
    "        self.number_patchesColumn=number_patchesColumn\n",
    "        self.number_blocks = number_blocks\n",
    "        self.Hidden_DGiven= Hidden_DGiven\n",
    "        self.NumberHeadsGiven = NumberHeadsGiven\n",
    "        \n",
    "        self.patch_size = (math.floor(Dimensions[1] / number_patchesRow), math.floor(Dimensions[2] / number_patchesColumn))\n",
    "        \n",
    "        self.input_d = int(Dimensions[0] * self.patch_size[0] * self.patch_size[1])\n",
    "        self.linear_mapper = nn.Linear(self.input_d, self.Hidden_DGiven)\n",
    "\n",
    "        self.class_token = nn.Parameter(torch.rand(1, self.Hidden_DGiven))\n",
    "\n",
    "        self.register_buffer(\n",
    "            \"positional_embeddings1\",\n",
    "            get_positional_embeddings4(number_patchesRow*number_patchesColumn + 1, Hidden_DGiven),\n",
    "            persistent=False,\n",
    "        )\n",
    "        \n",
    "        self.blocksA = nn.ModuleList(\n",
    "            [VisionTransformer(Hidden_DGiven, NumberHeadsGiven) for _ in range(number_blocks)]\n",
    "        )\n",
    "\n",
    "        self.mlp = nn.Sequential(nn.Linear(self.Hidden_DGiven, output_dimension), nn.Softmax(dim=-1))\n",
    "\n",
    "    def forward(self, images):        \n",
    "        n, c, h, w = images.shape\n",
    "        patches1A = images[0:n,0,0:self.patch_size[0]*self.number_patchesRow,0:self.patch_size[1]*self.number_patchesColumn]#patchify(images, self.n_patches).to(self.positional_embeddings1.device)\n",
    "        Size=64#(patches1A.size(1)*patches1A.size(2))/(self.number_patchesRow*self.number_patchesColumn)\n",
    "        #print(Size)\n",
    "        patches1=patches1A.reshape(n,self.number_patchesRow*self.number_patchesColumn,Size)\n",
    "        \n",
    "        tokens1 = self.linear_mapper(patches1)\n",
    "        tokensa = torch.cat((self.class_token.expand(n, 1, -1), tokens1), dim=1)\n",
    "\n",
    "        A    = tokensa + self.positional_embeddings1.repeat(n, 1, 1) \n",
    "\n",
    "        for block in self.blocksA:\n",
    "            A = block(A)\n",
    "        \n",
    "        output = torch.ones(n,self.Hidden_DGiven)\n",
    "        \n",
    "        output[0:n,self.Hidden_DGiven*0:self.Hidden_DGiven]  = A[:, 0]\n",
    "\n",
    "        return self.mlp(output)\n",
    "\n",
    "\n",
    "def main():\n",
    "    \n",
    "    transform = ToTensor()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = MyViT(\n",
    "        (1, 128,40), number_patchesRow=16, number_patchesColumn=5, number_blocks=2, Hidden_DGiven=5, NumberHeadsGiven=5, output_dimension=5\n",
    "    ).to(device)\n",
    "\n",
    "    NUMBER_EPOCHS = 3\n",
    "    LearningRate = 0.003\n",
    "\n",
    "    # Training Data loop\n",
    "    optimizer = Adam(model.parameters(), lr= LearningRate)\n",
    "    criterion = CrossEntropyLoss()\n",
    "\n",
    "    for epoch in trange(NUMBER_EPOCHS, desc=\"Training\"):\n",
    "        training_loss = 0.0\n",
    "        for batch in range(0,Length,Stride):\n",
    "            y = y_train[batch:batch+Stride]\n",
    "            x = X_train[batch:batch+Stride,0:1,0:128,0:40]\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            y_hat = model(x)\n",
    "            \n",
    "            loss = criterion(y_hat, y.type(torch.LongTensor))\n",
    "            print(loss)\n",
    "            training_loss += loss.detach().cpu().item()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        print(f\"Epoch {epoch + 1}/{NUMBER_EPOCHS} loss: {training_loss:.2f}\")\n",
    "\n",
    "    # Testing loop with testing data\n",
    "    with torch.no_grad():\n",
    "        correct, total = 0, 0\n",
    "        test_loss = 0.0\n",
    "        y = y_test\n",
    "        x = X_test\n",
    "\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        y_hat = model(x)\n",
    "        loss = criterion(y_hat, y.type(torch.LongTensor))\n",
    "\n",
    "        test_loss += loss.detach().cpu().item()\n",
    "\n",
    "        correct += torch.sum(torch.argmax(y_hat, dim=1) == y).detach().cpu().item()\n",
    "        total += len(x)\n",
    "        print(f\"Test loss: {test_loss:.2f}\")\n",
    "        print(f\"Test accuracy: {correct / total * 100:.2f}%\")\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c9d2e5a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:   0%|                                           | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.6158, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6170, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6131, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6079, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6078, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6073, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6075, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6075, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6033, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6017, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6026, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6015, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5980, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5959, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6001, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5991, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5944, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5946, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5951, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5972, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5930, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5937, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5932, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5886, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5893, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5897, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5849, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5818, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5832, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5852, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5839, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5821, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5732, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5738, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5729, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5726, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5664, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5674, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5671, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5649, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5561, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5575, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5484, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5388, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5321, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5284, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5210, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5136, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5088, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5174, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4909, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4909, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4865, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4783, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4678, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4682, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4515, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4353, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4244, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4219, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4207, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4136, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4042, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3998, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4071, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4018, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3887, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3874, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3793, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3838, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3737, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3740, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3561, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3575, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3722, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3495, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3269, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3336, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3176, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3298, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3138, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2922, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3054, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3029, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3074, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2807, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3224, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3143, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2783, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2547, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2831, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2848, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2630, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2611, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2717, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2465, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2441, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2576, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2493, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2494, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2439, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2496, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2507, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2421, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2425, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2407, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2192, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2119, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2010, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2263, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1882, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1988, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1965, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2052, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2141, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1951, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1877, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2028, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2003, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1752, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1996, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1712, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1700, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1859, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1763, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1882, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1733, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1900, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1599, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1683, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1713, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1710, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1593, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1671, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1776, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1694, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1614, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1607, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1535, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1411, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1399, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1390, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1560, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1487, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1370, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1449, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1424, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1551, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1470, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1287, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1300, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1414, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1123, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1391, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1400, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1422, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1123, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1318, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1299, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1108, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1198, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1072, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1156, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0933, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1111, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0924, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0912, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0840, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0701, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0715, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0583, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0682, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0794, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0704, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0740, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0638, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0719, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0618, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0424, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0410, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0343, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0370, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0361, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0335, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0303, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0191, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0236, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0121, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0207, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0260, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0245, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0213, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0020, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0204, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0072, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0116, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9993, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9978, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9928, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9941, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9947, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0048, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0090, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9936, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9886, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0066, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9853, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9899, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9856, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9916, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9845, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9788, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9841, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9832, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9860, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9734, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9762, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9746, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9758, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9762, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9802, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9685, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9704, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9730, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9628, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9638, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9652, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9671, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9680, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9637, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9733, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9637, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9636, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9631, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9556, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9502, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9657, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9588, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9617, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9609, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9664, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9673, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9489, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9539, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9608, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9638, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9526, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9559, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9579, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9585, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9625, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9527, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9412, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9526, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9503, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9549, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9571, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9512, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9597, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9511, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9590, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9521, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9519, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9580, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9478, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9544, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9531, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9557, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9515, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9460, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9409, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9395, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9430, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9507, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9572, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9374, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9547, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9498, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9412, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9551, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9430, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9440, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9578, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9434, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9483, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9369, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9368, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9400, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9362, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9405, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9383, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9361, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9386, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9342, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9268, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9314, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9378, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9410, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9308, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9343, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9386, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9317, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9284, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9342, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9272, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9371, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9359, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9333, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9285, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9318, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9358, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9294, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9253, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9376, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9382, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9282, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9341, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9277, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9299, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:  33%|███████████▎                      | 1/3 [16:06<32:13, 966.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 loss: 373.69\n",
      "tensor(0.9273, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9336, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9278, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9286, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9302, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9283, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9265, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9273, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9266, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9345, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9260, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9241, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9289, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9347, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9244, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9227, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9240, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9283, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9312, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9304, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9317, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9277, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9248, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9261, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9279, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9230, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9232, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9240, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9247, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9228, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9225, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9270, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9167, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9227, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9229, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9270, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9273, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9202, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9187, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9271, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9193, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9157, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9184, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9278, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9223, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9199, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9287, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9276, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9255, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9219, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9186, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9213, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9157, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9202, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9260, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9255, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9278, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9220, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9171, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9195, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9229, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9235, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9220, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9188, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9191, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9152, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9222, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9162, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9182, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9207, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9225, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9225, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9185, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9177, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9183, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9271, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9197, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9172, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9201, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9232, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9180, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9154, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9197, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9170, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9189, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9180, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9211, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9193, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9160, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9215, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9205, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9249, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9203, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9203, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9140, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9160, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9171, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9178, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9243, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9205, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9154, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9167, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9204, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9176, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9199, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9219, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9194, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9219, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9172, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9174, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9136, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9206, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9168, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9203, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9211, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9176, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9199, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9194, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9211, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9241, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9139, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9207, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9222, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9238, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9165, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9183, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9240, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9237, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9199, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9169, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9216, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9208, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9201, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9166, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9188, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9164, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9205, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9173, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9197, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9148, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9195, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9249, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9179, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9164, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9177, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9177, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9161, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9189, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9157, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9152, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9168, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9210, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9135, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9134, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9163, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9234, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9158, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9197, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9178, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9175, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9172, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9193, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9111, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9146, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9230, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9150, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9136, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9169, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9151, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9245, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9149, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9196, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9245, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9242, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9197, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9179, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9221, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9214, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9137, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9126, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9145, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9175, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9212, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9196, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9158, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9168, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9122, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9152, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9152, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9152, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9136, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9151, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9171, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9149, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9117, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9144, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9148, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9194, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9245, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9160, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9148, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9146, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9214, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9168, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9117, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9145, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9126, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9152, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9118, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9143, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9127, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9138, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9152, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9131, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9226, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9106, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9144, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9140, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9113, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9132, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9165, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9130, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9122, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9111, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9136, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9124, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9130, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9134, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9158, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9136, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9114, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9201, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9102, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9131, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9147, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9151, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9132, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9135, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9149, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9118, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9160, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9121, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9168, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9117, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9140, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9131, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9116, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9119, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9116, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9161, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9131, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9129, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9105, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9105, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9131, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9123, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9133, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9229, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9167, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9146, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9157, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9108, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9172, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9173, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9172, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9193, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9098, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9105, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9120, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9141, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9113, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9094, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9133, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9120, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9145, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9129, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9148, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9133, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9115, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9107, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9134, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9124, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9131, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9149, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9153, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9195, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9110, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9143, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9150, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9109, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9148, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9140, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9119, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9134, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9124, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9134, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9119, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9161, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9171, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9105, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9112, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9125, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9101, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9119, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9098, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9145, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9107, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9114, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9174, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9130, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9128, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9112, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9121, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9141, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9152, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9177, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9109, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9154, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9107, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9089, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:  67%|██████████████████████▋           | 2/3 [31:53<15:55, 955.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 loss: 293.72\n",
      "tensor(0.9110, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9090, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9110, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9124, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9107, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9094, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9102, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9152, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9123, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9117, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9100, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9110, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9141, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9094, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9114, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9111, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9156, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9111, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9153, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9148, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9131, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9089, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9155, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9100, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9117, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9106, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9132, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9103, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9126, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9126, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9107, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9153, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9086, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9078, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9103, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9117, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9136, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9101, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9095, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9135, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9085, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9089, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9089, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9115, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9113, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9084, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9141, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9103, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9126, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9174, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9124, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9126, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9079, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9098, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9138, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9119, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9120, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9095, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9087, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9130, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9122, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9109, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9116, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9100, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9086, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9089, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9117, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9086, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9098, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9098, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9098, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9122, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9151, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9091, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9100, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9144, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9137, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9103, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9153, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9111, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9060, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9141, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9133, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9118, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9085, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9073, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9106, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9096, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9094, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9107, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9095, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9120, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9065, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9101, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9058, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9067, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9089, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9100, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9088, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9121, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9088, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9064, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9091, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9080, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9085, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9115, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9102, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9114, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9107, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9078, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9060, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9087, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9097, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9090, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9111, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9093, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9102, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9095, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9081, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9097, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9064, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9064, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9086, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9084, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9085, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9071, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9074, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9099, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9080, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9091, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9095, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9093, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9108, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9083, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9074, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9076, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9105, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9081, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9086, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9074, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9116, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9114, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9095, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9073, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9072, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9077, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9072, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9114, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9071, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9061, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9078, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9100, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9060, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9098, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9087, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9084, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9099, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9105, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9078, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9085, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9087, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9074, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9075, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9090, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9089, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9064, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9079, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9098, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9076, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9079, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9086, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9086, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9092, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9118, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9096, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9079, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9088, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9076, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9073, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9058, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9098, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9109, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9080, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9089, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9067, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9090, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9059, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9074, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9084, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9070, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9072, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9075, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9097, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9092, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9077, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9077, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9074, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9073, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9111, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9096, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9099, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9077, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9105, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9078, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9087, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9096, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9067, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9089, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9087, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9097, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9062, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9101, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9111, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9082, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9140, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9067, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9085, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9089, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9069, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9078, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9083, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9096, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9110, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9053, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9093, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9093, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9072, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9085, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9071, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9097, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9081, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9101, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9070, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9086, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9080, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9068, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9071, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9079, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9095, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9062, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9099, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9067, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9115, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9107, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9096, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9074, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9087, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9099, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9078, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9084, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9098, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9078, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9061, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9070, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9109, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9078, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9120, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9121, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9112, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9101, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9078, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9085, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9106, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9096, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9180, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9179, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9061, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9085, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9100, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9119, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9109, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9092, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9132, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9119, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9103, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9110, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9128, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9131, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9130, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9092, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9115, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9119, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9222, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9130, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9071, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9084, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9103, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9138, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9111, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9099, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9098, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9076, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9086, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9086, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9089, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9086, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9090, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9085, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9113, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9096, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9080, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9093, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9067, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9080, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9056, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9069, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9061, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9094, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9095, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9055, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9075, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9086, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9076, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9081, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9101, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9113, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9069, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9087, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9061, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9059, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████| 3/3 [47:40<00:00, 953.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 loss: 291.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.91\n",
      "Test accuracy: 99.72%\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "class MyViT(nn.Module):\n",
    "    def __init__(self, Dimensions, number_patchesRow,number_patchesColumn, number_blocks, Hidden_DGiven, NumberHeadsGiven, output_dimension):\n",
    "        \n",
    "        super(MyViT, self).__init__()\n",
    "        self.Dimensions = Dimensions  \n",
    "        self.number_patchesRow = number_patchesRow\n",
    "        self.number_patchesColumn=number_patchesColumn\n",
    "        self.number_blocks = number_blocks\n",
    "        self.Hidden_DGiven= Hidden_DGiven\n",
    "        self.NumberHeadsGiven = NumberHeadsGiven\n",
    "        \n",
    "        self.patch_size = (math.floor(Dimensions[1] / number_patchesRow), math.floor(Dimensions[2] / number_patchesColumn))\n",
    "        \n",
    "        self.input_d = int(Dimensions[0] * self.patch_size[0] * self.patch_size[1])\n",
    "        self.linear_mapper = nn.Linear(self.input_d, self.Hidden_DGiven)\n",
    "\n",
    "        self.class_token = nn.Parameter(torch.rand(1, self.Hidden_DGiven))\n",
    "\n",
    "        self.register_buffer(\n",
    "            \"positional_embeddings1\",\n",
    "            get_positional_embeddings5(number_patchesRow*number_patchesColumn + 1, Hidden_DGiven),\n",
    "            persistent=False,\n",
    "        )\n",
    "        \n",
    "        self.blocksA = nn.ModuleList(\n",
    "            [VisionTransformer(Hidden_DGiven, NumberHeadsGiven) for _ in range(number_blocks)]\n",
    "        )\n",
    "\n",
    "        self.mlp = nn.Sequential(nn.Linear(self.Hidden_DGiven, output_dimension), nn.Softmax(dim=-1))\n",
    "\n",
    "    def forward(self, images):        \n",
    "        n, c, h, w = images.shape\n",
    "        patches1A = images[0:n,0,0:self.patch_size[0]*self.number_patchesRow,0:self.patch_size[1]*self.number_patchesColumn]#patchify(images, self.n_patches).to(self.positional_embeddings1.device)\n",
    "        Size=64#(patches1A.size(1)*patches1A.size(2))/(self.number_patchesRow*self.number_patchesColumn)\n",
    "        #print(Size)\n",
    "        patches1=patches1A.reshape(n,self.number_patchesRow*self.number_patchesColumn,Size)\n",
    "        \n",
    "        tokens1 = self.linear_mapper(patches1)\n",
    "        tokensa = torch.cat((self.class_token.expand(n, 1, -1), tokens1), dim=1)\n",
    "\n",
    "        A    = tokensa + self.positional_embeddings1.repeat(n, 1, 1) \n",
    "\n",
    "        for block in self.blocksA:\n",
    "            A = block(A)\n",
    "        \n",
    "        output = torch.ones(n,self.Hidden_DGiven)\n",
    "        \n",
    "        output[0:n,self.Hidden_DGiven*0:self.Hidden_DGiven]  = A[:, 0]\n",
    "\n",
    "        return self.mlp(output)\n",
    "\n",
    "\n",
    "def main():\n",
    "    \n",
    "    transform = ToTensor()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = MyViT(\n",
    "        (1, 128,40), number_patchesRow=16, number_patchesColumn=5, number_blocks=2, Hidden_DGiven=5, NumberHeadsGiven=5, output_dimension=5\n",
    "    ).to(device)\n",
    "\n",
    "    NUMBER_EPOCHS = 3\n",
    "    LearningRate = 0.003\n",
    "\n",
    "    # Training Data loop\n",
    "    optimizer = Adam(model.parameters(), lr= LearningRate)\n",
    "    criterion = CrossEntropyLoss()\n",
    "\n",
    "    for epoch in trange(NUMBER_EPOCHS, desc=\"Training\"):\n",
    "        training_loss = 0.0\n",
    "        for batch in range(0,Length,Stride):\n",
    "            y = y_train[batch:batch+Stride]\n",
    "            x = X_train[batch:batch+Stride,0:1,0:128,0:40]\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            y_hat = model(x)\n",
    "            \n",
    "            loss = criterion(y_hat, y.type(torch.LongTensor))\n",
    "            print(loss)\n",
    "            training_loss += loss.detach().cpu().item()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        print(f\"Epoch {epoch + 1}/{NUMBER_EPOCHS} loss: {training_loss:.2f}\")\n",
    "\n",
    "    # Testing loop with testing data\n",
    "    with torch.no_grad():\n",
    "        correct, total = 0, 0\n",
    "        test_loss = 0.0\n",
    "        y = y_test\n",
    "        x = X_test\n",
    "\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        y_hat = model(x)\n",
    "        loss = criterion(y_hat, y.type(torch.LongTensor))\n",
    "\n",
    "        test_loss += loss.detach().cpu().item()\n",
    "\n",
    "        correct += torch.sum(torch.argmax(y_hat, dim=1) == y).detach().cpu().item()\n",
    "        total += len(x)\n",
    "        print(f\"Test loss: {test_loss:.2f}\")\n",
    "        print(f\"Test accuracy: {correct / total * 100:.2f}%\")\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7700b6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_positional_embeddings1(seq_len, d):\n",
    "    resultingOutput = torch.ones(seq_len, d)\n",
    "    LearnableParameter1 = nn.SELU()\n",
    "    for i in range(seq_len):\n",
    "        for j in range(d):\n",
    "            resultingOutput[i][j] = LearnableParameter1(torch.tensor(np.sin(i / (10000 ** (2*j / d))) if j % 2 == 0 else np.cos(i / (10000 ** (2*(j - 1) / d)))))\n",
    "    return resultingOutput\n",
    "\n",
    "def get_positional_embeddings2(seq_len, d):\n",
    "    resultingOutput = torch.ones(seq_len, d)\n",
    "    LearnableParameter2 = nn.SELU()\n",
    "    for i in range(seq_len):\n",
    "        for j in range(d):\n",
    "            resultingOutput[i][j] = LearnableParameter2(torch.tensor(np.sin(i / (10000 ** (0.4*j / d))) if j % 2 == 0 else np.cos(i / (10000 ** (0.4*(j - 1) / d)))))\n",
    "    return resultingOutput\n",
    "\n",
    "def get_positional_embeddings3(seq_len, d):\n",
    "    resultingOutput = torch.ones(seq_len, d)\n",
    "    LearnableParameter3 = nn.SELU()\n",
    "    for i in range(seq_len):\n",
    "        for j in range(d):\n",
    "            resultingOutput[i][j] = LearnableParameter3(torch.tensor(np.sin(i / (10000 ** (1*j / d))) if j % 2 == 0 else np.cos(i / (10000 ** (1*(j - 1) / d)))))\n",
    "    return resultingOutput\n",
    "\n",
    "import math\n",
    "def get_positional_embeddings4(seq_len, d):\n",
    "    resultingOutput = torch.ones(seq_len, d)\n",
    "    LearnableParameter4 = nn.SELU()\n",
    "    for i in range(seq_len):\n",
    "        for j in range(d):\n",
    "            resultingOutput[i][j] = LearnableParameter4(torch.tensor(np.sin(i / (10000 ** (3*math.sqrt(j) / (d)))) if j % 2 == 0 else np.cos(i / (10000 ** (3*math.sqrt(j - 1) / (d))))))\n",
    "    return resultingOutput\n",
    "\n",
    "import math\n",
    "def get_positional_embeddings5(seq_len, d):\n",
    "    resultingOutput = torch.ones(seq_len, d)\n",
    "    LearnableParameter5 = nn.SELU()\n",
    "    for i in range(seq_len):\n",
    "        for j in range(d):\n",
    "            resultingOutput[i][j] = LearnableParameter5(torch.tensor(np.sin(i / (10000 ** (math.sqrt(j) / (d)))) if j % 2 == 0 else np.cos(i / (10000 ** (math.sqrt(j - 1) / (d))))))\n",
    "    return resultingOutput\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "78aebe4d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:   0%|                                           | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.6222, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6272, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6220, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6154, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6167, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6188, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6124, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6209, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6170, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6138, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6133, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6118, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6115, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6082, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6136, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6094, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6122, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6109, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6108, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6138, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6098, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6116, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6123, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6059, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6091, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6113, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6090, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6083, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6136, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6081, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6115, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6088, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6071, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6067, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6072, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6068, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6059, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6046, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6042, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6051, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6027, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6014, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6009, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5979, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5988, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5962, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5923, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5891, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5835, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5860, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5747, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5774, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5721, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5655, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5611, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5544, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5403, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5330, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5222, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5126, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4953, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4928, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4704, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4649, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4800, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4689, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4649, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4454, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4412, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4491, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4493, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4540, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4553, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4471, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4474, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4437, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4294, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4309, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4272, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4297, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4409, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4469, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4448, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4292, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4381, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4334, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4477, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4433, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4441, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4357, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4379, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4458, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4286, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4530, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4347, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4251, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4281, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4319, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4404, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4262, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4412, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4303, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4215, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4320, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4409, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4268, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4256, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4315, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4209, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4253, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4186, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4347, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4351, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4363, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4222, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4306, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4174, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4250, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4263, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4368, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4266, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4316, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4308, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4297, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4285, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4151, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4207, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4321, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4051, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4216, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4102, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3997, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4005, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3986, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4208, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4004, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3841, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3686, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3728, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3741, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3694, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3608, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3577, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3354, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3426, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3312, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3258, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3141, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3565, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3071, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3183, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3292, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2864, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3200, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2980, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2949, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2815, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2934, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2891, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2821, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2971, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2865, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2869, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2876, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2838, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2652, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2900, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2715, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2659, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2684, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2745, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2696, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2756, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2713, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2690, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2853, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2832, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2849, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2814, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2749, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2571, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2705, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2816, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2593, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2694, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2627, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2648, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2615, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2879, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2600, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2728, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.2759, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2689, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2614, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2592, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2590, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2599, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2448, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2698, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2571, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2606, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2614, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2763, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2494, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2585, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2631, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2595, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2638, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2608, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2581, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2590, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2466, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2617, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2691, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2576, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2541, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2480, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2368, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2420, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2551, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2389, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2435, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2528, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2578, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2688, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2517, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2259, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2379, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2468, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2578, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2456, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2475, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2278, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2444, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2402, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2441, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2256, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2374, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2516, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2466, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2372, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2262, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2311, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2246, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2221, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2415, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2408, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2367, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2403, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2322, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2389, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2424, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2483, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2290, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2320, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2328, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2151, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2331, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2412, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2164, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2468, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2458, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2227, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2338, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2172, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2112, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2297, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2257, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2272, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2034, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2322, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2312, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2343, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2162, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2300, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2231, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2239, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2194, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2235, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2296, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2440, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2180, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2354, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2098, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2296, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2276, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2306, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2331, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2168, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2008, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2223, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2220, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1976, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2063, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2032, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1853, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1836, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1856, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1943, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1933, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1503, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1705, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1462, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1509, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1497, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1515, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1459, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1263, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1365, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1095, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0986, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1101, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0999, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0945, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0893, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1074, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0739, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0710, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0688, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0816, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:  33%|███████████▎                      | 1/3 [15:53<31:47, 953.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 loss: 433.59\n",
      "tensor(1.0778, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0691, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0585, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0749, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0677, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0583, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0750, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0506, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0474, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0492, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0695, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0584, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0577, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0676, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0735, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0548, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0559, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0466, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0435, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0534, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0607, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0416, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0455, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0551, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0612, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0582, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0321, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0460, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0578, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0707, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0379, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0636, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0568, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0411, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0463, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0445, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0269, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0622, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0619, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0446, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0394, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0405, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0327, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0561, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0436, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0431, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0433, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0394, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0331, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0253, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0445, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0361, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0476, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0425, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0348, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0332, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0435, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0267, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0294, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0347, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0589, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0141, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0421, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0702, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0162, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0067, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0465, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0420, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0385, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0223, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0285, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0461, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0452, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0407, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0477, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0482, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0315, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0450, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0161, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0493, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0111, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0174, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0409, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0291, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0302, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0032, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0424, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0286, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0282, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0176, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0121, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0496, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0420, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0318, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0351, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0091, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0368, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0307, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0235, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0074, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0181, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0118, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0053, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0246, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0229, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0203, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0147, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0008, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0140, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0280, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0182, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0093, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0213, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0216, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0282, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0131, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0077, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9992, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0138, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0177, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0174, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0230, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0046, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0076, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0369, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0063, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0196, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0295, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0176, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0138, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0110, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0131, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0193, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9919, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9957, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9919, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9991, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9991, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0182, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0053, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9910, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9974, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0089, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9937, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0007, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0066, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0156, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9989, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9935, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0013, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0146, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0244, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9906, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0147, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9931, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0133, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0096, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9943, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0203, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9962, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0066, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0153, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9922, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0191, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0291, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9964, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0054, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0131, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0052, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0055, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9983, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0288, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0211, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0049, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9982, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0078, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0184, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9975, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9822, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0034, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9996, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9950, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0069, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9914, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0022, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9944, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9840, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9870, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0106, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9852, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0120, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9843, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0000, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9953, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0036, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0223, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0057, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0046, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0126, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0067, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0076, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0096, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0123, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0214, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0076, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0113, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0052, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0015, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0144, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0012, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0184, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9974, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9867, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0020, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9987, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0078, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9977, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9885, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9927, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0013, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9888, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9939, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9990, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9912, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0021, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9894, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0106, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9975, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9824, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9994, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9970, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0042, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0068, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0018, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0008, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9859, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9902, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0032, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9965, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9913, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9891, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9820, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9745, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9875, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9766, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9840, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9796, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9898, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9851, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0092, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9908, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9940, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9960, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9723, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9771, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9928, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9855, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9915, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9722, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9897, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9900, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9954, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9966, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9929, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9695, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9715, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9900, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9680, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9795, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9798, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9984, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9865, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9868, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9784, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9886, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9898, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9697, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9845, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0135, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9763, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9796, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9861, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9860, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9880, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9787, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9869, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9694, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9876, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9760, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9676, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9871, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9727, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9683, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9738, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9784, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9743, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9726, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9743, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9802, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9936, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9725, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9832, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9964, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9834, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9805, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0011, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9801, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9778, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9854, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9642, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9864, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9929, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9886, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9779, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0063, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9852, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9828, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9855, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9825, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9865, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:  67%|██████████████████████▋           | 2/3 [32:22<16:14, 974.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 loss: 323.76\n",
      "tensor(0.9862, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9711, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9773, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9839, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9911, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9844, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9827, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9949, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9669, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9800, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9873, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9756, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9918, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0091, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9900, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9754, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9918, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9886, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9709, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9812, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9866, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9752, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9600, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0013, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9949, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9946, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9631, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9811, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9995, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9970, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9712, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9573, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9857, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9887, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9699, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9671, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9684, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9815, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9930, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9667, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9681, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9741, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9854, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9848, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9827, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9833, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9718, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9730, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9669, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9641, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9772, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9677, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9842, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9718, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9729, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9658, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9737, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9711, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9683, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9650, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9780, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9628, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9676, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9690, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9638, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9577, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9731, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9702, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9826, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9826, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9626, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0042, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9873, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9864, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9879, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9964, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9730, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9863, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9751, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9790, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9622, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9705, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9720, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9687, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9808, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9572, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9746, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9853, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9572, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9713, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9896, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9770, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9699, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9869, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9888, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9682, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9727, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9784, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0052, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9563, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9680, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9828, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9772, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9895, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9759, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9738, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9839, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9642, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9618, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9709, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9698, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9828, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9779, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9661, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9690, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9643, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9658, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9549, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9721, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9696, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9802, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9692, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9640, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9846, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9777, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9610, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9784, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9956, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9709, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9604, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9689, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9633, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9701, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9583, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9775, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9677, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9745, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9753, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9642, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9734, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9571, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9526, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9625, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9596, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9744, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9753, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9776, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9667, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9554, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9616, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9798, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9765, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9630, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9777, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9627, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9828, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9888, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9583, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9638, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9570, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9592, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9613, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9670, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9569, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9702, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9567, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9647, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9594, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9628, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9684, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9532, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9796, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9757, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9825, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9673, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9622, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9774, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9756, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9814, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9695, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9666, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9620, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9657, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9540, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9604, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9572, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9603, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9470, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9670, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9446, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9549, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9548, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9421, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9617, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9461, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9527, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9583, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9577, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9620, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9551, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9519, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9594, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9589, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9540, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9696, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9614, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9562, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9535, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9709, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9638, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9494, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9552, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9751, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9435, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9493, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9647, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9572, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9578, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9488, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9485, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9805, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9717, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9561, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9555, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9660, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9505, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9570, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9549, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9540, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9620, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9637, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9598, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9513, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9539, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9641, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9484, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9533, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9575, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9722, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9928, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9562, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9502, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9453, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9749, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9540, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9560, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9507, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9560, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9582, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9618, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9566, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9507, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9497, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9458, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9491, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9499, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9479, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9532, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9468, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9533, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9522, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9545, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9545, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9483, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9412, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9409, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9496, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9480, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9462, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9644, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9737, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9512, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9487, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9564, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9560, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9554, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9562, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9605, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9683, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9556, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9593, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9514, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9684, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9526, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9520, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9522, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9441, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9602, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9501, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9354, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9502, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9479, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9419, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9443, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9511, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9464, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9467, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9372, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9587, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9580, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9401, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9646, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9502, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9450, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9525, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9627, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9442, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9527, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9546, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9603, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9629, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9611, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9521, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9492, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9634, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9554, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9546, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9425, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9624, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9599, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████| 3/3 [48:09<00:00, 963.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 loss: 309.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.95\n",
      "Test accuracy: 95.51%\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "class MyViT(nn.Module):\n",
    "    def __init__(self, Dimensions, number_patchesRow,number_patchesColumn, number_blocks, Hidden_DGiven, NumberHeadsGiven, output_dimension):\n",
    "        \n",
    "        super(MyViT, self).__init__()\n",
    "        self.Dimensions = Dimensions  \n",
    "        self.number_patchesRow = number_patchesRow\n",
    "        self.number_patchesColumn=number_patchesColumn\n",
    "        self.number_blocks = number_blocks\n",
    "        self.Hidden_DGiven= Hidden_DGiven\n",
    "        self.NumberHeadsGiven = NumberHeadsGiven\n",
    "        \n",
    "        self.patch_size = (math.floor(Dimensions[1] / number_patchesRow), math.floor(Dimensions[2] / number_patchesColumn))\n",
    "        \n",
    "        self.input_d = int(Dimensions[0] * self.patch_size[0] * self.patch_size[1])\n",
    "        self.linear_mapper = nn.Linear(self.input_d, self.Hidden_DGiven)\n",
    "\n",
    "        self.class_token = nn.Parameter(torch.rand(1, self.Hidden_DGiven))\n",
    "\n",
    "        self.register_buffer(\n",
    "            \"positional_embeddings1\",\n",
    "            get_positional_embeddings1(number_patchesRow*number_patchesColumn + 1, Hidden_DGiven),\n",
    "            persistent=False,\n",
    "        )\n",
    "        \n",
    "        self.blocksA = nn.ModuleList(\n",
    "            [VisionTransformer(Hidden_DGiven, NumberHeadsGiven) for _ in range(number_blocks)]\n",
    "        )\n",
    "\n",
    "        self.mlp = nn.Sequential(nn.Linear(self.Hidden_DGiven, output_dimension), nn.Softmax(dim=-1))\n",
    "\n",
    "    def forward(self, images):        \n",
    "        n, c, h, w = images.shape\n",
    "        patches1A = images[0:n,0,0:self.patch_size[0]*self.number_patchesRow,0:self.patch_size[1]*self.number_patchesColumn]#patchify(images, self.n_patches).to(self.positional_embeddings1.device)\n",
    "        Size=64#(patches1A.size(1)*patches1A.size(2))/(self.number_patchesRow*self.number_patchesColumn)\n",
    "        #print(Size)\n",
    "        patches1=patches1A.reshape(n,self.number_patchesRow*self.number_patchesColumn,Size)\n",
    "        \n",
    "        tokens1 = self.linear_mapper(patches1)\n",
    "        tokensa = torch.cat((self.class_token.expand(n, 1, -1), tokens1), dim=1)\n",
    "\n",
    "        A    = tokensa + self.positional_embeddings1.repeat(n, 1, 1) \n",
    "\n",
    "        for block in self.blocksA:\n",
    "            A = block(A)\n",
    "        \n",
    "        output = torch.ones(n,self.Hidden_DGiven)\n",
    "        \n",
    "        output[0:n,self.Hidden_DGiven*0:self.Hidden_DGiven]  = A[:, 0]\n",
    "\n",
    "        return self.mlp(output)\n",
    "\n",
    "\n",
    "def main():\n",
    "    \n",
    "    transform = ToTensor()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = MyViT(\n",
    "        (1, 128,40), number_patchesRow=16, number_patchesColumn=5, number_blocks=2, Hidden_DGiven=5, NumberHeadsGiven=5, output_dimension=5\n",
    "    ).to(device)\n",
    "\n",
    "    NUMBER_EPOCHS = 3\n",
    "    LearningRate = 0.003\n",
    "\n",
    "    # Training Data loop\n",
    "    optimizer = Adam(model.parameters(), lr= LearningRate)\n",
    "    criterion = CrossEntropyLoss()\n",
    "\n",
    "    for epoch in trange(NUMBER_EPOCHS, desc=\"Training\"):\n",
    "        training_loss = 0.0\n",
    "        for batch in range(0,Length,Stride):\n",
    "            y = y_train[batch:batch+Stride]\n",
    "            x = X_train[batch:batch+Stride,0:1,0:128,0:40]\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            y_hat = model(x)\n",
    "            \n",
    "            loss = criterion(y_hat, y.type(torch.LongTensor))\n",
    "            print(loss)\n",
    "            training_loss += loss.detach().cpu().item()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        print(f\"Epoch {epoch + 1}/{NUMBER_EPOCHS} loss: {training_loss:.2f}\")\n",
    "\n",
    "    # Testing loop with testing data\n",
    "    with torch.no_grad():\n",
    "        correct, total = 0, 0\n",
    "        test_loss = 0.0\n",
    "        y = y_test\n",
    "        x = X_test\n",
    "\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        y_hat = model(x)\n",
    "        loss = criterion(y_hat, y.type(torch.LongTensor))\n",
    "\n",
    "        test_loss += loss.detach().cpu().item()\n",
    "\n",
    "        correct += torch.sum(torch.argmax(y_hat, dim=1) == y).detach().cpu().item()\n",
    "        total += len(x)\n",
    "        print(f\"Test loss: {test_loss:.2f}\")\n",
    "        print(f\"Test accuracy: {correct / total * 100:.2f}%\")\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bf539c5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:   0%|                                           | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.6107, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6095, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5972, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6014, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5966, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5942, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5905, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5875, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5914, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5816, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5811, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5768, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5758, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5723, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5601, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5638, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5557, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5549, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5481, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5334, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5370, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5283, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5180, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5259, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5078, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5004, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4988, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4973, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4796, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4965, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4690, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4658, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4744, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4618, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4589, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4453, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4734, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4531, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4489, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4444, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4470, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4445, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4398, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4516, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4554, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4530, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4488, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4278, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4237, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4433, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4156, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4386, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4421, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4372, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4386, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4372, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4285, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4314, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4317, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4328, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4277, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4350, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4184, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4231, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4454, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4402, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4399, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4229, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4220, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4317, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4331, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4389, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4403, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4341, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4349, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4292, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4135, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4154, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4159, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4139, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4241, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4248, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4190, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4067, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4115, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4001, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4178, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4079, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4031, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3827, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3873, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3911, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3621, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3723, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3625, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3425, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3329, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3361, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3338, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3286, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3383, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3285, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3100, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3124, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3192, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3002, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2947, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2821, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2771, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2814, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2565, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2661, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2627, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2711, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2554, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2523, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2381, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2297, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2390, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2341, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2289, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2262, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2184, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1975, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2164, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1867, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2004, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2219, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1791, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1794, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1798, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1611, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1670, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1591, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1785, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1576, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1557, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1495, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1426, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1676, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1457, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1430, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1467, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1375, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1385, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1343, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1307, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1142, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1467, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1223, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1339, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1449, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1143, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1412, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1193, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1232, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0968, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1037, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1149, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0973, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1007, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1023, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0983, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0889, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0912, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0689, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0840, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0721, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0806, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0954, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0684, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0648, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0842, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0763, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0639, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0756, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0777, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0651, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0650, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0667, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0575, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0550, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0603, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0388, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0489, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0449, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0505, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0369, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0655, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0489, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0449, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0395, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0371, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0387, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0331, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0397, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0343, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0268, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0195, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0217, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0434, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0392, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0304, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0349, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0264, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0281, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0194, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0284, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0341, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0251, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0129, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0169, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0166, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0183, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0137, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0239, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0138, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0078, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0162, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0259, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0263, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0077, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0184, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0217, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0256, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0233, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9977, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0264, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0082, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0008, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9935, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0167, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0068, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0047, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0034, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0027, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0042, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9997, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0019, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0108, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0017, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0045, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0039, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9892, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9942, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9923, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0024, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9881, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9908, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0026, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9917, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0105, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9938, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9909, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9948, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9935, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9866, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9962, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0063, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9909, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9906, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9964, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9953, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9828, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9845, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0022, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9861, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9760, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9875, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9927, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0029, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0009, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9790, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9868, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9945, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9929, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9967, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9933, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0061, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9926, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0041, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9778, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9903, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0099, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9800, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9963, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9895, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9868, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9922, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9730, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9995, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9985, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9834, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9793, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9968, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9921, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9879, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9859, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9952, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9959, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9798, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0013, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9872, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9874, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9839, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9959, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9969, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9928, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9903, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9754, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9821, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9995, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9735, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9723, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9915, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9949, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9842, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9878, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9856, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9839, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:  33%|███████████▎                      | 1/3 [15:59<31:58, 959.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 loss: 380.46\n",
      "tensor(0.9784, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9780, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9846, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9747, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9715, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9797, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9827, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9940, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9816, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9867, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9769, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9726, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9913, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9972, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9765, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9698, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9794, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9900, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9991, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9737, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9861, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9824, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9700, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9816, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9686, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9767, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9829, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9699, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9655, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9724, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9814, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9907, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9728, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9773, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9823, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9917, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9723, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9871, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9742, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9598, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9803, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9656, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9814, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0002, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9744, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9853, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9690, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9720, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9855, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9761, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9675, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9748, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9844, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9790, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9777, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9736, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9710, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9919, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9716, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9797, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9815, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9881, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9869, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9886, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9756, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9832, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9849, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9673, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9825, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9703, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9850, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9854, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9728, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9895, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9729, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9904, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9877, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9872, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9832, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9799, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9899, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9757, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9945, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9680, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9960, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9812, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9809, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9772, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9777, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9866, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9680, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9911, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9727, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9873, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9698, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9698, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9799, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9822, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9791, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9896, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9697, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9778, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9661, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9827, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9682, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9678, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9812, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9751, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9694, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9876, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9721, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9789, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9695, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9791, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9788, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9756, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9690, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9614, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9692, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9808, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9729, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9745, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9836, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9697, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9675, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9734, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9724, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9777, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9668, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9677, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9807, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9701, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9716, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9822, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9819, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9778, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9741, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9811, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9743, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9714, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9657, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9673, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9705, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9754, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9873, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9782, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9738, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9719, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9691, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9732, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9797, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9843, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9574, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9679, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9758, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9846, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9673, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9685, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9722, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9686, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9784, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9674, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9630, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9748, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9661, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9535, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9697, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9791, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9795, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9819, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9653, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9726, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9844, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9723, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9761, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9727, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9665, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9635, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9670, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9701, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9768, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9700, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9718, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9587, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9736, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9589, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9732, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9680, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9741, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9732, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9790, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9718, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9610, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9679, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9637, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9720, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9744, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9711, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9602, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9639, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9745, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9681, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9771, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9731, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9671, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9673, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9766, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9626, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9600, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9715, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9632, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9681, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9598, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9692, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9608, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9788, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9595, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9644, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9762, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9696, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9768, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9687, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9679, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9754, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9749, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9694, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9579, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9870, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9642, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9696, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9535, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9731, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9684, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9671, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9528, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9693, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9681, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9700, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9688, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9755, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9717, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9742, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9717, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9527, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9600, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9590, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9642, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9615, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9606, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9789, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9655, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9681, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9627, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9655, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9728, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9645, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9692, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9756, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9794, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9622, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9590, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9758, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9673, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9534, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9584, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9820, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9643, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9537, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9563, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9638, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9764, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9813, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9586, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9554, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9614, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9712, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9750, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9595, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9818, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9569, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9661, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9564, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9674, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9703, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9548, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9758, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9658, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9613, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9674, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9558, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9793, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9645, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9631, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9663, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9802, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9670, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9702, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9636, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9672, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9684, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9663, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9744, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9712, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9633, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9607, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9768, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9671, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9670, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9650, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9645, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9742, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9777, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9576, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9648, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9611, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9770, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9568, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9674, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9645, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9630, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:  67%|██████████████████████▋           | 2/3 [31:44<15:51, 951.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 loss: 311.31\n",
      "tensor(0.9565, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9608, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9697, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9620, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9610, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9616, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9646, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9744, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9640, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9702, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9541, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9567, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9655, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9699, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9580, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9564, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9606, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9768, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9879, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9570, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9556, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9647, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9646, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9673, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9582, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9576, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9551, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9572, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9517, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9608, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9502, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9627, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9543, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9584, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9596, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9624, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9591, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9646, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9598, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9502, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9616, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9429, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9624, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9712, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9484, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9678, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9565, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9593, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9659, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9589, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9529, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9508, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9638, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9645, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9546, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9528, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9586, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9649, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9536, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9610, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9664, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9677, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9626, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9621, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9515, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9530, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9669, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9501, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9704, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9574, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9655, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9627, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9567, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9689, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9585, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9823, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9681, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9652, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9699, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9722, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9823, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9766, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9727, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9578, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9699, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9516, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9601, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9592, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9569, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9659, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9532, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9715, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9548, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9624, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9608, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9510, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9611, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9611, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9622, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9744, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9551, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9556, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9474, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9685, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9526, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9559, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9657, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9561, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9528, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9683, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9558, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9636, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9509, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9625, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9678, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9609, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9633, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9507, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9621, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9656, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9530, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9564, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9728, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9629, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9497, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9577, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9602, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9614, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9545, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9604, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9608, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9511, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9513, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9630, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9626, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9695, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9552, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9599, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9536, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9557, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9472, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9452, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9527, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9599, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9685, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9560, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9610, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9535, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9605, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9570, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9618, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9689, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9500, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9514, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9593, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9633, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9514, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9580, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9579, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9517, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9513, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9503, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9512, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9569, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9553, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9472, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9519, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9627, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9564, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9660, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9466, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9647, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9690, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9573, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9642, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9539, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9509, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9528, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9575, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9546, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9584, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9531, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9597, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9556, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9589, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9448, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9521, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9493, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9620, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9525, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9619, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9575, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9556, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9503, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9495, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9563, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9565, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9562, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9521, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9544, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9602, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9507, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9659, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9567, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9579, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9633, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9705, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9519, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9491, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9563, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9458, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9523, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9457, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9530, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9505, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9575, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9527, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9523, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9556, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9626, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9556, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9542, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9544, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9613, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9614, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9506, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9502, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9748, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9453, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9578, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9488, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9656, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9615, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9539, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9453, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9574, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9657, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9609, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9561, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9626, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9538, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9644, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9626, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9487, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9480, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9500, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9486, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9564, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9440, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9628, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9551, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9599, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9457, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9532, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9589, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9524, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9469, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9488, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9646, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9494, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9550, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9597, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9601, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9400, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9497, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9681, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9516, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9423, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9489, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9552, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9629, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9615, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9479, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9485, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9491, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9572, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9631, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9586, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9790, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9496, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9510, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9468, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9586, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9654, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9574, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9593, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9600, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9510, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9533, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9476, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9661, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9582, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9568, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9515, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9659, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9543, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9583, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9584, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9618, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9587, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9582, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9597, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9601, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9540, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9435, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9536, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9586, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9615, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9486, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9526, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9425, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9567, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9446, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9547, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9501, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9589, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9492, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9610, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9587, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9493, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████| 3/3 [47:26<00:00, 948.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 loss: 306.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.95\n",
      "Test accuracy: 95.20%\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "class MyViT(nn.Module):\n",
    "    def __init__(self, Dimensions, number_patchesRow,number_patchesColumn, number_blocks, Hidden_DGiven, NumberHeadsGiven, output_dimension):\n",
    "        \n",
    "        super(MyViT, self).__init__()\n",
    "        self.Dimensions = Dimensions  \n",
    "        self.number_patchesRow = number_patchesRow\n",
    "        self.number_patchesColumn=number_patchesColumn\n",
    "        self.number_blocks = number_blocks\n",
    "        self.Hidden_DGiven= Hidden_DGiven\n",
    "        self.NumberHeadsGiven = NumberHeadsGiven\n",
    "        \n",
    "        self.patch_size = (math.floor(Dimensions[1] / number_patchesRow), math.floor(Dimensions[2] / number_patchesColumn))\n",
    "        \n",
    "        self.input_d = int(Dimensions[0] * self.patch_size[0] * self.patch_size[1])\n",
    "        self.linear_mapper = nn.Linear(self.input_d, self.Hidden_DGiven)\n",
    "\n",
    "        self.class_token = nn.Parameter(torch.rand(1, self.Hidden_DGiven))\n",
    "\n",
    "        self.register_buffer(\n",
    "            \"positional_embeddings1\",\n",
    "            get_positional_embeddings2(number_patchesRow*number_patchesColumn + 1, Hidden_DGiven),\n",
    "            persistent=False,\n",
    "        )\n",
    "        \n",
    "        self.blocksA = nn.ModuleList(\n",
    "            [VisionTransformer(Hidden_DGiven, NumberHeadsGiven) for _ in range(number_blocks)]\n",
    "        )\n",
    "\n",
    "        self.mlp = nn.Sequential(nn.Linear(self.Hidden_DGiven, output_dimension), nn.Softmax(dim=-1))\n",
    "\n",
    "    def forward(self, images):        \n",
    "        n, c, h, w = images.shape\n",
    "        patches1A = images[0:n,0,0:self.patch_size[0]*self.number_patchesRow,0:self.patch_size[1]*self.number_patchesColumn]#patchify(images, self.n_patches).to(self.positional_embeddings1.device)\n",
    "        Size=64#(patches1A.size(1)*patches1A.size(2))/(self.number_patchesRow*self.number_patchesColumn)\n",
    "        #print(Size)\n",
    "        patches1=patches1A.reshape(n,self.number_patchesRow*self.number_patchesColumn,Size)\n",
    "        \n",
    "        tokens1 = self.linear_mapper(patches1)\n",
    "        tokensa = torch.cat((self.class_token.expand(n, 1, -1), tokens1), dim=1)\n",
    "\n",
    "        A    = tokensa + self.positional_embeddings1.repeat(n, 1, 1) \n",
    "\n",
    "        for block in self.blocksA:\n",
    "            A = block(A)\n",
    "        \n",
    "        output = torch.ones(n,self.Hidden_DGiven)\n",
    "        \n",
    "        output[0:n,self.Hidden_DGiven*0:self.Hidden_DGiven]  = A[:, 0]\n",
    "\n",
    "        return self.mlp(output)\n",
    "\n",
    "\n",
    "def main():\n",
    "    \n",
    "    transform = ToTensor()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = MyViT(\n",
    "        (1, 128,40), number_patchesRow=16, number_patchesColumn=5, number_blocks=2, Hidden_DGiven=5, NumberHeadsGiven=5, output_dimension=5\n",
    "    ).to(device)\n",
    "\n",
    "    NUMBER_EPOCHS = 3\n",
    "    LearningRate = 0.003\n",
    "\n",
    "    # Training Data loop\n",
    "    optimizer = Adam(model.parameters(), lr= LearningRate)\n",
    "    criterion = CrossEntropyLoss()\n",
    "\n",
    "    for epoch in trange(NUMBER_EPOCHS, desc=\"Training\"):\n",
    "        training_loss = 0.0\n",
    "        for batch in range(0,Length,Stride):\n",
    "            y = y_train[batch:batch+Stride]\n",
    "            x = X_train[batch:batch+Stride,0:1,0:128,0:40]\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            y_hat = model(x)\n",
    "            \n",
    "            loss = criterion(y_hat, y.type(torch.LongTensor))\n",
    "            print(loss)\n",
    "            training_loss += loss.detach().cpu().item()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        print(f\"Epoch {epoch + 1}/{NUMBER_EPOCHS} loss: {training_loss:.2f}\")\n",
    "\n",
    "    # Testing loop with testing data\n",
    "    with torch.no_grad():\n",
    "        correct, total = 0, 0\n",
    "        test_loss = 0.0\n",
    "        y = y_test\n",
    "        x = X_test\n",
    "\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        y_hat = model(x)\n",
    "        loss = criterion(y_hat, y.type(torch.LongTensor))\n",
    "\n",
    "        test_loss += loss.detach().cpu().item()\n",
    "\n",
    "        correct += torch.sum(torch.argmax(y_hat, dim=1) == y).detach().cpu().item()\n",
    "        total += len(x)\n",
    "        print(f\"Test loss: {test_loss:.2f}\")\n",
    "        print(f\"Test accuracy: {correct / total * 100:.2f}%\")\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4a73e44c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:   0%|                                           | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.6349, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6238, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6250, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6180, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6193, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6143, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6220, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6144, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6070, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6111, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6078, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6098, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6081, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6063, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6071, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6065, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6066, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6041, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6045, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6043, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6022, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6023, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6015, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6016, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5992, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5988, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5976, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5970, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5940, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5961, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5921, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5924, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5910, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5882, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5864, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5839, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5829, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5828, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5824, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5775, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5713, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5737, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5685, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5682, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5686, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5605, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5546, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5448, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5350, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5418, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5209, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5263, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5240, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5190, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5082, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5007, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4922, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4891, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4779, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4767, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4707, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4630, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4534, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4527, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4648, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4531, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4532, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4426, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4309, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4317, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4446, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4463, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4443, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4434, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4436, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4379, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4190, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4178, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4138, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4251, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4298, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4202, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4279, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4141, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4208, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4127, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4403, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4350, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4201, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4032, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4131, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4220, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4014, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4159, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3983, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3837, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3775, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3728, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3770, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3549, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3734, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3542, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3295, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3397, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3501, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3188, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3180, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3005, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3053, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3092, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2696, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2961, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2869, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2994, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2911, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2869, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2822, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2673, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2830, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2764, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2802, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2839, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2635, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2676, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2815, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2636, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2720, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2930, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2487, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2587, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2561, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2581, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2509, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2543, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2724, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2619, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2451, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2383, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2460, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2561, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2531, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2500, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2527, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2380, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2453, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2410, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2341, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2344, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2493, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2243, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2285, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2419, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2015, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2300, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2127, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2234, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1984, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2094, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2088, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1833, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1974, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1859, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1735, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1688, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1627, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1348, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1420, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1287, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1174, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1225, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1095, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1086, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1025, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0946, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0720, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0830, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0822, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0659, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0624, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0517, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0489, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0430, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0521, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0412, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0478, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0260, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0272, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0294, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0442, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0231, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0270, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0261, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0186, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0234, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0059, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0119, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0170, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0010, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0085, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0076, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9953, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0030, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0240, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9989, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0024, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9941, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9984, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9866, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9884, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9876, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0034, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9743, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9958, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9938, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9797, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9929, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9874, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9752, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9788, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9850, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9796, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9815, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9873, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9687, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9812, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9768, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9740, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9861, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9741, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9743, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9690, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9707, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9669, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9739, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9674, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9679, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9564, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9680, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9769, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9667, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9589, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9632, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9686, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9568, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9619, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9618, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9696, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9623, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9634, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9537, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9595, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9627, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9537, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9536, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9653, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9583, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9445, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9547, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9617, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9488, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9656, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9580, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9563, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9552, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9442, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9692, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9771, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9491, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9475, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9612, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9526, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9580, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9505, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9370, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9527, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9471, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9458, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9545, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9531, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9460, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9522, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9415, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9442, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9558, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9430, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9436, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9510, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9543, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9468, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9399, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9434, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9425, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9343, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9429, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9405, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9413, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9438, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9401, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9461, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9408, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9457, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9419, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9343, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9379, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9383, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9427, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9486, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9403, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9291, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9449, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9441, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9390, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9416, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9384, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9371, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9537, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9409, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9365, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9377, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9393, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:  33%|███████████▎                      | 1/3 [15:48<31:36, 948.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 loss: 385.84\n",
      "tensor(0.9354, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9291, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9335, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9362, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9331, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9335, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9317, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9521, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9285, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9348, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9439, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9367, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9370, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9503, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9397, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9303, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9363, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9430, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9386, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9355, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9296, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9285, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9352, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9327, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9373, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9359, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9291, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9329, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9311, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9330, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9318, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9315, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9348, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9280, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9359, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9346, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9329, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9371, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9313, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9250, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9395, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9320, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9308, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9336, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9253, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9291, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9299, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9273, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9216, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9275, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9283, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9338, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9291, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9244, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9280, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9279, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9304, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9233, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9239, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9262, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9357, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9253, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9217, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9256, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9211, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9254, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9231, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9270, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9266, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9245, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9318, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9319, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9281, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9309, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9316, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9301, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9376, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9313, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9272, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9278, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9228, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9296, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9215, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9274, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9243, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9229, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9285, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9255, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9241, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9207, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9299, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9295, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9266, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9207, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9317, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9235, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9231, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9246, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9203, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9259, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9227, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9165, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9300, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9287, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9215, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9274, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9286, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9232, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9197, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9317, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9232, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9186, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9164, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9226, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9235, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9228, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9318, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9217, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9260, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9244, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9233, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9219, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9314, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9237, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9213, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9180, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9304, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9288, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9285, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9266, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9257, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9220, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9241, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9181, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9282, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9206, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9213, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9260, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9211, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9197, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9265, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9324, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9240, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9234, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9226, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9328, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9230, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9242, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9197, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9185, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9202, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9205, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9183, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9265, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9197, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9259, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9205, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9212, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9177, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9179, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9220, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9165, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9199, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9205, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9218, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9201, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9156, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9219, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9269, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9213, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9193, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9227, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9348, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9244, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9155, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9250, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9265, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9234, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9211, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9278, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9211, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9195, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9253, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9148, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9230, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9191, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9220, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9223, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9167, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9241, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9270, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9266, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9156, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9350, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9300, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9226, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9212, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9312, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9446, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9269, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9184, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9388, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9423, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9246, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9172, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9164, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9329, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9326, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9266, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9202, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9235, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9236, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9269, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9281, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9266, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9249, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9160, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9183, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9230, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9209, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9194, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9247, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9234, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9233, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9180, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9204, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9167, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9202, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9188, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9190, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9174, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9213, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9179, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9215, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9129, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9174, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9146, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9248, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9236, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9199, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9207, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9199, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9249, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9215, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9184, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9280, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9234, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9221, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9196, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9174, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9250, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9313, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9185, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9179, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9193, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9235, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9252, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9233, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9236, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9135, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9187, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9227, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9220, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9175, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9203, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9182, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9189, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9170, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9180, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9216, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9209, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9190, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9201, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9170, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9212, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9222, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9184, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9232, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9256, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9168, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9177, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9172, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9161, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9254, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9204, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9173, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9183, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9218, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9184, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9145, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9188, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9178, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9134, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9163, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9145, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9168, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9205, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9183, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9176, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9126, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9132, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9164, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9182, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9172, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9185, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9157, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9202, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9211, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9161, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9164, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9198, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9226, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9184, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9207, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9131, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9197, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9202, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9199, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9199, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9182, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:  67%|██████████████████████▋           | 2/3 [31:31<15:45, 945.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 loss: 295.83\n",
      "tensor(0.9156, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9120, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9154, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9205, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9159, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9211, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9135, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9214, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9155, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9179, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9160, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9217, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9173, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9176, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9145, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9192, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9201, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9177, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9179, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9199, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9127, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9175, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9165, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9161, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9161, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9158, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9144, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9172, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9177, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9141, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9150, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9151, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9153, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9159, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9124, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9182, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9157, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9168, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9171, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9152, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9241, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9190, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9143, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9153, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9107, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9158, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9162, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9116, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9113, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9144, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9199, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9172, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9129, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9138, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9180, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9164, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9173, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9135, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9154, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9128, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9177, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9166, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9140, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9155, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9114, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9128, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9125, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9153, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9140, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9158, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9176, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9134, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9162, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9168, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9172, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9177, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9158, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9138, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9145, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9126, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9113, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9172, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9118, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9161, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9140, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9119, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9179, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9143, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9134, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9116, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9178, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9172, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9142, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9123, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9158, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9120, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9146, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9135, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9147, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9169, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9102, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9117, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9160, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9172, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9143, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9113, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9146, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9147, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9118, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9167, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9112, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9084, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9106, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9173, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9166, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9125, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9180, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9127, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9169, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9146, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9138, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9136, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9194, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9117, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9118, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9131, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9181, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9161, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9212, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9155, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9166, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9118, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9174, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9092, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9178, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9159, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9155, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9128, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9131, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9137, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9132, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9187, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9128, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9120, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9157, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9233, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9149, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9140, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9147, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9139, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9148, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9144, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9116, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9185, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9127, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9128, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9163, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9145, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9111, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9144, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9146, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9096, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9120, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9124, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9115, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9136, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9121, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9146, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9180, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9105, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9140, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9141, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9164, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9123, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9103, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9117, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9183, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9131, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9130, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9180, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9157, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9132, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9146, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9119, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9214, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9126, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9116, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9173, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9133, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9169, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9223, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9188, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9128, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9192, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9198, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9221, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9146, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9153, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9313, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9240, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9122, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9198, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9255, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9261, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9151, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9090, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9180, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9295, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9251, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9182, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9152, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9143, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9204, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9264, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9303, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9166, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9139, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9136, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9145, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9224, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9208, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9175, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9185, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9191, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9109, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9157, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9117, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9160, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9123, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9127, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9136, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9155, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9114, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9126, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9084, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9109, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9099, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9161, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9155, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9143, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9162, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9143, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9178, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9130, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9115, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9192, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9175, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9242, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9172, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9137, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9126, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9165, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9120, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9130, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9200, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9143, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9161, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9131, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9131, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9115, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9147, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9164, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9157, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9114, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9138, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9107, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9145, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9103, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9126, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9202, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9172, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9124, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9145, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9110, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9123, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9163, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9131, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9173, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9202, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9097, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9114, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9117, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9106, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9176, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9128, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9124, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9125, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9137, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9126, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9085, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9132, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9127, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9083, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9157, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9111, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9127, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9157, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9151, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9145, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9094, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9113, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9107, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9124, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9163, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9124, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9098, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9133, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9152, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9097, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9133, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9112, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9164, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9133, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9094, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9113, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9143, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9135, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9112, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9112, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9155, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████| 3/3 [47:23<00:00, 947.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 loss: 292.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.91\n",
      "Test accuracy: 99.36%\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "class MyViT(nn.Module):\n",
    "    def __init__(self, Dimensions, number_patchesRow,number_patchesColumn, number_blocks, Hidden_DGiven, NumberHeadsGiven, output_dimension):\n",
    "        \n",
    "        super(MyViT, self).__init__()\n",
    "        self.Dimensions = Dimensions  \n",
    "        self.number_patchesRow = number_patchesRow\n",
    "        self.number_patchesColumn=number_patchesColumn\n",
    "        self.number_blocks = number_blocks\n",
    "        self.Hidden_DGiven= Hidden_DGiven\n",
    "        self.NumberHeadsGiven = NumberHeadsGiven\n",
    "        \n",
    "        self.patch_size = (math.floor(Dimensions[1] / number_patchesRow), math.floor(Dimensions[2] / number_patchesColumn))\n",
    "        \n",
    "        self.input_d = int(Dimensions[0] * self.patch_size[0] * self.patch_size[1])\n",
    "        self.linear_mapper = nn.Linear(self.input_d, self.Hidden_DGiven)\n",
    "\n",
    "        self.class_token = nn.Parameter(torch.rand(1, self.Hidden_DGiven))\n",
    "\n",
    "        self.register_buffer(\n",
    "            \"positional_embeddings1\",\n",
    "            get_positional_embeddings3(number_patchesRow*number_patchesColumn + 1, Hidden_DGiven),\n",
    "            persistent=False,\n",
    "        )\n",
    "        \n",
    "        self.blocksA = nn.ModuleList(\n",
    "            [VisionTransformer(Hidden_DGiven, NumberHeadsGiven) for _ in range(number_blocks)]\n",
    "        )\n",
    "\n",
    "        self.mlp = nn.Sequential(nn.Linear(self.Hidden_DGiven, output_dimension), nn.Softmax(dim=-1))\n",
    "\n",
    "    def forward(self, images):        \n",
    "        n, c, h, w = images.shape\n",
    "        patches1A = images[0:n,0,0:self.patch_size[0]*self.number_patchesRow,0:self.patch_size[1]*self.number_patchesColumn]#patchify(images, self.n_patches).to(self.positional_embeddings1.device)\n",
    "        Size=64#(patches1A.size(1)*patches1A.size(2))/(self.number_patchesRow*self.number_patchesColumn)\n",
    "        #print(Size)\n",
    "        patches1=patches1A.reshape(n,self.number_patchesRow*self.number_patchesColumn,Size)\n",
    "        \n",
    "        tokens1 = self.linear_mapper(patches1)\n",
    "        tokensa = torch.cat((self.class_token.expand(n, 1, -1), tokens1), dim=1)\n",
    "\n",
    "        A    = tokensa + self.positional_embeddings1.repeat(n, 1, 1) \n",
    "\n",
    "        for block in self.blocksA:\n",
    "            A = block(A)\n",
    "        \n",
    "        output = torch.ones(n,self.Hidden_DGiven)\n",
    "        \n",
    "        output[0:n,self.Hidden_DGiven*0:self.Hidden_DGiven]  = A[:, 0]\n",
    "\n",
    "        return self.mlp(output)\n",
    "\n",
    "\n",
    "def main():\n",
    "    \n",
    "    transform = ToTensor()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = MyViT(\n",
    "        (1, 128,40), number_patchesRow=16, number_patchesColumn=5, number_blocks=2, Hidden_DGiven=5, NumberHeadsGiven=5, output_dimension=5\n",
    "    ).to(device)\n",
    "\n",
    "    NUMBER_EPOCHS = 3\n",
    "    LearningRate = 0.003\n",
    "\n",
    "    # Training Data loop\n",
    "    optimizer = Adam(model.parameters(), lr= LearningRate)\n",
    "    criterion = CrossEntropyLoss()\n",
    "\n",
    "    for epoch in trange(NUMBER_EPOCHS, desc=\"Training\"):\n",
    "        training_loss = 0.0\n",
    "        for batch in range(0,Length,Stride):\n",
    "            y = y_train[batch:batch+Stride]\n",
    "            x = X_train[batch:batch+Stride,0:1,0:128,0:40]\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            y_hat = model(x)\n",
    "            \n",
    "            loss = criterion(y_hat, y.type(torch.LongTensor))\n",
    "            print(loss)\n",
    "            training_loss += loss.detach().cpu().item()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        print(f\"Epoch {epoch + 1}/{NUMBER_EPOCHS} loss: {training_loss:.2f}\")\n",
    "\n",
    "    # Testing loop with testing data\n",
    "    with torch.no_grad():\n",
    "        correct, total = 0, 0\n",
    "        test_loss = 0.0\n",
    "        y = y_test\n",
    "        x = X_test\n",
    "\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        y_hat = model(x)\n",
    "        loss = criterion(y_hat, y.type(torch.LongTensor))\n",
    "\n",
    "        test_loss += loss.detach().cpu().item()\n",
    "\n",
    "        correct += torch.sum(torch.argmax(y_hat, dim=1) == y).detach().cpu().item()\n",
    "        total += len(x)\n",
    "        print(f\"Test loss: {test_loss:.2f}\")\n",
    "        print(f\"Test accuracy: {correct / total * 100:.2f}%\")\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "96986a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:   0%|                                           | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.6132, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6117, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6052, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6064, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6040, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6014, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6012, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6013, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5948, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5960, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5928, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5934, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5887, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5860, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5859, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5832, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5788, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5743, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5732, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5736, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5671, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5659, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5634, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5590, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5536, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5538, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5458, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5405, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5283, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5353, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5241, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5256, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5186, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5086, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5024, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5001, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4895, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4892, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4920, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4819, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4647, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4713, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4595, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4555, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4609, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4512, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4422, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4320, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4232, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4450, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4176, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4282, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4319, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4322, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4256, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4278, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4177, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4155, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4076, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4112, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4138, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4025, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4023, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3980, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4104, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4013, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3972, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3930, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3777, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3709, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3888, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3807, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3748, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3773, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3646, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3635, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3334, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3288, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3226, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3267, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3288, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2960, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3056, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2930, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2932, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2838, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3139, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3096, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2857, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2673, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2831, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2941, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2727, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2798, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2747, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2602, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2584, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2634, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2656, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2537, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2755, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2759, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2590, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2620, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2789, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2598, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2584, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2472, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2505, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2489, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2301, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2458, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2387, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2559, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2529, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2451, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2455, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2340, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2406, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2360, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2401, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2434, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2273, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2301, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2376, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2179, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2302, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2380, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1989, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2118, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2044, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2020, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2134, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1975, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2089, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2060, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1875, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1881, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1898, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1835, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1703, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1704, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1763, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1572, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1604, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1455, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1403, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1433, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1445, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1310, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1209, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1285, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0838, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1089, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0869, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1090, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0877, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0794, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0718, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0712, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0657, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0542, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0438, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0475, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0313, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0233, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0151, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0174, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0118, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0026, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9910, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9858, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9809, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9877, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9750, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9794, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9676, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9795, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9736, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9615, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9774, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9640, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9706, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9566, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9569, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9593, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9569, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9565, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9455, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9501, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9569, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9522, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9510, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9536, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9428, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9498, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9494, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9437, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9456, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9376, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9368, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9471, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9524, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9347, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9428, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9360, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9365, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9412, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9392, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9389, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9278, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9364, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9328, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9371, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9337, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9260, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9436, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9316, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9281, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9283, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9317, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9251, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9305, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9284, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9302, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9324, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9265, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9246, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9310, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9292, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9274, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9408, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9399, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9294, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9294, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9211, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9243, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9317, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9285, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9284, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9291, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9246, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9291, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9299, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9295, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9186, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9249, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9215, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9258, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9187, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9231, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9190, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9205, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9161, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9262, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9248, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9247, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9279, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9191, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9227, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9239, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9331, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9225, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9157, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9262, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9252, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9277, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9205, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9216, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9247, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9293, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9218, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9302, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9218, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9224, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9235, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9274, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9256, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9239, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9253, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9264, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9224, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9266, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9271, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9174, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9208, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9228, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9215, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9216, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9149, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9177, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9197, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9203, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9150, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9175, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9177, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9193, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9183, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9216, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9179, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9161, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9208, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9172, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9192, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9152, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9199, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9192, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9164, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9191, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9186, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9227, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9208, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9217, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9181, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9214, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9250, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9157, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9174, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9156, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9187, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:  33%|███████████▎                      | 1/3 [15:45<31:30, 945.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 loss: 366.37\n",
      "tensor(0.9136, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9175, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9140, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9198, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9209, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9163, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9197, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9227, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9153, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9249, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9205, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9165, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9171, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9240, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9245, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9186, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9202, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9169, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9190, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9214, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9251, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9121, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9218, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9176, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9202, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9242, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9232, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9187, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9167, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9200, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9166, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9201, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9181, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9156, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9128, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9195, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9199, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9156, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9202, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9177, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9133, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9180, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9200, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9242, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9134, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9219, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9198, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9190, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9144, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9177, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9209, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9277, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9199, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9187, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9188, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9166, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9199, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9202, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9162, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9152, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9256, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9172, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9125, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9193, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9144, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9162, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9188, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9213, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9239, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9173, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9196, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9131, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9161, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9171, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9175, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9216, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9170, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9169, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9171, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9212, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9151, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9208, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9188, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9135, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9262, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9189, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9189, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9235, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9170, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9158, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9170, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9217, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9255, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9144, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9231, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9169, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9147, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9146, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9165, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9157, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9168, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9139, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9157, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9190, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9160, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9204, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9253, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9190, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9153, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9253, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9146, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9179, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9181, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9190, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9166, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9205, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9180, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9178, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9251, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9155, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9165, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9146, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9247, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9231, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9151, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9182, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9234, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9190, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9227, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9211, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9208, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9199, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9220, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9128, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9169, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9138, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9180, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9213, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9194, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9110, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9200, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9207, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9175, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9173, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9159, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9162, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9133, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9126, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9163, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9190, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9188, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9220, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9106, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9143, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9194, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9169, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9233, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9135, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9155, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9111, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9128, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9129, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9155, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9118, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9150, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9146, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9207, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9153, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9125, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9184, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9159, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9131, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9142, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9175, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9129, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9131, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9154, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9158, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9141, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9141, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9152, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9154, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9183, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9125, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9127, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9170, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9178, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9121, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9110, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9148, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9190, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9146, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9142, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9173, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9132, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9182, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9168, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9134, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9217, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9139, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9134, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9160, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9224, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9159, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9126, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9127, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9123, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9174, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9152, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9184, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9131, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9144, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9142, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9180, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9149, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9122, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9143, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9153, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9162, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9092, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9130, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9121, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9151, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9143, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9129, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9179, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9112, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9162, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9183, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9137, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9184, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9205, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9143, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9125, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9178, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9118, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9160, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9203, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9159, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9148, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9161, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9157, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9171, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9115, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9200, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9095, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9110, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9140, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9172, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9119, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9195, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9132, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9123, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9103, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9125, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9142, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9159, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9166, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9122, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9150, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9142, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9157, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9125, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9125, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9163, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9119, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9142, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9132, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9117, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9129, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9179, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9129, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9186, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9130, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9097, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9148, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9162, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9122, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9131, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9123, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9158, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9118, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9183, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9144, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9126, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9130, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9108, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9160, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9152, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9084, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9117, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9129, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9112, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9112, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9115, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9128, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9120, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9140, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9148, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9132, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9105, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9114, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9137, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9113, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9103, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9150, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9131, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9142, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9148, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9121, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9153, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9136, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9154, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9125, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9139, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9173, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9132, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9131, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9122, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9119, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:  67%|██████████████████████▋           | 2/3 [31:30<15:45, 945.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 loss: 293.24\n",
      "tensor(0.9101, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9121, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9108, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9126, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9151, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9112, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9140, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9147, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9141, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9143, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9125, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9093, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9118, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9172, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9141, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9095, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9115, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9101, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9128, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9126, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9150, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9104, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9105, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9110, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9142, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9186, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9148, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9140, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9131, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9167, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9164, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9124, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9131, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9146, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9110, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9103, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9163, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9110, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9125, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9112, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9088, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9132, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9086, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9162, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9119, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9137, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9161, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9110, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9095, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9137, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9150, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9198, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9132, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9139, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9145, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9115, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9158, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9156, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9146, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9154, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9175, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9145, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9107, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9152, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9120, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9123, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9158, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9177, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9153, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9109, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9154, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9110, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9114, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9184, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9117, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9137, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9111, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9134, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9160, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9152, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9082, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9137, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9128, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9102, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9193, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9151, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9156, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9157, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9088, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9182, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9107, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9154, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9187, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9126, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9221, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9160, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9094, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9113, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9162, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9196, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9155, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9141, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9134, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9143, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9163, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9194, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9174, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9149, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9148, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9262, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9126, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9155, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9175, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9180, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9160, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9177, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9197, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9113, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9166, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9138, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9235, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9154, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9168, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9157, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9125, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9205, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9130, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9117, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9191, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9198, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9162, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9129, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9168, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9143, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9177, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9131, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9112, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9149, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9157, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9106, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9179, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9163, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9135, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9138, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9155, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9116, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9112, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9096, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9150, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9136, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9120, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9157, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9105, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9129, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9173, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9146, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9176, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9119, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9125, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9090, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9113, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9137, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9132, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9102, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9121, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9121, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9152, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9121, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9099, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9162, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9140, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9106, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9145, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9155, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9122, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9116, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9117, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9124, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9139, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9139, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9115, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9131, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9116, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9094, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9093, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9136, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9133, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9104, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9098, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9112, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9130, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9113, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9095, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9141, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9107, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9157, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9167, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9105, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9185, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9107, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9116, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9141, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9189, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9159, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9094, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9116, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9112, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9116, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9118, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9159, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9095, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9101, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9118, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9162, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9098, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9096, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9110, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9148, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9138, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9061, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9112, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9101, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9122, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9115, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9110, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9154, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9100, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9115, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9142, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9119, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9149, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9155, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9131, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9102, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9134, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9112, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9158, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9151, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9114, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9113, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9124, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9121, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9140, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9096, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9145, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9070, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9076, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9107, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9151, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9135, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9134, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9118, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9104, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9089, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9100, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9143, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9140, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9128, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9108, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9137, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9151, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9145, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9108, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9113, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9143, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9165, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9126, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9102, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9097, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9130, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9147, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9109, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9122, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9089, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9084, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9118, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9146, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9099, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9134, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9114, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9143, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9104, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9159, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9131, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9116, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9099, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9096, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9147, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9133, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9086, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9112, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9105, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9099, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9098, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9098, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9112, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9117, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9113, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9155, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9127, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9085, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9100, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9138, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9095, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9076, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9110, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9127, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9112, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9131, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9112, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9146, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9125, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9146, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9097, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9138, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9157, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9115, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9118, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9096, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9096, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████| 3/3 [47:20<00:00, 946.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 loss: 292.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.91\n",
      "Test accuracy: 99.28%\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "class MyViT(nn.Module):\n",
    "    def __init__(self, Dimensions, number_patchesRow,number_patchesColumn, number_blocks, Hidden_DGiven, NumberHeadsGiven, output_dimension):\n",
    "        \n",
    "        super(MyViT, self).__init__()\n",
    "        self.Dimensions = Dimensions  \n",
    "        self.number_patchesRow = number_patchesRow\n",
    "        self.number_patchesColumn=number_patchesColumn\n",
    "        self.number_blocks = number_blocks\n",
    "        self.Hidden_DGiven= Hidden_DGiven\n",
    "        self.NumberHeadsGiven = NumberHeadsGiven\n",
    "        \n",
    "        self.patch_size = (math.floor(Dimensions[1] / number_patchesRow), math.floor(Dimensions[2] / number_patchesColumn))\n",
    "        \n",
    "        self.input_d = int(Dimensions[0] * self.patch_size[0] * self.patch_size[1])\n",
    "        self.linear_mapper = nn.Linear(self.input_d, self.Hidden_DGiven)\n",
    "\n",
    "        self.class_token = nn.Parameter(torch.rand(1, self.Hidden_DGiven))\n",
    "\n",
    "        self.register_buffer(\n",
    "            \"positional_embeddings1\",\n",
    "            get_positional_embeddings4(number_patchesRow*number_patchesColumn + 1, Hidden_DGiven),\n",
    "            persistent=False,\n",
    "        )\n",
    "        \n",
    "        self.blocksA = nn.ModuleList(\n",
    "            [VisionTransformer(Hidden_DGiven, NumberHeadsGiven) for _ in range(number_blocks)]\n",
    "        )\n",
    "\n",
    "        self.mlp = nn.Sequential(nn.Linear(self.Hidden_DGiven, output_dimension), nn.Softmax(dim=-1))\n",
    "\n",
    "    def forward(self, images):        \n",
    "        n, c, h, w = images.shape\n",
    "        patches1A = images[0:n,0,0:self.patch_size[0]*self.number_patchesRow,0:self.patch_size[1]*self.number_patchesColumn]#patchify(images, self.n_patches).to(self.positional_embeddings1.device)\n",
    "        Size=64#(patches1A.size(1)*patches1A.size(2))/(self.number_patchesRow*self.number_patchesColumn)\n",
    "        #print(Size)\n",
    "        patches1=patches1A.reshape(n,self.number_patchesRow*self.number_patchesColumn,Size)\n",
    "        \n",
    "        tokens1 = self.linear_mapper(patches1)\n",
    "        tokensa = torch.cat((self.class_token.expand(n, 1, -1), tokens1), dim=1)\n",
    "\n",
    "        A    = tokensa + self.positional_embeddings1.repeat(n, 1, 1) \n",
    "\n",
    "        for block in self.blocksA:\n",
    "            A = block(A)\n",
    "        \n",
    "        output = torch.ones(n,self.Hidden_DGiven)\n",
    "        \n",
    "        output[0:n,self.Hidden_DGiven*0:self.Hidden_DGiven]  = A[:, 0]\n",
    "\n",
    "        return self.mlp(output)\n",
    "\n",
    "\n",
    "def main():\n",
    "    \n",
    "    transform = ToTensor()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = MyViT(\n",
    "        (1, 128,40), number_patchesRow=16, number_patchesColumn=5, number_blocks=2, Hidden_DGiven=5, NumberHeadsGiven=5, output_dimension=5\n",
    "    ).to(device)\n",
    "\n",
    "    NUMBER_EPOCHS = 3\n",
    "    LearningRate = 0.003\n",
    "\n",
    "    # Training Data loop\n",
    "    optimizer = Adam(model.parameters(), lr= LearningRate)\n",
    "    criterion = CrossEntropyLoss()\n",
    "\n",
    "    for epoch in trange(NUMBER_EPOCHS, desc=\"Training\"):\n",
    "        training_loss = 0.0\n",
    "        for batch in range(0,Length,Stride):\n",
    "            y = y_train[batch:batch+Stride]\n",
    "            x = X_train[batch:batch+Stride,0:1,0:128,0:40]\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            y_hat = model(x)\n",
    "            \n",
    "            loss = criterion(y_hat, y.type(torch.LongTensor))\n",
    "            print(loss)\n",
    "            training_loss += loss.detach().cpu().item()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        print(f\"Epoch {epoch + 1}/{NUMBER_EPOCHS} loss: {training_loss:.2f}\")\n",
    "\n",
    "    # Testing loop with testing data\n",
    "    with torch.no_grad():\n",
    "        correct, total = 0, 0\n",
    "        test_loss = 0.0\n",
    "        y = y_test\n",
    "        x = X_test\n",
    "\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        y_hat = model(x)\n",
    "        loss = criterion(y_hat, y.type(torch.LongTensor))\n",
    "\n",
    "        test_loss += loss.detach().cpu().item()\n",
    "\n",
    "        correct += torch.sum(torch.argmax(y_hat, dim=1) == y).detach().cpu().item()\n",
    "        total += len(x)\n",
    "        print(f\"Test loss: {test_loss:.2f}\")\n",
    "        print(f\"Test accuracy: {correct / total * 100:.2f}%\")\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74d9a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import scipy.io as sio\n",
    "from os import listdir\n",
    "from skimage import io\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets.mnist import MNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "from tqdm import tqdm, trange\n",
    "import math   \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Install Data as it is saved from MATLAB\n",
    "\n",
    "NumPerElement=439999+1\n",
    "\n",
    "im=torch.zeros(NumPerElement,1,2,3600)\n",
    "label=torch.zeros(NumPerElement)\n",
    "\n",
    "count1=0\n",
    "count=-1\n",
    "folder_dir ='/Users/anuraagthakur/Desktop/RawData/2CW'\n",
    "for images in os.listdir(folder_dir):\n",
    "    if images != '.DS_Store':\n",
    "        AA=sio.loadmat(folder_dir+'/'+images)\n",
    "        if(count1<NumPerElement):\n",
    "            count1=count1+1\n",
    "            count=count+1\n",
    "            for key, value in AA.items():\n",
    "                im[count,0:1,0:1,0:3600] = torch.from_numpy(value.real[0:1,0:3600])\n",
    "                im[count,0:1,1:2,0:3600] = torch.from_numpy(value.imag[0:1,0:3600].copy())\n",
    "            label[count]=0\n",
    "\n",
    "            \n",
    "folder_dir ='/Users/anuraagthakur/Desktop/RawData/4CW'\n",
    "count2=0\n",
    "for images in os.listdir(folder_dir):\n",
    "    if images != '.DS_Store':\n",
    "        AA=sio.loadmat(folder_dir+'/'+images)\n",
    "        if(count2<NumPerElement):\n",
    "            count2=count2+1\n",
    "            count=count+1\n",
    "            for key, value in AA.items():\n",
    "                im[count,0:1,0:1,0:3600] = torch.from_numpy(value.real[0:1,0:3600])\n",
    "                im[count,0:1,1:2,0:3600] = torch.from_numpy(value.imag[0:1,0:3600].copy())\n",
    "            label[count]=0\n",
    "\n",
    "        \n",
    "folder_dir ='/Users/anuraagthakur/Desktop/RawData/6CW'\n",
    "count3=0\n",
    "for images in os.listdir(folder_dir):\n",
    "    if images != '.DS_Store':\n",
    "        AA=sio.loadmat(folder_dir+'/'+images)\n",
    "        if(count3<NumPerElement):\n",
    "            count3=count3+1\n",
    "            count=count+1\n",
    "            for key, value in AA.items():\n",
    "                im[count,0:1,0:1,0:3600] = torch.from_numpy(value.real[0:1,0:3600])\n",
    "                im[count,0:1,1:2,0:3600] = torch.from_numpy(value.imag[0:1,0:3600].copy())\n",
    "            label[count]=0\n",
    "\n",
    " \n",
    "folder_dir ='/Users/anuraagthakur/Desktop/RawData/8CW'\n",
    "count4=0\n",
    "for images in os.listdir(folder_dir):   \n",
    "    if images != '.DS_Store':\n",
    "        AA=sio.loadmat(folder_dir+'/'+images)\n",
    "        if(count4<NumPerElement):\n",
    "            count4=count4+1\n",
    "            count=count+1\n",
    "            for key, value in AA.items():\n",
    "                im[count,0:1,0:1,0:3600] = torch.from_numpy(value.real[0:1,0:3600])\n",
    "                im[count,0:1,1:2,0:3600] = torch.from_numpy(value.imag[0:1,0:3600].copy())\n",
    "            label[count]=0\n",
    "\n",
    "folder_dir ='/Users/anuraagthakur/Desktop/RawData/AWGN'\n",
    "count5=0\n",
    "for images in os.listdir(folder_dir):\n",
    "    if images != '.DS_Store':\n",
    "        AA=sio.loadmat(folder_dir+'/'+images)\n",
    "        if(count5<NumPerElement):\n",
    "            count5=count5+1\n",
    "            count=count+1\n",
    "            for key, value in AA.items():\n",
    "                im[count,0:1,0:1,0:3600] = torch.from_numpy(value.real[0:1,0:3600])\n",
    "                im[count,0:1,1:2,0:3600] = torch.from_numpy(value.imag[0:1,0:3600].copy())\n",
    "            label[count]=1\n",
    "\n",
    "folder_dir ='/Users/anuraagthakur/Desktop/RawData/FMCWD1'\n",
    "count6=0\n",
    "for images in os.listdir(folder_dir):     \n",
    "    if images != '.DS_Store':\n",
    "        AA=sio.loadmat(folder_dir+'/'+images)\n",
    "        if(count6<NumPerElement):\n",
    "            count6=count6+1\n",
    "            count=count+1\n",
    "            for key, value in AA.items():\n",
    "                im[count,0:1,0:1,0:3600] = torch.from_numpy(value.real[0:1,0:3600])\n",
    "                im[count,0:1,1:2,0:3600] = torch.from_numpy(value.imag[0:1,0:3600].copy())\n",
    "            label[count]=2\n",
    "\n",
    "folder_dir ='/Users/anuraagthakur/Desktop/RawData/FMCWD2'        \n",
    "count7=0\n",
    "for images in os.listdir(folder_dir):\n",
    "    if images != '.DS_Store':\n",
    "        AA=sio.loadmat(folder_dir+'/'+images)\n",
    "        if(count7<NumPerElement):\n",
    "            count7=count7+1\n",
    "            count=count+1\n",
    "            for key, value in AA.items():\n",
    "                im[count,0:1,0:1,0:3600] = torch.from_numpy(value.real[0:1,0:3600])\n",
    "                im[count,0:1,1:2,0:3600] = torch.from_numpy(value.imag[0:1,0:3600].copy())\n",
    "            label[count]=2\n",
    "\n",
    "folder_dir ='/Users/anuraagthakur/Desktop/RawData/FMCWD3'        \n",
    "count8=0\n",
    "for images in os.listdir(folder_dir):\n",
    "    if images != '.DS_Store':\n",
    "        AA=sio.loadmat(folder_dir+'/'+images)\n",
    "        if(count8<NumPerElement):\n",
    "            count8=count8+1\n",
    "            count=count+1\n",
    "            for key, value in AA.items():\n",
    "                im[count,0:1,0:1,0:3600] = torch.from_numpy(value.real[0:1,0:3600])\n",
    "                im[count,0:1,1:2,0:3600] = torch.from_numpy(value.imag[0:1,0:3600].copy())\n",
    "            label[count]=2  \n",
    "                \n",
    "folder_dir ='/Users/anuraagthakur/Desktop/RawData/FMCWD4'        \n",
    "count9=0\n",
    "for images in os.listdir(folder_dir):\n",
    "    if images != '.DS_Store':\n",
    "        AA=sio.loadmat(folder_dir+'/'+images)\n",
    "        if(count9<NumPerElement):\n",
    "            count9=count9+1\n",
    "            count=count+1\n",
    "            for key, value in AA.items():\n",
    "                im[count,0:1,0:1,0:3600] = torch.from_numpy(value.real[0:1,0:3600])\n",
    "                im[count,0:1,1:2,0:3600] = torch.from_numpy(value.imag[0:1,0:3600].copy())\n",
    "            label[count]=2 \n",
    "                \n",
    "                \n",
    "folder_dir ='/Users/anuraagthakur/Desktop/RawData/FMCWT1'        \n",
    "count10=0\n",
    "for images in os.listdir(folder_dir):\n",
    "    if images != '.DS_Store':\n",
    "        AA=sio.loadmat(folder_dir+'/'+images)\n",
    "        if(count10<NumPerElement):\n",
    "            count10=count10+1\n",
    "            count=count+1\n",
    "            for key, value in AA.items():\n",
    "                im[count,0:1,0:1,0:3600] = torch.from_numpy(value.real[0:1,0:3600])\n",
    "                im[count,0:1,1:2,0:3600] = torch.from_numpy(value.imag[0:1,0:3600].copy())\n",
    "            label[count]=3\n",
    "                \n",
    "                \n",
    "folder_dir ='/Users/anuraagthakur/Desktop/RawData/FMCWT2'        \n",
    "count11=0\n",
    "for images in os.listdir(folder_dir):\n",
    "    if images != '.DS_Store':\n",
    "        AA=sio.loadmat(folder_dir+'/'+images)\n",
    "        if(count11<NumPerElement):\n",
    "            count11=count11+1\n",
    "            count=count+1\n",
    "            for key, value in AA.items():\n",
    "                im[count,0:1,0:1,0:3600] = torch.from_numpy(value.real[0:1,0:3600])\n",
    "                im[count,0:1,1:2,0:3600] = torch.from_numpy(value.imag[0:1,0:3600].copy())\n",
    "            label[count]=3\n",
    "\n",
    "folder_dir ='/Users/anuraagthakur/Desktop/RawData/FMCWT3'        \n",
    "count12=0\n",
    "for images in os.listdir(folder_dir):\n",
    "    if images != '.DS_Store':\n",
    "        AA=sio.loadmat(folder_dir+'/'+images)\n",
    "        if(count12<NumPerElement):\n",
    "            count12=count12+1\n",
    "            count=count+1\n",
    "            for key, value in AA.items():\n",
    "                Image1=torch.from_numpy(value)\n",
    "                im[count,0:1,0:1,0:3600] = torch.from_numpy(value.real[0:1,0:3600])\n",
    "                im[count,0:1,1:2,0:3600] = torch.from_numpy(value.imag[0:1,0:3600].copy())\n",
    "            label[count]=3\n",
    "        \n",
    "        \n",
    "folder_dir ='/Users/anuraagthakur/Desktop/RawData/FMCWT4'        \n",
    "count13=0\n",
    "for images in os.listdir(folder_dir):\n",
    "    if images != '.DS_Store':\n",
    "        AA=sio.loadmat(folder_dir+'/'+images)\n",
    "        if(count13<NumPerElement):\n",
    "            count13=count13+1\n",
    "            count=count+1\n",
    "            for key, value in AA.items():\n",
    "                im[count,0:1,0:1,0:3600] = torch.from_numpy(value.real[0:1,0:3600])\n",
    "                im[count,0:1,1:2,0:3600] = torch.from_numpy(value.imag[0:1,0:3600].copy())\n",
    "            label[count]=3\n",
    "            \n",
    "folder_dir ='/Users/anuraagthakur/Desktop/RawData/FMCWUP1'        \n",
    "count14=0\n",
    "for images in os.listdir(folder_dir):\n",
    "    if images != '.DS_Store':\n",
    "        AA=sio.loadmat(folder_dir+'/'+images)\n",
    "        if(count14<NumPerElement):\n",
    "            count14=count14+1\n",
    "            count=count+1\n",
    "            for key, value in AA.items():\n",
    "                im[count,0:1,0:1,0:3600] = torch.from_numpy(value.real[0:1,0:3600])\n",
    "                im[count,0:1,1:2,0:3600] = torch.from_numpy(value.imag[0:1,0:3600].copy())\n",
    "            label[count]=4\n",
    "            \n",
    "\n",
    "folder_dir ='/Users/anuraagthakur/Desktop/RawData/FMCWUP2'        \n",
    "count15=0\n",
    "for images in os.listdir(folder_dir):\n",
    "    if images != '.DS_Store':\n",
    "        AA=sio.loadmat(folder_dir+'/'+images)\n",
    "        if(count15<NumPerElement):\n",
    "            count15=count15+1\n",
    "            count=count+1\n",
    "            for key, value in AA.items():\n",
    "                im[count,0:1,0:1,0:3600] = torch.from_numpy(value.real[0:1,0:3600])\n",
    "                im[count,0:1,1:2,0:3600] = torch.from_numpy(value.imag[0:1,0:3600].copy())\n",
    "            label[count]=4\n",
    "            \n",
    "folder_dir ='/Users/anuraagthakur/Desktop/RawData/FMCWUP3'        \n",
    "count16=0\n",
    "for images in os.listdir(folder_dir):\n",
    "    if images != '.DS_Store':\n",
    "        AA=sio.loadmat(folder_dir+'/'+images)\n",
    "        if(count16<NumPerElement):\n",
    "            count16=count16+1\n",
    "            count=count+1\n",
    "            for key, value in AA.items():\n",
    "                im[count,0:1,0:1,0:3600] = torch.from_numpy(value.real[0:1,0:3600])\n",
    "                im[count,0:1,1:2,0:3600] = torch.from_numpy(value.imag[0:1,0:3600].copy())\n",
    "            label[count]=4\n",
    "            \n",
    "folder_dir ='/Users/anuraagthakur/Desktop/RawData/FMCWUP4'        \n",
    "count17=0\n",
    "for images in os.listdir(folder_dir):\n",
    "    if images != '.DS_Store':\n",
    "        AA=sio.loadmat(folder_dir+'/'+images)\n",
    "        if(count17<NumPerElement):\n",
    "            count17=count17+1\n",
    "            count=count+1\n",
    "            for key, value in AA.items():\n",
    "                im[count,0:1,0:1,0:3600] = torch.from_numpy(value.real[0:1,0:3600])\n",
    "                im[count,0:1,1:2,0:3600] = torch.from_numpy(value.imag[0:1,0:3600].copy())\n",
    "            label[count]=4\n",
    "\n",
    "folder_dir ='/Users/anuraagthakur/Desktop/RawData/FSK2'        \n",
    "count18=0\n",
    "for images in os.listdir(folder_dir):\n",
    "    if images != '.DS_Store':\n",
    "        AA=sio.loadmat(folder_dir+'/'+images)\n",
    "        if(count18<NumPerElement):\n",
    "            count18=count18+1\n",
    "            count=count+1\n",
    "            for key, value in AA.items():\n",
    "                im[count,0:1,0:1,0:3600] = torch.from_numpy(value.real[0:1,0:3600])\n",
    "                im[count,0:1,1:2,0:3600] = torch.from_numpy(value.imag[0:1,0:3600].copy())\n",
    "            label[count]=5\n",
    "            \n",
    "            \n",
    "folder_dir ='/Users/anuraagthakur/Desktop/RawData/FSK4'        \n",
    "count19=0\n",
    "for images in os.listdir(folder_dir):\n",
    "    if images != '.DS_Store':\n",
    "        AA=sio.loadmat(folder_dir+'/'+images)\n",
    "        if(count19<NumPerElement):\n",
    "            count19=count19+1\n",
    "            count=count+1\n",
    "            for key, value in AA.items():\n",
    "                im[count,0:1,0:1,0:3600] = torch.from_numpy(value.real[0:1,0:3600])\n",
    "                im[count,0:1,1:2,0:3600] = torch.from_numpy(value.imag[0:1,0:3600].copy())\n",
    "            label[count]=5\n",
    "            \n",
    "folder_dir ='/Users/anuraagthakur/Desktop/RawData/FSK8'        \n",
    "count20=0\n",
    "for images in os.listdir(folder_dir):\n",
    "    if images != '.DS_Store':\n",
    "        AA=sio.loadmat(folder_dir+'/'+images)\n",
    "        if(count20<NumPerElement):\n",
    "            count20=count20+1\n",
    "            count=count+1\n",
    "            for key, value in AA.items():\n",
    "                im[count,0:1,0:1,0:3600] = torch.from_numpy(value.real[0:1,0:3600])\n",
    "                im[count,0:1,1:2,0:3600] = torch.from_numpy(value.imag[0:1,0:3600].copy())\n",
    "            label[count]=5\n",
    "            \n",
    "            \n",
    "folder_dir ='/Users/anuraagthakur/Desktop/RawData/FSK16'        \n",
    "count21=0\n",
    "for images in os.listdir(folder_dir):\n",
    "    if images != '.DS_Store':\n",
    "        AA=sio.loadmat(folder_dir+'/'+images)\n",
    "        if(count21<NumPerElement):\n",
    "            count21=count21+1\n",
    "            count=count+1\n",
    "            for key, value in AA.items():\n",
    "                im[count,0:1,0:1,0:3600] = torch.from_numpy(value.real[0:1,0:3600])\n",
    "                im[count,0:1,1:2,0:3600] = torch.from_numpy(value.imag[0:1,0:3600].copy())\n",
    "            label[count]=5\n",
    "\n",
    "\n",
    "folder_dir ='/Users/anuraagthakur/Desktop/RawData/Wideband'        \n",
    "count22=0\n",
    "for images in os.listdir(folder_dir):\n",
    "    if images != '.DS_Store':\n",
    "        AA=sio.loadmat(folder_dir+'/'+images)\n",
    "        if(count22<NumPerElement):\n",
    "            count22=count22+1\n",
    "            count=count+1\n",
    "            for key, value in AA.items():\n",
    "                im[count,0:1,0:1,0:3600] = torch.from_numpy(value.real[0:1,0:3600])\n",
    "                im[count,0:1,1:2,0:3600] = torch.from_numpy(value.imag[0:1,0:3600].copy())\n",
    "            label[count]=6"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
